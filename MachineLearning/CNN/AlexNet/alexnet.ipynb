{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annoying-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "familiar-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AlexNet结构\n",
    "硬件原因，修改了网络的参数\n",
    "\n",
    "1.卷积层\n",
    "2.池化层\n",
    "3.归一化层\n",
    "4.卷积层\n",
    "5.池化层\n",
    "6.归一化层\n",
    "7.卷积层\n",
    "8.卷积层\n",
    "9.卷积层\n",
    "10.池化层 \n",
    "11.全连接层\n",
    "12.dropout层\n",
    "13.全连接层\n",
    "14.dropout层\n",
    "15.全连接层\n",
    "'''\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, classNums):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=48,\n",
    "                      kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=48, out_channels=128,\n",
    "                      kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=192,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=192,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=128,\n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 6 * 6, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "\n",
    "        self.output = nn.Linear(1024, classNums)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.conv2(net)\n",
    "        net = self.conv3(net)\n",
    "        net = self.conv4(net)\n",
    "        net = self.conv5(net)\n",
    "        net = net.view(net.size(0), -1)\n",
    "        net = self.fc1(net)\n",
    "        net = self.fc2(net)\n",
    "        res = self.output(net)\n",
    "\n",
    "        return res, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "armed-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vietnamese-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkfile(fp):\n",
    "    if not os.path.exists(fp):\n",
    "        os.makedirs(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[daisy] : 633]\n",
      "[dandelion] : 898]\n",
      "[roses] : 641]\n",
      "[sunflowers] : 699]\n",
      "[tulips] : 799]\n",
      "processing done!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "数据和代码不在一个盘里\n",
    "'''\n",
    "fp = \"M:/DataSet/alexnet/flower_photos/\"\n",
    "\n",
    "flower_labels = [label for label in os.listdir(fp) if \".txt\" not in label]\n",
    "\n",
    "mkfile(\"M:/DataSet/alexnet/train\")\n",
    "for label in flower_labels:\n",
    "    mkfile(\"M:/DataSet/alexnet/train/\" + label)\n",
    "\n",
    "mkfile(\"M:/DataSet/alexnet/val\")\n",
    "for label in flower_labels:\n",
    "    mkfile(\"M:/DataSet/alexnet/val/\" + label)\n",
    "\n",
    "rate = 0.1\n",
    "for label in flower_labels:\n",
    "    label_path = fp + \"/\" + label + \"/\"\n",
    "    imgs = os.listdir(label_path)\n",
    "    imgNums = len(imgs)\n",
    "    indexs = random.sample(imgs, k=int(imgNums*rate))\n",
    "    for idx, img in enumerate(imgs):\n",
    "        if img in indexs:\n",
    "            img_path = label_path + img\n",
    "            new_path = \"M:/DataSet/alexnet/val/\" + label\n",
    "            copy(img_path, new_path)\n",
    "        else:\n",
    "            img_path = label_path + img\n",
    "            new_path = \"M:/DataSet/alexnet/train/\" + label\n",
    "            copy(img_path, new_path)\n",
    "    print(f\"\\r[{label}] : {imgNums}]\")\n",
    "\n",
    "print(\"processing done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proud-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = torch.device(\"cpu\")\n",
    "handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "antique-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据变换\n",
    "data_trans = {\n",
    "    \"train\": torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop(224),\n",
    "                                            torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]),\n",
    "    \"val\": torchvision.transforms.Compose([torchvision.transforms.RandomResizedCrop((224, 224)),\n",
    "                                           torchvision.transforms.ToTensor(),\n",
    "                                           torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accepting-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据的根目录与代码不在同一个盘\n",
    "data_root = \"M:/DataSet/alexnet/\"\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root=data_root + \"train\", transform=data_trans[\"train\"])\n",
    "trainNums = len(train_data)\n",
    "\n",
    "flower_list = train_data.class_to_idx\n",
    "label_dict = dict((val, key) for key, val in flower_list.items())\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "distinguished-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data = torchvision.datasets.ImageFolder(\n",
    "    root=data_root+\"val\", transform=data_trans[\"val\"])\n",
    "valNums = len(validate_data)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    validate_data, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arabic-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "jsons = json.dumps(label_dict, indent=4)\n",
    "with open(\"alexnet.json\", 'w') as json_file:\n",
    "    json_file.write(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mature-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = iter(val_loader)\n",
    "test_img, test_label = test_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet(classNums=5)\n",
    "net.to(handler)\n",
    "\n",
    "# 使用交叉熵和adam优化器\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0002)\n",
    "\n",
    "# 参数保存路径\n",
    "save_path = \"./alexnet.pth\"\n",
    "\n",
    "# 最高准确率\n",
    "accBest = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fatty-final",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train_loss: 1.397  test_acc: 0.444\n",
      "[epoch 2] train_loss: 1.217  test_acc: 0.538\n",
      "[epoch 3] train_loss: 1.098  test_acc: 0.554\n",
      "[epoch 4] train_loss: 1.013  test_acc: 0.617\n",
      "[epoch 5] train_loss: 0.959  test_acc: 0.622\n",
      "[epoch 6] train_loss: 0.943  test_acc: 0.672\n",
      "[epoch 7] train_loss: 0.910  test_acc: 0.645\n",
      "[epoch 8] train_loss: 0.870  test_acc: 0.674\n",
      "[epoch 9] train_loss: 0.862  test_acc: 0.698\n",
      "[epoch 10] train_loss: 0.821  test_acc: 0.709\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    for step, data in enumerate(train_loader, start=0):\n",
    "        imgs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(imgs.to(handler))\n",
    "        loss = loss_func(outputs[0], labels.to(handler))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 测试\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_data in val_loader:\n",
    "            val_imgs, val_labels = val_data\n",
    "            outputs = net(val_imgs.to(handler))\n",
    "            pred_y = torch.max(outputs[0], dim=1)[1]\n",
    "            acc += (pred_y == val_labels.to(handler)).sum().item()\n",
    "        val_acc = acc / valNums\n",
    "        if val_acc > accBest:\n",
    "            accBest = val_acc\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "        print(\"[epoch {}] train_loss: {:.3f}  test_acc: {:.3f}\".format(\n",
    "            epoch+1, running_loss/step, val_acc))\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-stomach",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
