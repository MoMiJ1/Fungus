{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prepared-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 212697 entries, 0 to 212696\n",
      "Columns: 312 entries, TMC to yorkrockhillkuza29730\n",
      "dtypes: float64(10), int64(302)\n",
      "memory usage: 507.9 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold,GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "from imblearn import over_sampling\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv(\"M:/DataSet/usaccident/real/selectData.csv\",index_col=0)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "romance-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212697, 311), (212697,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['Severity']\n",
    "X = data.drop([\"Severity\"], axis=1)\n",
    "\n",
    "del data\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-notice",
   "metadata": {},
   "source": [
    "Part Ⅰ \n",
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-planning",
   "metadata": {},
   "source": [
    "1.划分数据集\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "invalid-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136125, 311), (42540, 311), (34032, 311), (136125,), (42540,), (34032,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10, stratify=Y)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size=0.2,random_state=10,stratify=Y_train)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape, Y_train.shape, Y_test.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-portuguese",
   "metadata": {},
   "source": [
    "2.PCA\n",
    "=\n",
    "Note:<br>\n",
    "先标准化再PCA的原因<br>\n",
    "ANS：<br>\n",
    "PCA通常用于高维数据的降维，它可以将原来高维的数据投影到某个低维空间并使其方差尽可能大<br>\n",
    "如果数据某一列数值特别大，那么他在整个误差计算的比重就很大，因此在投影到低维空间后，为了使<br>\n",
    "低秩分解逼近原数据，整个投影会努力逼近最大的那个特征，而忽略数值比较小的特征，因为建模前<br>\n",
    "我们不知道各个特征的重要性，这样就很可能造成大量信息丢失，因此为了防止捕捉哪些数值过大的特征<br>\n",
    "需要在PCA前进行标准化<br>\n",
    "<br>实例：如果这里不经标准化就PCA，当设定 n_components=0.99时，只有4个特征；标准化后再PCA则为19个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shaped-present",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999014000578292\n",
      "207\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9999)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(len(pca.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satellite-devices",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136125, 207), (42540, 207), (34032, 207))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-minnesota",
   "metadata": {},
   "source": [
    "3.OverSampling\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excessive-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 111548), (2, 111548), (3, 111548), (4, 111548)]\n"
     ]
    }
   ],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=12)\n",
    "\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(sorted(Counter(Y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-interpretation",
   "metadata": {},
   "source": [
    "4.Model\n",
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-minute",
   "metadata": {},
   "source": [
    "DecisionTree\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaning-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    0 24652    13    22]\n",
      " [    0     0  5064     0]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    4    19     2     0]\n",
      " [   21 31445  3176   217]\n",
      " [    4  3503  3768    52]\n",
      " [    0   182    53    94]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00     24687\n",
      "           3       1.00      1.00      1.00      5064\n",
      "           4       0.91      1.00      0.96       234\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       0.98      1.00      0.99     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.16      0.15        25\n",
      "           2       0.89      0.90      0.90     34859\n",
      "           3       0.54      0.51      0.53      7327\n",
      "           4       0.26      0.29      0.27       329\n",
      "\n",
      "    accuracy                           0.83     42540\n",
      "   macro avg       0.46      0.47      0.46     42540\n",
      "weighted avg       0.83      0.83      0.83     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "\n",
    "pred_dt = dtree.predict(X_test)\n",
    "y_train_pred = dtree.predict(X_train[:30000])\n",
    "\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "mat_dt = confusion_matrix(Y_test, pred_dt)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_dt}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_dt))\n",
    "\n",
    "del pred_dt, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "actual-rubber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   14     0     1     0]\n",
      " [  454 13035  8533  2665]\n",
      " [   47   401  4316   300]\n",
      " [    1     1    12   220]]\n",
      "\n",
      "confusion matrix :\n",
      "[[   11    10     4     0]\n",
      " [  693 18252 12243  3671]\n",
      " [   66   639  6181   441]\n",
      " [    2    43    31   253]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.03      0.93      0.05        15\n",
      "           2       0.97      0.53      0.68     24687\n",
      "           3       0.34      0.85      0.48      5064\n",
      "           4       0.07      0.94      0.13       234\n",
      "\n",
      "    accuracy                           0.59     30000\n",
      "   macro avg       0.35      0.81      0.34     30000\n",
      "weighted avg       0.86      0.59      0.65     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.44      0.03        25\n",
      "           2       0.96      0.52      0.68     34859\n",
      "           3       0.33      0.84      0.48      7327\n",
      "           4       0.06      0.77      0.11       329\n",
      "\n",
      "    accuracy                           0.58     42540\n",
      "   macro avg       0.34      0.64      0.32     42540\n",
      "weighted avg       0.85      0.58      0.64     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[8,10,12,14,16]\n",
    "}\n",
    "clf = GridSearchCV(dtree, param_grid=dt_params,cv=5,scoring='recall',n_jobs=-1)\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(**clf.best_params_)\n",
    "dtree.fit(X_train, Y_train)\n",
    "\n",
    "pred_dt = dtree.predict(X_test)\n",
    "y_train_pred = dtree.predict(X_train[:30000])\n",
    "\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "mat_dt = confusion_matrix(Y_test, pred_dt)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_dt}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_dt))\n",
    "\n",
    "del pred_dt, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-classics",
   "metadata": {},
   "source": [
    "RandomForest\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "improving-avatar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    6 20003  4342   336]\n",
      " [    0    59  4943    62]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    5    18     2     0]\n",
      " [    7 27362  6895   595]\n",
      " [    1   718  6428   180]\n",
      " [    0   115    30   184]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      1.00      0.83        15\n",
      "           2       1.00      0.81      0.89     24687\n",
      "           3       0.53      0.98      0.69      5064\n",
      "           4       0.37      1.00      0.54       234\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.65      0.95      0.74     30000\n",
      "weighted avg       0.91      0.84      0.86     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.20      0.26        25\n",
      "           2       0.97      0.78      0.87     34859\n",
      "           3       0.48      0.88      0.62      7327\n",
      "           4       0.19      0.56      0.29       329\n",
      "\n",
      "    accuracy                           0.80     42540\n",
      "   macro avg       0.51      0.61      0.51     42540\n",
      "weighted avg       0.88      0.80      0.82     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "y_train_pred = rfc.predict(X_train[:30000])\n",
    "\n",
    "mat_rfc = confusion_matrix(Y_test, pred_rfc)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_rfc}\\n\")\n",
    "\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_rfc))\n",
    "\n",
    "del pred_rfc, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impressive-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [   15 18095  5412  1165]\n",
      " [    1   211  4673   179]\n",
      " [    0     0     4   230]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    6    17     2     0]\n",
      " [   21 25140  7987  1711]\n",
      " [    3   616  6381   327]\n",
      " [    0    71    26   232]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      1.00      0.65        15\n",
      "           2       0.99      0.73      0.84     24687\n",
      "           3       0.46      0.92      0.62      5064\n",
      "           4       0.15      0.98      0.25       234\n",
      "\n",
      "    accuracy                           0.77     30000\n",
      "   macro avg       0.52      0.91      0.59     30000\n",
      "weighted avg       0.89      0.77      0.80     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.24      0.22        25\n",
      "           2       0.97      0.72      0.83     34859\n",
      "           3       0.44      0.87      0.59      7327\n",
      "           4       0.10      0.71      0.18       329\n",
      "\n",
      "    accuracy                           0.75     42540\n",
      "   macro avg       0.43      0.63      0.45     42540\n",
      "weighted avg       0.87      0.75      0.78     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_params = {\n",
    "    \"n_estimators\" : [150, 200],\n",
    "    'max_depth' : [11,15,19]\n",
    "}\n",
    "clf = GridSearchCV(rfc, param_grid=rfc_params, scoring='recall',cv=5,n_jobs=-1)\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "rfc = RandomForestClassifier(**clf.best_params_)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "y_train_pred = rfc.predict(X_train[:30000])\n",
    "\n",
    "mat_rfc = confusion_matrix(Y_test, pred_rfc)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_rfc}\\n\")\n",
    "\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_rfc))\n",
    "\n",
    "del pred_rfc,y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-nothing",
   "metadata": {},
   "source": [
    "XGB\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dynamic-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    1 20190  4167   329]\n",
      " [    0   192  4840    32]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    5    18     2     0]\n",
      " [    4 27901  6389   565]\n",
      " [    1   680  6501   145]\n",
      " [    0    98    49   182]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       0.99      0.82      0.90     24687\n",
      "           3       0.54      0.96      0.69      5064\n",
      "           4       0.39      1.00      0.56       234\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.71      0.94      0.78     30000\n",
      "weighted avg       0.91      0.84      0.86     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.20      0.29        25\n",
      "           2       0.97      0.80      0.88     34859\n",
      "           3       0.50      0.89      0.64      7327\n",
      "           4       0.20      0.55      0.30       329\n",
      "\n",
      "    accuracy                           0.81     42540\n",
      "   macro avg       0.54      0.61      0.53     42540\n",
      "weighted avg       0.89      0.81      0.83     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, Y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "y_train_pred = xgb.predict(X_train[:30000])\n",
    "\n",
    "mat_xgb = confusion_matrix(Y_test, pred_xgb)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_xgb}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_xgb))\n",
    "\n",
    "del pred_xgb, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "internal-hollow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:22:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:23:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:24:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:24:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:25:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:26:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:27:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:31:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:35:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:36:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:38:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:40:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:43:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:45:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:47:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:52:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:00:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:03:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:10:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:13:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:20:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[12:21:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [ 1373 14119  6278  2917]\n",
      " [  111   386  4253   314]\n",
      " [    7     7     8   212]]\n",
      "\n",
      "confusion matrix :\n",
      "[[   13     8     4     0]\n",
      " [ 2000 19851  8958  4050]\n",
      " [  180   581  6096   470]\n",
      " [   11    18    14   286]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      1.00      0.02        15\n",
      "           2       0.97      0.57      0.72     24687\n",
      "           3       0.40      0.84      0.55      5064\n",
      "           4       0.06      0.91      0.12       234\n",
      "\n",
      "    accuracy                           0.62     30000\n",
      "   macro avg       0.36      0.83      0.35     30000\n",
      "weighted avg       0.87      0.62      0.69     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.52      0.01        25\n",
      "           2       0.97      0.57      0.72     34859\n",
      "           3       0.40      0.83      0.54      7327\n",
      "           4       0.06      0.87      0.11       329\n",
      "\n",
      "    accuracy                           0.62     42540\n",
      "   macro avg       0.36      0.70      0.35     42540\n",
      "weighted avg       0.87      0.62      0.68     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'max_depth' : [1,3,5],\n",
    "    'n_estimators' : [150,200]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(xgb, param_grid=xgb_params,cv=5,scoring='recall')\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(**clf.best_params_)\n",
    "xgb.fit(X_train, Y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "y_train_pred = xgb.predict(X_train[:30000])\n",
    "\n",
    "mat_xgb = confusion_matrix(Y_test, pred_xgb)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_xgb}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_xgb))\n",
    "\n",
    "del pred_xgb, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-morrison",
   "metadata": {},
   "source": [
    "LGBM\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "textile-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    7 19322  4691   667]\n",
      " [    0   289  4681    94]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    8    13     4     0]\n",
      " [    8 26946  6903  1002]\n",
      " [    1   598  6507   221]\n",
      " [    0    66    32   231]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      1.00      0.81        15\n",
      "           2       0.99      0.78      0.87     24687\n",
      "           3       0.50      0.92      0.65      5064\n",
      "           4       0.24      1.00      0.38       234\n",
      "\n",
      "    accuracy                           0.81     30000\n",
      "   macro avg       0.60      0.93      0.68     30000\n",
      "weighted avg       0.90      0.81      0.83     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.32      0.38        25\n",
      "           2       0.98      0.77      0.86     34859\n",
      "           3       0.48      0.89      0.63      7327\n",
      "           4       0.16      0.70      0.26       329\n",
      "\n",
      "    accuracy                           0.79     42540\n",
      "   macro avg       0.52      0.67      0.53     42540\n",
      "weighted avg       0.88      0.79      0.82     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, Y_train)\n",
    "pred_lgbm = lgbm.predict(X_test)\n",
    "y_train_pred = lgbm.predict(X_train[:30000])\n",
    "\n",
    "mat_lgbm = confusion_matrix(Y_test, pred_lgbm)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_lgbm}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_lgbm))\n",
    "\n",
    "del pred_lgbm, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-poverty",
   "metadata": {},
   "source": [
    "CATBoost\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tight-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.108006\n",
      "0:\tlearn: 1.2780253\ttotal: 1.06s\tremaining: 17m 40s\n",
      "1:\tlearn: 1.1976163\ttotal: 2s\tremaining: 16m 37s\n",
      "2:\tlearn: 1.1311887\ttotal: 2.92s\tremaining: 16m 10s\n",
      "3:\tlearn: 1.0785918\ttotal: 3.78s\tremaining: 15m 42s\n",
      "4:\tlearn: 1.0281566\ttotal: 4.99s\tremaining: 16m 33s\n",
      "5:\tlearn: 0.9890995\ttotal: 5.89s\tremaining: 16m 16s\n",
      "6:\tlearn: 0.9559753\ttotal: 6.77s\tremaining: 16m\n",
      "7:\tlearn: 0.9223701\ttotal: 7.76s\tremaining: 16m 2s\n",
      "8:\tlearn: 0.8960565\ttotal: 8.56s\tremaining: 15m 42s\n",
      "9:\tlearn: 0.8687259\ttotal: 9.55s\tremaining: 15m 45s\n",
      "10:\tlearn: 0.8416812\ttotal: 10.6s\tremaining: 15m 56s\n",
      "11:\tlearn: 0.8211241\ttotal: 11.5s\tremaining: 15m 49s\n",
      "12:\tlearn: 0.7981245\ttotal: 12.6s\tremaining: 15m 56s\n",
      "13:\tlearn: 0.7780670\ttotal: 13.5s\tremaining: 15m 51s\n",
      "14:\tlearn: 0.7632426\ttotal: 14.4s\tremaining: 15m 48s\n",
      "15:\tlearn: 0.7466232\ttotal: 15.4s\tremaining: 15m 47s\n",
      "16:\tlearn: 0.7320396\ttotal: 16.2s\tremaining: 15m 39s\n",
      "17:\tlearn: 0.7212058\ttotal: 17.1s\tremaining: 15m 30s\n",
      "18:\tlearn: 0.7074303\ttotal: 18s\tremaining: 15m 31s\n",
      "19:\tlearn: 0.6929914\ttotal: 19.1s\tremaining: 15m 37s\n",
      "20:\tlearn: 0.6804982\ttotal: 20.1s\tremaining: 15m 36s\n",
      "21:\tlearn: 0.6720008\ttotal: 20.8s\tremaining: 15m 25s\n",
      "22:\tlearn: 0.6600759\ttotal: 21.8s\tremaining: 15m 26s\n",
      "23:\tlearn: 0.6476222\ttotal: 22.9s\tremaining: 15m 31s\n",
      "24:\tlearn: 0.6359750\ttotal: 24s\tremaining: 15m 35s\n",
      "25:\tlearn: 0.6268451\ttotal: 24.9s\tremaining: 15m 32s\n",
      "26:\tlearn: 0.6176023\ttotal: 25.8s\tremaining: 15m 30s\n",
      "27:\tlearn: 0.6125584\ttotal: 26.5s\tremaining: 15m 21s\n",
      "28:\tlearn: 0.6038328\ttotal: 27.6s\tremaining: 15m 22s\n",
      "29:\tlearn: 0.5961040\ttotal: 28.4s\tremaining: 15m 19s\n",
      "30:\tlearn: 0.5880430\ttotal: 29.4s\tremaining: 15m 17s\n",
      "31:\tlearn: 0.5812360\ttotal: 30.1s\tremaining: 15m 11s\n",
      "32:\tlearn: 0.5752915\ttotal: 30.9s\tremaining: 15m 4s\n",
      "33:\tlearn: 0.5710241\ttotal: 31.6s\tremaining: 14m 57s\n",
      "34:\tlearn: 0.5655456\ttotal: 32.4s\tremaining: 14m 53s\n",
      "35:\tlearn: 0.5595636\ttotal: 33.3s\tremaining: 14m 52s\n",
      "36:\tlearn: 0.5537871\ttotal: 34.3s\tremaining: 14m 51s\n",
      "37:\tlearn: 0.5494177\ttotal: 35s\tremaining: 14m 46s\n",
      "38:\tlearn: 0.5457045\ttotal: 35.8s\tremaining: 14m 41s\n",
      "39:\tlearn: 0.5406216\ttotal: 36.7s\tremaining: 14m 40s\n",
      "40:\tlearn: 0.5354885\ttotal: 37.6s\tremaining: 14m 38s\n",
      "41:\tlearn: 0.5321060\ttotal: 38.4s\tremaining: 14m 35s\n",
      "42:\tlearn: 0.5278567\ttotal: 39.4s\tremaining: 14m 35s\n",
      "43:\tlearn: 0.5217455\ttotal: 40.3s\tremaining: 14m 35s\n",
      "44:\tlearn: 0.5151343\ttotal: 41.4s\tremaining: 14m 39s\n",
      "45:\tlearn: 0.5118629\ttotal: 42.1s\tremaining: 14m 33s\n",
      "46:\tlearn: 0.5094026\ttotal: 42.7s\tremaining: 14m 26s\n",
      "47:\tlearn: 0.5046260\ttotal: 43.7s\tremaining: 14m 27s\n",
      "48:\tlearn: 0.5005217\ttotal: 44.5s\tremaining: 14m 24s\n",
      "49:\tlearn: 0.4974060\ttotal: 45.3s\tremaining: 14m 20s\n",
      "50:\tlearn: 0.4946545\ttotal: 46.1s\tremaining: 14m 17s\n",
      "51:\tlearn: 0.4897117\ttotal: 47.2s\tremaining: 14m 20s\n",
      "52:\tlearn: 0.4857583\ttotal: 48.1s\tremaining: 14m 19s\n",
      "53:\tlearn: 0.4825608\ttotal: 48.8s\tremaining: 14m 15s\n",
      "54:\tlearn: 0.4788513\ttotal: 49.6s\tremaining: 14m 12s\n",
      "55:\tlearn: 0.4750605\ttotal: 50.7s\tremaining: 14m 14s\n",
      "56:\tlearn: 0.4730083\ttotal: 51.5s\tremaining: 14m 11s\n",
      "57:\tlearn: 0.4691035\ttotal: 52.3s\tremaining: 14m 9s\n",
      "58:\tlearn: 0.4661111\ttotal: 53s\tremaining: 14m 5s\n",
      "59:\tlearn: 0.4636483\ttotal: 53.8s\tremaining: 14m 2s\n",
      "60:\tlearn: 0.4618591\ttotal: 54.5s\tremaining: 13m 59s\n",
      "61:\tlearn: 0.4584126\ttotal: 55.5s\tremaining: 13m 59s\n",
      "62:\tlearn: 0.4557630\ttotal: 56.2s\tremaining: 13m 56s\n",
      "63:\tlearn: 0.4533267\ttotal: 56.9s\tremaining: 13m 52s\n",
      "64:\tlearn: 0.4509451\ttotal: 57.7s\tremaining: 13m 50s\n",
      "65:\tlearn: 0.4492179\ttotal: 58.5s\tremaining: 13m 47s\n",
      "66:\tlearn: 0.4469465\ttotal: 59.1s\tremaining: 13m 43s\n",
      "67:\tlearn: 0.4452296\ttotal: 59.8s\tremaining: 13m 39s\n",
      "68:\tlearn: 0.4423986\ttotal: 1m\tremaining: 13m 38s\n",
      "69:\tlearn: 0.4395777\ttotal: 1m 1s\tremaining: 13m 38s\n",
      "70:\tlearn: 0.4382809\ttotal: 1m 2s\tremaining: 13m 36s\n",
      "71:\tlearn: 0.4360947\ttotal: 1m 3s\tremaining: 13m 35s\n",
      "72:\tlearn: 0.4344553\ttotal: 1m 4s\tremaining: 13m 33s\n",
      "73:\tlearn: 0.4328077\ttotal: 1m 5s\tremaining: 13m 33s\n",
      "74:\tlearn: 0.4309945\ttotal: 1m 6s\tremaining: 13m 34s\n",
      "75:\tlearn: 0.4281560\ttotal: 1m 7s\tremaining: 13m 37s\n",
      "76:\tlearn: 0.4259872\ttotal: 1m 7s\tremaining: 13m 34s\n",
      "77:\tlearn: 0.4250046\ttotal: 1m 8s\tremaining: 13m 32s\n",
      "78:\tlearn: 0.4234340\ttotal: 1m 9s\tremaining: 13m 29s\n",
      "79:\tlearn: 0.4211797\ttotal: 1m 10s\tremaining: 13m 31s\n",
      "80:\tlearn: 0.4195008\ttotal: 1m 11s\tremaining: 13m 29s\n",
      "81:\tlearn: 0.4181570\ttotal: 1m 12s\tremaining: 13m 27s\n",
      "82:\tlearn: 0.4159992\ttotal: 1m 13s\tremaining: 13m 28s\n",
      "83:\tlearn: 0.4152646\ttotal: 1m 13s\tremaining: 13m 25s\n",
      "84:\tlearn: 0.4137481\ttotal: 1m 14s\tremaining: 13m 26s\n",
      "85:\tlearn: 0.4122705\ttotal: 1m 15s\tremaining: 13m 25s\n",
      "86:\tlearn: 0.4105539\ttotal: 1m 16s\tremaining: 13m 25s\n",
      "87:\tlearn: 0.4087703\ttotal: 1m 17s\tremaining: 13m 25s\n",
      "88:\tlearn: 0.4071992\ttotal: 1m 18s\tremaining: 13m 24s\n",
      "89:\tlearn: 0.4056999\ttotal: 1m 19s\tremaining: 13m 23s\n",
      "90:\tlearn: 0.4048551\ttotal: 1m 20s\tremaining: 13m 19s\n",
      "91:\tlearn: 0.4041583\ttotal: 1m 20s\tremaining: 13m 16s\n",
      "92:\tlearn: 0.4028703\ttotal: 1m 21s\tremaining: 13m 15s\n",
      "93:\tlearn: 0.4012963\ttotal: 1m 22s\tremaining: 13m 14s\n",
      "94:\tlearn: 0.3995847\ttotal: 1m 23s\tremaining: 13m 12s\n",
      "95:\tlearn: 0.3983774\ttotal: 1m 23s\tremaining: 13m 9s\n",
      "96:\tlearn: 0.3973979\ttotal: 1m 24s\tremaining: 13m 6s\n",
      "97:\tlearn: 0.3958761\ttotal: 1m 25s\tremaining: 13m 7s\n",
      "98:\tlearn: 0.3949684\ttotal: 1m 26s\tremaining: 13m 4s\n",
      "99:\tlearn: 0.3933426\ttotal: 1m 26s\tremaining: 13m 2s\n",
      "100:\tlearn: 0.3922402\ttotal: 1m 27s\tremaining: 13m\n",
      "101:\tlearn: 0.3908185\ttotal: 1m 28s\tremaining: 12m 59s\n",
      "102:\tlearn: 0.3899738\ttotal: 1m 29s\tremaining: 12m 57s\n",
      "103:\tlearn: 0.3888838\ttotal: 1m 29s\tremaining: 12m 55s\n",
      "104:\tlearn: 0.3881494\ttotal: 1m 30s\tremaining: 12m 53s\n",
      "105:\tlearn: 0.3868709\ttotal: 1m 31s\tremaining: 12m 52s\n",
      "106:\tlearn: 0.3854395\ttotal: 1m 32s\tremaining: 12m 51s\n",
      "107:\tlearn: 0.3844928\ttotal: 1m 33s\tremaining: 12m 49s\n",
      "108:\tlearn: 0.3830921\ttotal: 1m 33s\tremaining: 12m 47s\n",
      "109:\tlearn: 0.3816516\ttotal: 1m 34s\tremaining: 12m 46s\n",
      "110:\tlearn: 0.3806419\ttotal: 1m 35s\tremaining: 12m 43s\n",
      "111:\tlearn: 0.3793060\ttotal: 1m 36s\tremaining: 12m 41s\n",
      "112:\tlearn: 0.3779903\ttotal: 1m 36s\tremaining: 12m 40s\n",
      "113:\tlearn: 0.3768146\ttotal: 1m 37s\tremaining: 12m 38s\n",
      "114:\tlearn: 0.3760079\ttotal: 1m 38s\tremaining: 12m 37s\n",
      "115:\tlearn: 0.3750684\ttotal: 1m 39s\tremaining: 12m 35s\n",
      "116:\tlearn: 0.3733969\ttotal: 1m 40s\tremaining: 12m 34s\n",
      "117:\tlearn: 0.3718211\ttotal: 1m 40s\tremaining: 12m 34s\n",
      "118:\tlearn: 0.3708467\ttotal: 1m 41s\tremaining: 12m 32s\n",
      "119:\tlearn: 0.3695586\ttotal: 1m 42s\tremaining: 12m 31s\n",
      "120:\tlearn: 0.3688693\ttotal: 1m 43s\tremaining: 12m 28s\n",
      "121:\tlearn: 0.3677992\ttotal: 1m 43s\tremaining: 12m 27s\n",
      "122:\tlearn: 0.3665091\ttotal: 1m 44s\tremaining: 12m 26s\n",
      "123:\tlearn: 0.3654978\ttotal: 1m 45s\tremaining: 12m 25s\n",
      "124:\tlearn: 0.3643034\ttotal: 1m 46s\tremaining: 12m 24s\n",
      "125:\tlearn: 0.3637710\ttotal: 1m 46s\tremaining: 12m 21s\n",
      "126:\tlearn: 0.3628216\ttotal: 1m 47s\tremaining: 12m 20s\n",
      "127:\tlearn: 0.3620407\ttotal: 1m 48s\tremaining: 12m 19s\n",
      "128:\tlearn: 0.3611930\ttotal: 1m 49s\tremaining: 12m 17s\n",
      "129:\tlearn: 0.3603053\ttotal: 1m 49s\tremaining: 12m 16s\n",
      "130:\tlearn: 0.3594961\ttotal: 1m 50s\tremaining: 12m 13s\n",
      "131:\tlearn: 0.3583244\ttotal: 1m 51s\tremaining: 12m 13s\n",
      "132:\tlearn: 0.3573757\ttotal: 1m 52s\tremaining: 12m 11s\n",
      "133:\tlearn: 0.3563052\ttotal: 1m 52s\tremaining: 12m 9s\n",
      "134:\tlearn: 0.3553891\ttotal: 1m 53s\tremaining: 12m 7s\n",
      "135:\tlearn: 0.3544054\ttotal: 1m 54s\tremaining: 12m 7s\n",
      "136:\tlearn: 0.3536180\ttotal: 1m 55s\tremaining: 12m 5s\n",
      "137:\tlearn: 0.3526192\ttotal: 1m 56s\tremaining: 12m 5s\n",
      "138:\tlearn: 0.3515516\ttotal: 1m 56s\tremaining: 12m 4s\n",
      "139:\tlearn: 0.3503771\ttotal: 1m 57s\tremaining: 12m 3s\n",
      "140:\tlearn: 0.3496712\ttotal: 1m 58s\tremaining: 12m 1s\n",
      "141:\tlearn: 0.3489372\ttotal: 1m 59s\tremaining: 11m 59s\n",
      "142:\tlearn: 0.3481137\ttotal: 2m\tremaining: 11m 59s\n",
      "143:\tlearn: 0.3472437\ttotal: 2m\tremaining: 11m 58s\n",
      "144:\tlearn: 0.3466074\ttotal: 2m 1s\tremaining: 11m 57s\n",
      "145:\tlearn: 0.3455872\ttotal: 2m 2s\tremaining: 11m 56s\n",
      "146:\tlearn: 0.3447797\ttotal: 2m 3s\tremaining: 11m 55s\n",
      "147:\tlearn: 0.3431700\ttotal: 2m 4s\tremaining: 11m 55s\n",
      "148:\tlearn: 0.3422649\ttotal: 2m 5s\tremaining: 11m 54s\n",
      "149:\tlearn: 0.3418177\ttotal: 2m 5s\tremaining: 11m 52s\n",
      "150:\tlearn: 0.3410742\ttotal: 2m 6s\tremaining: 11m 51s\n",
      "151:\tlearn: 0.3400884\ttotal: 2m 7s\tremaining: 11m 51s\n",
      "152:\tlearn: 0.3395261\ttotal: 2m 8s\tremaining: 11m 49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153:\tlearn: 0.3385454\ttotal: 2m 8s\tremaining: 11m 48s\n",
      "154:\tlearn: 0.3378440\ttotal: 2m 9s\tremaining: 11m 47s\n",
      "155:\tlearn: 0.3372740\ttotal: 2m 10s\tremaining: 11m 46s\n",
      "156:\tlearn: 0.3366117\ttotal: 2m 11s\tremaining: 11m 44s\n",
      "157:\tlearn: 0.3356362\ttotal: 2m 12s\tremaining: 11m 43s\n",
      "158:\tlearn: 0.3344301\ttotal: 2m 13s\tremaining: 11m 44s\n",
      "159:\tlearn: 0.3336781\ttotal: 2m 13s\tremaining: 11m 43s\n",
      "160:\tlearn: 0.3328945\ttotal: 2m 14s\tremaining: 11m 41s\n",
      "161:\tlearn: 0.3319757\ttotal: 2m 15s\tremaining: 11m 40s\n",
      "162:\tlearn: 0.3308263\ttotal: 2m 16s\tremaining: 11m 39s\n",
      "163:\tlearn: 0.3302614\ttotal: 2m 17s\tremaining: 11m 38s\n",
      "164:\tlearn: 0.3296808\ttotal: 2m 17s\tremaining: 11m 37s\n",
      "165:\tlearn: 0.3288703\ttotal: 2m 18s\tremaining: 11m 36s\n",
      "166:\tlearn: 0.3279671\ttotal: 2m 19s\tremaining: 11m 35s\n",
      "167:\tlearn: 0.3273713\ttotal: 2m 20s\tremaining: 11m 34s\n",
      "168:\tlearn: 0.3267355\ttotal: 2m 20s\tremaining: 11m 33s\n",
      "169:\tlearn: 0.3259737\ttotal: 2m 21s\tremaining: 11m 32s\n",
      "170:\tlearn: 0.3251240\ttotal: 2m 22s\tremaining: 11m 31s\n",
      "171:\tlearn: 0.3242988\ttotal: 2m 23s\tremaining: 11m 30s\n",
      "172:\tlearn: 0.3238475\ttotal: 2m 24s\tremaining: 11m 29s\n",
      "173:\tlearn: 0.3229617\ttotal: 2m 25s\tremaining: 11m 28s\n",
      "174:\tlearn: 0.3220913\ttotal: 2m 25s\tremaining: 11m 28s\n",
      "175:\tlearn: 0.3212333\ttotal: 2m 26s\tremaining: 11m 27s\n",
      "176:\tlearn: 0.3206292\ttotal: 2m 27s\tremaining: 11m 26s\n",
      "177:\tlearn: 0.3198976\ttotal: 2m 28s\tremaining: 11m 25s\n",
      "178:\tlearn: 0.3191922\ttotal: 2m 29s\tremaining: 11m 24s\n",
      "179:\tlearn: 0.3180073\ttotal: 2m 30s\tremaining: 11m 24s\n",
      "180:\tlearn: 0.3171412\ttotal: 2m 30s\tremaining: 11m 23s\n",
      "181:\tlearn: 0.3163297\ttotal: 2m 31s\tremaining: 11m 22s\n",
      "182:\tlearn: 0.3158679\ttotal: 2m 32s\tremaining: 11m 20s\n",
      "183:\tlearn: 0.3148453\ttotal: 2m 33s\tremaining: 11m 19s\n",
      "184:\tlearn: 0.3141835\ttotal: 2m 34s\tremaining: 11m 18s\n",
      "185:\tlearn: 0.3136016\ttotal: 2m 34s\tremaining: 11m 17s\n",
      "186:\tlearn: 0.3130763\ttotal: 2m 35s\tremaining: 11m 17s\n",
      "187:\tlearn: 0.3123942\ttotal: 2m 36s\tremaining: 11m 16s\n",
      "188:\tlearn: 0.3119174\ttotal: 2m 37s\tremaining: 11m 15s\n",
      "189:\tlearn: 0.3112540\ttotal: 2m 38s\tremaining: 11m 14s\n",
      "190:\tlearn: 0.3109612\ttotal: 2m 38s\tremaining: 11m 12s\n",
      "191:\tlearn: 0.3102886\ttotal: 2m 39s\tremaining: 11m 11s\n",
      "192:\tlearn: 0.3097630\ttotal: 2m 40s\tremaining: 11m 10s\n",
      "193:\tlearn: 0.3093309\ttotal: 2m 41s\tremaining: 11m 9s\n",
      "194:\tlearn: 0.3089735\ttotal: 2m 41s\tremaining: 11m 7s\n",
      "195:\tlearn: 0.3080474\ttotal: 2m 42s\tremaining: 11m 7s\n",
      "196:\tlearn: 0.3072203\ttotal: 2m 43s\tremaining: 11m 7s\n",
      "197:\tlearn: 0.3067412\ttotal: 2m 44s\tremaining: 11m 5s\n",
      "198:\tlearn: 0.3061197\ttotal: 2m 45s\tremaining: 11m 4s\n",
      "199:\tlearn: 0.3056223\ttotal: 2m 45s\tremaining: 11m 3s\n",
      "200:\tlearn: 0.3049826\ttotal: 2m 46s\tremaining: 11m 3s\n",
      "201:\tlearn: 0.3042599\ttotal: 2m 47s\tremaining: 11m 2s\n",
      "202:\tlearn: 0.3035800\ttotal: 2m 48s\tremaining: 11m\n",
      "203:\tlearn: 0.3029744\ttotal: 2m 49s\tremaining: 11m\n",
      "204:\tlearn: 0.3027453\ttotal: 2m 49s\tremaining: 10m 58s\n",
      "205:\tlearn: 0.3022495\ttotal: 2m 50s\tremaining: 10m 57s\n",
      "206:\tlearn: 0.3017275\ttotal: 2m 51s\tremaining: 10m 56s\n",
      "207:\tlearn: 0.3009377\ttotal: 2m 52s\tremaining: 10m 55s\n",
      "208:\tlearn: 0.3004489\ttotal: 2m 52s\tremaining: 10m 54s\n",
      "209:\tlearn: 0.3001596\ttotal: 2m 53s\tremaining: 10m 52s\n",
      "210:\tlearn: 0.2997174\ttotal: 2m 54s\tremaining: 10m 51s\n",
      "211:\tlearn: 0.2992355\ttotal: 2m 54s\tremaining: 10m 50s\n",
      "212:\tlearn: 0.2984107\ttotal: 2m 55s\tremaining: 10m 49s\n",
      "213:\tlearn: 0.2978647\ttotal: 2m 56s\tremaining: 10m 48s\n",
      "214:\tlearn: 0.2974274\ttotal: 2m 57s\tremaining: 10m 47s\n",
      "215:\tlearn: 0.2970799\ttotal: 2m 58s\tremaining: 10m 46s\n",
      "216:\tlearn: 0.2966030\ttotal: 2m 58s\tremaining: 10m 44s\n",
      "217:\tlearn: 0.2963236\ttotal: 2m 59s\tremaining: 10m 43s\n",
      "218:\tlearn: 0.2958860\ttotal: 3m\tremaining: 10m 42s\n",
      "219:\tlearn: 0.2954632\ttotal: 3m\tremaining: 10m 40s\n",
      "220:\tlearn: 0.2950821\ttotal: 3m 1s\tremaining: 10m 39s\n",
      "221:\tlearn: 0.2945263\ttotal: 3m 2s\tremaining: 10m 39s\n",
      "222:\tlearn: 0.2941231\ttotal: 3m 3s\tremaining: 10m 37s\n",
      "223:\tlearn: 0.2935627\ttotal: 3m 3s\tremaining: 10m 37s\n",
      "224:\tlearn: 0.2930356\ttotal: 3m 4s\tremaining: 10m 36s\n",
      "225:\tlearn: 0.2924266\ttotal: 3m 5s\tremaining: 10m 35s\n",
      "226:\tlearn: 0.2920046\ttotal: 3m 6s\tremaining: 10m 35s\n",
      "227:\tlearn: 0.2915319\ttotal: 3m 7s\tremaining: 10m 33s\n",
      "228:\tlearn: 0.2913050\ttotal: 3m 7s\tremaining: 10m 32s\n",
      "229:\tlearn: 0.2908072\ttotal: 3m 8s\tremaining: 10m 31s\n",
      "230:\tlearn: 0.2902183\ttotal: 3m 9s\tremaining: 10m 31s\n",
      "231:\tlearn: 0.2897058\ttotal: 3m 10s\tremaining: 10m 30s\n",
      "232:\tlearn: 0.2892083\ttotal: 3m 11s\tremaining: 10m 30s\n",
      "233:\tlearn: 0.2888351\ttotal: 3m 12s\tremaining: 10m 29s\n",
      "234:\tlearn: 0.2885288\ttotal: 3m 12s\tremaining: 10m 27s\n",
      "235:\tlearn: 0.2879848\ttotal: 3m 13s\tremaining: 10m 26s\n",
      "236:\tlearn: 0.2876928\ttotal: 3m 14s\tremaining: 10m 25s\n",
      "237:\tlearn: 0.2872487\ttotal: 3m 15s\tremaining: 10m 24s\n",
      "238:\tlearn: 0.2868611\ttotal: 3m 15s\tremaining: 10m 23s\n",
      "239:\tlearn: 0.2864187\ttotal: 3m 16s\tremaining: 10m 22s\n",
      "240:\tlearn: 0.2859254\ttotal: 3m 17s\tremaining: 10m 21s\n",
      "241:\tlearn: 0.2854807\ttotal: 3m 18s\tremaining: 10m 20s\n",
      "242:\tlearn: 0.2851641\ttotal: 3m 18s\tremaining: 10m 19s\n",
      "243:\tlearn: 0.2846628\ttotal: 3m 19s\tremaining: 10m 18s\n",
      "244:\tlearn: 0.2842023\ttotal: 3m 20s\tremaining: 10m 17s\n",
      "245:\tlearn: 0.2835305\ttotal: 3m 21s\tremaining: 10m 16s\n",
      "246:\tlearn: 0.2831404\ttotal: 3m 21s\tremaining: 10m 15s\n",
      "247:\tlearn: 0.2826833\ttotal: 3m 22s\tremaining: 10m 14s\n",
      "248:\tlearn: 0.2821744\ttotal: 3m 23s\tremaining: 10m 13s\n",
      "249:\tlearn: 0.2817012\ttotal: 3m 24s\tremaining: 10m 12s\n",
      "250:\tlearn: 0.2812214\ttotal: 3m 25s\tremaining: 10m 12s\n",
      "251:\tlearn: 0.2808421\ttotal: 3m 26s\tremaining: 10m 11s\n",
      "252:\tlearn: 0.2804807\ttotal: 3m 26s\tremaining: 10m 11s\n",
      "253:\tlearn: 0.2799797\ttotal: 3m 27s\tremaining: 10m 10s\n",
      "254:\tlearn: 0.2795106\ttotal: 3m 28s\tremaining: 10m 9s\n",
      "255:\tlearn: 0.2790410\ttotal: 3m 29s\tremaining: 10m 8s\n",
      "256:\tlearn: 0.2786687\ttotal: 3m 30s\tremaining: 10m 7s\n",
      "257:\tlearn: 0.2782659\ttotal: 3m 31s\tremaining: 10m 7s\n",
      "258:\tlearn: 0.2779731\ttotal: 3m 31s\tremaining: 10m 6s\n",
      "259:\tlearn: 0.2775075\ttotal: 3m 32s\tremaining: 10m 5s\n",
      "260:\tlearn: 0.2773011\ttotal: 3m 33s\tremaining: 10m 4s\n",
      "261:\tlearn: 0.2768482\ttotal: 3m 34s\tremaining: 10m 3s\n",
      "262:\tlearn: 0.2765209\ttotal: 3m 35s\tremaining: 10m 2s\n",
      "263:\tlearn: 0.2761955\ttotal: 3m 35s\tremaining: 10m 2s\n",
      "264:\tlearn: 0.2758037\ttotal: 3m 36s\tremaining: 10m\n",
      "265:\tlearn: 0.2755776\ttotal: 3m 37s\tremaining: 9m 59s\n",
      "266:\tlearn: 0.2750907\ttotal: 3m 37s\tremaining: 9m 58s\n",
      "267:\tlearn: 0.2744941\ttotal: 3m 38s\tremaining: 9m 57s\n",
      "268:\tlearn: 0.2741633\ttotal: 3m 39s\tremaining: 9m 57s\n",
      "269:\tlearn: 0.2737891\ttotal: 3m 40s\tremaining: 9m 56s\n",
      "270:\tlearn: 0.2732667\ttotal: 3m 41s\tremaining: 9m 55s\n",
      "271:\tlearn: 0.2729754\ttotal: 3m 42s\tremaining: 9m 55s\n",
      "272:\tlearn: 0.2727149\ttotal: 3m 43s\tremaining: 9m 54s\n",
      "273:\tlearn: 0.2723922\ttotal: 3m 43s\tremaining: 9m 53s\n",
      "274:\tlearn: 0.2720115\ttotal: 3m 44s\tremaining: 9m 52s\n",
      "275:\tlearn: 0.2716536\ttotal: 3m 45s\tremaining: 9m 51s\n",
      "276:\tlearn: 0.2712114\ttotal: 3m 46s\tremaining: 9m 50s\n",
      "277:\tlearn: 0.2709662\ttotal: 3m 46s\tremaining: 9m 49s\n",
      "278:\tlearn: 0.2705912\ttotal: 3m 47s\tremaining: 9m 48s\n",
      "279:\tlearn: 0.2702197\ttotal: 3m 48s\tremaining: 9m 47s\n",
      "280:\tlearn: 0.2697142\ttotal: 3m 49s\tremaining: 9m 46s\n",
      "281:\tlearn: 0.2694080\ttotal: 3m 50s\tremaining: 9m 46s\n",
      "282:\tlearn: 0.2689954\ttotal: 3m 50s\tremaining: 9m 45s\n",
      "283:\tlearn: 0.2687250\ttotal: 3m 51s\tremaining: 9m 44s\n",
      "284:\tlearn: 0.2683639\ttotal: 3m 52s\tremaining: 9m 43s\n",
      "285:\tlearn: 0.2680035\ttotal: 3m 53s\tremaining: 9m 42s\n",
      "286:\tlearn: 0.2676340\ttotal: 3m 54s\tremaining: 9m 41s\n",
      "287:\tlearn: 0.2672590\ttotal: 3m 54s\tremaining: 9m 40s\n",
      "288:\tlearn: 0.2668886\ttotal: 3m 55s\tremaining: 9m 39s\n",
      "289:\tlearn: 0.2666041\ttotal: 3m 56s\tremaining: 9m 38s\n",
      "290:\tlearn: 0.2662955\ttotal: 3m 57s\tremaining: 9m 38s\n",
      "291:\tlearn: 0.2660027\ttotal: 3m 58s\tremaining: 9m 37s\n",
      "292:\tlearn: 0.2657275\ttotal: 3m 59s\tremaining: 9m 37s\n",
      "293:\tlearn: 0.2653179\ttotal: 4m\tremaining: 9m 36s\n",
      "294:\tlearn: 0.2650167\ttotal: 4m\tremaining: 9m 35s\n",
      "295:\tlearn: 0.2646292\ttotal: 4m 1s\tremaining: 9m 34s\n",
      "296:\tlearn: 0.2642430\ttotal: 4m 2s\tremaining: 9m 34s\n",
      "297:\tlearn: 0.2639922\ttotal: 4m 3s\tremaining: 9m 33s\n",
      "298:\tlearn: 0.2636249\ttotal: 4m 4s\tremaining: 9m 32s\n",
      "299:\tlearn: 0.2631763\ttotal: 4m 4s\tremaining: 9m 31s\n",
      "300:\tlearn: 0.2626611\ttotal: 4m 5s\tremaining: 9m 30s\n",
      "301:\tlearn: 0.2622943\ttotal: 4m 6s\tremaining: 9m 29s\n",
      "302:\tlearn: 0.2619714\ttotal: 4m 7s\tremaining: 9m 28s\n",
      "303:\tlearn: 0.2617015\ttotal: 4m 7s\tremaining: 9m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304:\tlearn: 0.2612132\ttotal: 4m 8s\tremaining: 9m 26s\n",
      "305:\tlearn: 0.2609335\ttotal: 4m 9s\tremaining: 9m 25s\n",
      "306:\tlearn: 0.2605591\ttotal: 4m 10s\tremaining: 9m 25s\n",
      "307:\tlearn: 0.2603098\ttotal: 4m 11s\tremaining: 9m 24s\n",
      "308:\tlearn: 0.2600998\ttotal: 4m 11s\tremaining: 9m 22s\n",
      "309:\tlearn: 0.2597246\ttotal: 4m 12s\tremaining: 9m 21s\n",
      "310:\tlearn: 0.2595101\ttotal: 4m 13s\tremaining: 9m 20s\n",
      "311:\tlearn: 0.2592779\ttotal: 4m 13s\tremaining: 9m 19s\n",
      "312:\tlearn: 0.2590175\ttotal: 4m 14s\tremaining: 9m 18s\n",
      "313:\tlearn: 0.2587743\ttotal: 4m 15s\tremaining: 9m 17s\n",
      "314:\tlearn: 0.2584909\ttotal: 4m 16s\tremaining: 9m 16s\n",
      "315:\tlearn: 0.2581496\ttotal: 4m 16s\tremaining: 9m 15s\n",
      "316:\tlearn: 0.2578179\ttotal: 4m 17s\tremaining: 9m 15s\n",
      "317:\tlearn: 0.2575419\ttotal: 4m 18s\tremaining: 9m 14s\n",
      "318:\tlearn: 0.2572485\ttotal: 4m 19s\tremaining: 9m 13s\n",
      "319:\tlearn: 0.2570197\ttotal: 4m 19s\tremaining: 9m 12s\n",
      "320:\tlearn: 0.2566279\ttotal: 4m 20s\tremaining: 9m 11s\n",
      "321:\tlearn: 0.2564616\ttotal: 4m 21s\tremaining: 9m 10s\n",
      "322:\tlearn: 0.2561569\ttotal: 4m 22s\tremaining: 9m 9s\n",
      "323:\tlearn: 0.2558876\ttotal: 4m 23s\tremaining: 9m 9s\n",
      "324:\tlearn: 0.2555823\ttotal: 4m 23s\tremaining: 9m 8s\n",
      "325:\tlearn: 0.2553782\ttotal: 4m 24s\tremaining: 9m 6s\n",
      "326:\tlearn: 0.2549198\ttotal: 4m 25s\tremaining: 9m 6s\n",
      "327:\tlearn: 0.2547484\ttotal: 4m 26s\tremaining: 9m 5s\n",
      "328:\tlearn: 0.2545629\ttotal: 4m 27s\tremaining: 9m 4s\n",
      "329:\tlearn: 0.2542904\ttotal: 4m 27s\tremaining: 9m 3s\n",
      "330:\tlearn: 0.2540570\ttotal: 4m 28s\tremaining: 9m 2s\n",
      "331:\tlearn: 0.2536979\ttotal: 4m 29s\tremaining: 9m 1s\n",
      "332:\tlearn: 0.2533966\ttotal: 4m 30s\tremaining: 9m\n",
      "333:\tlearn: 0.2531045\ttotal: 4m 30s\tremaining: 9m\n",
      "334:\tlearn: 0.2528701\ttotal: 4m 31s\tremaining: 8m 59s\n",
      "335:\tlearn: 0.2526950\ttotal: 4m 32s\tremaining: 8m 58s\n",
      "336:\tlearn: 0.2524492\ttotal: 4m 33s\tremaining: 8m 57s\n",
      "337:\tlearn: 0.2521599\ttotal: 4m 34s\tremaining: 8m 56s\n",
      "338:\tlearn: 0.2519822\ttotal: 4m 34s\tremaining: 8m 55s\n",
      "339:\tlearn: 0.2517212\ttotal: 4m 35s\tremaining: 8m 55s\n",
      "340:\tlearn: 0.2513002\ttotal: 4m 36s\tremaining: 8m 54s\n",
      "341:\tlearn: 0.2511048\ttotal: 4m 37s\tremaining: 8m 53s\n",
      "342:\tlearn: 0.2508345\ttotal: 4m 38s\tremaining: 8m 52s\n",
      "343:\tlearn: 0.2505686\ttotal: 4m 38s\tremaining: 8m 51s\n",
      "344:\tlearn: 0.2501331\ttotal: 4m 39s\tremaining: 8m 51s\n",
      "345:\tlearn: 0.2498630\ttotal: 4m 40s\tremaining: 8m 50s\n",
      "346:\tlearn: 0.2496749\ttotal: 4m 41s\tremaining: 8m 49s\n",
      "347:\tlearn: 0.2494338\ttotal: 4m 42s\tremaining: 8m 48s\n",
      "348:\tlearn: 0.2492408\ttotal: 4m 43s\tremaining: 8m 48s\n",
      "349:\tlearn: 0.2489866\ttotal: 4m 44s\tremaining: 8m 47s\n",
      "350:\tlearn: 0.2486458\ttotal: 4m 44s\tremaining: 8m 46s\n",
      "351:\tlearn: 0.2483886\ttotal: 4m 45s\tremaining: 8m 45s\n",
      "352:\tlearn: 0.2479727\ttotal: 4m 46s\tremaining: 8m 45s\n",
      "353:\tlearn: 0.2477831\ttotal: 4m 47s\tremaining: 8m 44s\n",
      "354:\tlearn: 0.2476158\ttotal: 4m 48s\tremaining: 8m 43s\n",
      "355:\tlearn: 0.2474655\ttotal: 4m 48s\tremaining: 8m 42s\n",
      "356:\tlearn: 0.2470606\ttotal: 4m 49s\tremaining: 8m 41s\n",
      "357:\tlearn: 0.2467826\ttotal: 4m 50s\tremaining: 8m 40s\n",
      "358:\tlearn: 0.2464875\ttotal: 4m 51s\tremaining: 8m 40s\n",
      "359:\tlearn: 0.2462215\ttotal: 4m 51s\tremaining: 8m 39s\n",
      "360:\tlearn: 0.2460248\ttotal: 4m 52s\tremaining: 8m 38s\n",
      "361:\tlearn: 0.2458368\ttotal: 4m 53s\tremaining: 8m 37s\n",
      "362:\tlearn: 0.2455027\ttotal: 4m 54s\tremaining: 8m 36s\n",
      "363:\tlearn: 0.2453330\ttotal: 4m 55s\tremaining: 8m 35s\n",
      "364:\tlearn: 0.2451420\ttotal: 4m 55s\tremaining: 8m 34s\n",
      "365:\tlearn: 0.2448919\ttotal: 4m 56s\tremaining: 8m 33s\n",
      "366:\tlearn: 0.2447338\ttotal: 4m 57s\tremaining: 8m 32s\n",
      "367:\tlearn: 0.2445682\ttotal: 4m 57s\tremaining: 8m 31s\n",
      "368:\tlearn: 0.2443573\ttotal: 4m 58s\tremaining: 8m 30s\n",
      "369:\tlearn: 0.2441568\ttotal: 4m 59s\tremaining: 8m 29s\n",
      "370:\tlearn: 0.2438168\ttotal: 5m\tremaining: 8m 28s\n",
      "371:\tlearn: 0.2436874\ttotal: 5m\tremaining: 8m 27s\n",
      "372:\tlearn: 0.2434789\ttotal: 5m 1s\tremaining: 8m 26s\n",
      "373:\tlearn: 0.2432342\ttotal: 5m 2s\tremaining: 8m 25s\n",
      "374:\tlearn: 0.2429016\ttotal: 5m 3s\tremaining: 8m 25s\n",
      "375:\tlearn: 0.2425938\ttotal: 5m 3s\tremaining: 8m 24s\n",
      "376:\tlearn: 0.2423195\ttotal: 5m 4s\tremaining: 8m 23s\n",
      "377:\tlearn: 0.2420404\ttotal: 5m 5s\tremaining: 8m 22s\n",
      "378:\tlearn: 0.2419053\ttotal: 5m 6s\tremaining: 8m 21s\n",
      "379:\tlearn: 0.2417481\ttotal: 5m 6s\tremaining: 8m 20s\n",
      "380:\tlearn: 0.2415260\ttotal: 5m 7s\tremaining: 8m 19s\n",
      "381:\tlearn: 0.2412691\ttotal: 5m 8s\tremaining: 8m 19s\n",
      "382:\tlearn: 0.2410819\ttotal: 5m 9s\tremaining: 8m 18s\n",
      "383:\tlearn: 0.2408244\ttotal: 5m 10s\tremaining: 8m 17s\n",
      "384:\tlearn: 0.2405328\ttotal: 5m 11s\tremaining: 8m 16s\n",
      "385:\tlearn: 0.2402300\ttotal: 5m 11s\tremaining: 8m 16s\n",
      "386:\tlearn: 0.2400173\ttotal: 5m 12s\tremaining: 8m 15s\n",
      "387:\tlearn: 0.2398759\ttotal: 5m 13s\tremaining: 8m 14s\n",
      "388:\tlearn: 0.2396075\ttotal: 5m 14s\tremaining: 8m 13s\n",
      "389:\tlearn: 0.2393051\ttotal: 5m 15s\tremaining: 8m 12s\n",
      "390:\tlearn: 0.2391322\ttotal: 5m 15s\tremaining: 8m 11s\n",
      "391:\tlearn: 0.2389147\ttotal: 5m 16s\tremaining: 8m 11s\n",
      "392:\tlearn: 0.2386667\ttotal: 5m 17s\tremaining: 8m 10s\n",
      "393:\tlearn: 0.2383131\ttotal: 5m 18s\tremaining: 8m 9s\n",
      "394:\tlearn: 0.2379925\ttotal: 5m 18s\tremaining: 8m 8s\n",
      "395:\tlearn: 0.2377798\ttotal: 5m 19s\tremaining: 8m 7s\n",
      "396:\tlearn: 0.2375861\ttotal: 5m 20s\tremaining: 8m 6s\n",
      "397:\tlearn: 0.2372982\ttotal: 5m 21s\tremaining: 8m 6s\n",
      "398:\tlearn: 0.2371072\ttotal: 5m 22s\tremaining: 8m 5s\n",
      "399:\tlearn: 0.2368999\ttotal: 5m 23s\tremaining: 8m 4s\n",
      "400:\tlearn: 0.2366671\ttotal: 5m 24s\tremaining: 8m 4s\n",
      "401:\tlearn: 0.2363134\ttotal: 5m 25s\tremaining: 8m 3s\n",
      "402:\tlearn: 0.2360645\ttotal: 5m 25s\tremaining: 8m 2s\n",
      "403:\tlearn: 0.2357295\ttotal: 5m 26s\tremaining: 8m 2s\n",
      "404:\tlearn: 0.2353784\ttotal: 5m 27s\tremaining: 8m 1s\n",
      "405:\tlearn: 0.2352448\ttotal: 5m 28s\tremaining: 8m\n",
      "406:\tlearn: 0.2349633\ttotal: 5m 29s\tremaining: 7m 59s\n",
      "407:\tlearn: 0.2347549\ttotal: 5m 29s\tremaining: 7m 58s\n",
      "408:\tlearn: 0.2345261\ttotal: 5m 30s\tremaining: 7m 57s\n",
      "409:\tlearn: 0.2343706\ttotal: 5m 31s\tremaining: 7m 57s\n",
      "410:\tlearn: 0.2340968\ttotal: 5m 32s\tremaining: 7m 56s\n",
      "411:\tlearn: 0.2338172\ttotal: 5m 33s\tremaining: 7m 55s\n",
      "412:\tlearn: 0.2336377\ttotal: 5m 33s\tremaining: 7m 54s\n",
      "413:\tlearn: 0.2334803\ttotal: 5m 34s\tremaining: 7m 53s\n",
      "414:\tlearn: 0.2332904\ttotal: 5m 35s\tremaining: 7m 52s\n",
      "415:\tlearn: 0.2329433\ttotal: 5m 36s\tremaining: 7m 52s\n",
      "416:\tlearn: 0.2328144\ttotal: 5m 37s\tremaining: 7m 51s\n",
      "417:\tlearn: 0.2326603\ttotal: 5m 37s\tremaining: 7m 50s\n",
      "418:\tlearn: 0.2325243\ttotal: 5m 38s\tremaining: 7m 49s\n",
      "419:\tlearn: 0.2322278\ttotal: 5m 39s\tremaining: 7m 48s\n",
      "420:\tlearn: 0.2320159\ttotal: 5m 40s\tremaining: 7m 47s\n",
      "421:\tlearn: 0.2318430\ttotal: 5m 41s\tremaining: 7m 47s\n",
      "422:\tlearn: 0.2314771\ttotal: 5m 42s\tremaining: 7m 46s\n",
      "423:\tlearn: 0.2312947\ttotal: 5m 43s\tremaining: 7m 45s\n",
      "424:\tlearn: 0.2311306\ttotal: 5m 43s\tremaining: 7m 45s\n",
      "425:\tlearn: 0.2307728\ttotal: 5m 44s\tremaining: 7m 44s\n",
      "426:\tlearn: 0.2304604\ttotal: 5m 45s\tremaining: 7m 43s\n",
      "427:\tlearn: 0.2302774\ttotal: 5m 46s\tremaining: 7m 43s\n",
      "428:\tlearn: 0.2299993\ttotal: 5m 47s\tremaining: 7m 42s\n",
      "429:\tlearn: 0.2297693\ttotal: 5m 48s\tremaining: 7m 41s\n",
      "430:\tlearn: 0.2295740\ttotal: 5m 49s\tremaining: 7m 40s\n",
      "431:\tlearn: 0.2293730\ttotal: 5m 49s\tremaining: 7m 40s\n",
      "432:\tlearn: 0.2291305\ttotal: 5m 50s\tremaining: 7m 39s\n",
      "433:\tlearn: 0.2289549\ttotal: 5m 51s\tremaining: 7m 38s\n",
      "434:\tlearn: 0.2288338\ttotal: 5m 52s\tremaining: 7m 37s\n",
      "435:\tlearn: 0.2286841\ttotal: 5m 52s\tremaining: 7m 36s\n",
      "436:\tlearn: 0.2284706\ttotal: 5m 53s\tremaining: 7m 36s\n",
      "437:\tlearn: 0.2283026\ttotal: 5m 54s\tremaining: 7m 35s\n",
      "438:\tlearn: 0.2281369\ttotal: 5m 55s\tremaining: 7m 34s\n",
      "439:\tlearn: 0.2279613\ttotal: 5m 56s\tremaining: 7m 33s\n",
      "440:\tlearn: 0.2276801\ttotal: 5m 57s\tremaining: 7m 33s\n",
      "441:\tlearn: 0.2274266\ttotal: 5m 58s\tremaining: 7m 32s\n",
      "442:\tlearn: 0.2272221\ttotal: 5m 59s\tremaining: 7m 31s\n",
      "443:\tlearn: 0.2270893\ttotal: 5m 59s\tremaining: 7m 30s\n",
      "444:\tlearn: 0.2269754\ttotal: 6m\tremaining: 7m 29s\n",
      "445:\tlearn: 0.2266312\ttotal: 6m 1s\tremaining: 7m 29s\n",
      "446:\tlearn: 0.2264490\ttotal: 6m 2s\tremaining: 7m 28s\n",
      "447:\tlearn: 0.2262583\ttotal: 6m 3s\tremaining: 7m 27s\n",
      "448:\tlearn: 0.2259821\ttotal: 6m 3s\tremaining: 7m 26s\n",
      "449:\tlearn: 0.2258339\ttotal: 6m 4s\tremaining: 7m 25s\n",
      "450:\tlearn: 0.2257150\ttotal: 6m 5s\tremaining: 7m 24s\n",
      "451:\tlearn: 0.2255203\ttotal: 6m 6s\tremaining: 7m 23s\n",
      "452:\tlearn: 0.2252703\ttotal: 6m 7s\tremaining: 7m 23s\n",
      "453:\tlearn: 0.2251022\ttotal: 6m 8s\tremaining: 7m 22s\n",
      "454:\tlearn: 0.2249053\ttotal: 6m 9s\tremaining: 7m 22s\n",
      "455:\tlearn: 0.2246389\ttotal: 6m 9s\tremaining: 7m 21s\n",
      "456:\tlearn: 0.2245341\ttotal: 6m 10s\tremaining: 7m 20s\n",
      "457:\tlearn: 0.2243387\ttotal: 6m 11s\tremaining: 7m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458:\tlearn: 0.2242265\ttotal: 6m 12s\tremaining: 7m 18s\n",
      "459:\tlearn: 0.2240415\ttotal: 6m 12s\tremaining: 7m 17s\n",
      "460:\tlearn: 0.2238366\ttotal: 6m 13s\tremaining: 7m 17s\n",
      "461:\tlearn: 0.2237528\ttotal: 6m 14s\tremaining: 7m 16s\n",
      "462:\tlearn: 0.2236078\ttotal: 6m 15s\tremaining: 7m 15s\n",
      "463:\tlearn: 0.2234044\ttotal: 6m 16s\tremaining: 7m 14s\n",
      "464:\tlearn: 0.2233001\ttotal: 6m 17s\tremaining: 7m 13s\n",
      "465:\tlearn: 0.2230743\ttotal: 6m 18s\tremaining: 7m 13s\n",
      "466:\tlearn: 0.2229047\ttotal: 6m 18s\tremaining: 7m 12s\n",
      "467:\tlearn: 0.2227543\ttotal: 6m 19s\tremaining: 7m 11s\n",
      "468:\tlearn: 0.2226325\ttotal: 6m 20s\tremaining: 7m 10s\n",
      "469:\tlearn: 0.2224755\ttotal: 6m 21s\tremaining: 7m 9s\n",
      "470:\tlearn: 0.2222896\ttotal: 6m 21s\tremaining: 7m 8s\n",
      "471:\tlearn: 0.2220954\ttotal: 6m 22s\tremaining: 7m 7s\n",
      "472:\tlearn: 0.2218741\ttotal: 6m 23s\tremaining: 7m 7s\n",
      "473:\tlearn: 0.2216935\ttotal: 6m 24s\tremaining: 7m 6s\n",
      "474:\tlearn: 0.2216083\ttotal: 6m 24s\tremaining: 7m 5s\n",
      "475:\tlearn: 0.2214456\ttotal: 6m 25s\tremaining: 7m 4s\n",
      "476:\tlearn: 0.2213598\ttotal: 6m 26s\tremaining: 7m 3s\n",
      "477:\tlearn: 0.2211115\ttotal: 6m 26s\tremaining: 7m 2s\n",
      "478:\tlearn: 0.2209415\ttotal: 6m 27s\tremaining: 7m 1s\n",
      "479:\tlearn: 0.2207763\ttotal: 6m 28s\tremaining: 7m\n",
      "480:\tlearn: 0.2205447\ttotal: 6m 29s\tremaining: 7m\n",
      "481:\tlearn: 0.2202882\ttotal: 6m 30s\tremaining: 6m 59s\n",
      "482:\tlearn: 0.2200799\ttotal: 6m 31s\tremaining: 6m 58s\n",
      "483:\tlearn: 0.2197706\ttotal: 6m 32s\tremaining: 6m 58s\n",
      "484:\tlearn: 0.2195817\ttotal: 6m 33s\tremaining: 6m 57s\n",
      "485:\tlearn: 0.2194408\ttotal: 6m 33s\tremaining: 6m 56s\n",
      "486:\tlearn: 0.2191651\ttotal: 6m 34s\tremaining: 6m 55s\n",
      "487:\tlearn: 0.2190251\ttotal: 6m 35s\tremaining: 6m 55s\n",
      "488:\tlearn: 0.2188797\ttotal: 6m 36s\tremaining: 6m 54s\n",
      "489:\tlearn: 0.2187246\ttotal: 6m 37s\tremaining: 6m 53s\n",
      "490:\tlearn: 0.2185194\ttotal: 6m 38s\tremaining: 6m 52s\n",
      "491:\tlearn: 0.2184061\ttotal: 6m 39s\tremaining: 6m 52s\n",
      "492:\tlearn: 0.2182691\ttotal: 6m 39s\tremaining: 6m 51s\n",
      "493:\tlearn: 0.2180935\ttotal: 6m 40s\tremaining: 6m 50s\n",
      "494:\tlearn: 0.2179436\ttotal: 6m 41s\tremaining: 6m 49s\n",
      "495:\tlearn: 0.2176583\ttotal: 6m 42s\tremaining: 6m 48s\n",
      "496:\tlearn: 0.2173777\ttotal: 6m 43s\tremaining: 6m 48s\n",
      "497:\tlearn: 0.2171950\ttotal: 6m 44s\tremaining: 6m 47s\n",
      "498:\tlearn: 0.2170164\ttotal: 6m 45s\tremaining: 6m 46s\n",
      "499:\tlearn: 0.2168730\ttotal: 6m 45s\tremaining: 6m 45s\n",
      "500:\tlearn: 0.2167166\ttotal: 6m 46s\tremaining: 6m 44s\n",
      "501:\tlearn: 0.2165923\ttotal: 6m 47s\tremaining: 6m 44s\n",
      "502:\tlearn: 0.2164640\ttotal: 6m 48s\tremaining: 6m 43s\n",
      "503:\tlearn: 0.2163923\ttotal: 6m 48s\tremaining: 6m 42s\n",
      "504:\tlearn: 0.2161801\ttotal: 6m 49s\tremaining: 6m 41s\n",
      "505:\tlearn: 0.2160471\ttotal: 6m 50s\tremaining: 6m 41s\n",
      "506:\tlearn: 0.2158627\ttotal: 6m 51s\tremaining: 6m 40s\n",
      "507:\tlearn: 0.2156741\ttotal: 6m 52s\tremaining: 6m 39s\n",
      "508:\tlearn: 0.2155981\ttotal: 6m 53s\tremaining: 6m 38s\n",
      "509:\tlearn: 0.2152869\ttotal: 6m 54s\tremaining: 6m 37s\n",
      "510:\tlearn: 0.2151164\ttotal: 6m 54s\tremaining: 6m 37s\n",
      "511:\tlearn: 0.2149608\ttotal: 6m 55s\tremaining: 6m 36s\n",
      "512:\tlearn: 0.2147898\ttotal: 6m 56s\tremaining: 6m 35s\n",
      "513:\tlearn: 0.2146432\ttotal: 6m 57s\tremaining: 6m 34s\n",
      "514:\tlearn: 0.2144848\ttotal: 6m 58s\tremaining: 6m 33s\n",
      "515:\tlearn: 0.2143968\ttotal: 6m 58s\tremaining: 6m 32s\n",
      "516:\tlearn: 0.2142306\ttotal: 6m 59s\tremaining: 6m 31s\n",
      "517:\tlearn: 0.2140836\ttotal: 7m\tremaining: 6m 31s\n",
      "518:\tlearn: 0.2139442\ttotal: 7m 1s\tremaining: 6m 30s\n",
      "519:\tlearn: 0.2137349\ttotal: 7m 2s\tremaining: 6m 29s\n",
      "520:\tlearn: 0.2135784\ttotal: 7m 3s\tremaining: 6m 29s\n",
      "521:\tlearn: 0.2133794\ttotal: 7m 4s\tremaining: 6m 28s\n",
      "522:\tlearn: 0.2131451\ttotal: 7m 4s\tremaining: 6m 27s\n",
      "523:\tlearn: 0.2130079\ttotal: 7m 5s\tremaining: 6m 26s\n",
      "524:\tlearn: 0.2127549\ttotal: 7m 6s\tremaining: 6m 26s\n",
      "525:\tlearn: 0.2125505\ttotal: 7m 7s\tremaining: 6m 25s\n",
      "526:\tlearn: 0.2123443\ttotal: 7m 8s\tremaining: 6m 24s\n",
      "527:\tlearn: 0.2121575\ttotal: 7m 9s\tremaining: 6m 23s\n",
      "528:\tlearn: 0.2120572\ttotal: 7m 10s\tremaining: 6m 23s\n",
      "529:\tlearn: 0.2119314\ttotal: 7m 11s\tremaining: 6m 22s\n",
      "530:\tlearn: 0.2118156\ttotal: 7m 11s\tremaining: 6m 21s\n",
      "531:\tlearn: 0.2116754\ttotal: 7m 12s\tremaining: 6m 20s\n",
      "532:\tlearn: 0.2115564\ttotal: 7m 13s\tremaining: 6m 19s\n",
      "533:\tlearn: 0.2113415\ttotal: 7m 14s\tremaining: 6m 18s\n",
      "534:\tlearn: 0.2111203\ttotal: 7m 15s\tremaining: 6m 18s\n",
      "535:\tlearn: 0.2109469\ttotal: 7m 16s\tremaining: 6m 17s\n",
      "536:\tlearn: 0.2107672\ttotal: 7m 16s\tremaining: 6m 16s\n",
      "537:\tlearn: 0.2106587\ttotal: 7m 17s\tremaining: 6m 15s\n",
      "538:\tlearn: 0.2105451\ttotal: 7m 18s\tremaining: 6m 15s\n",
      "539:\tlearn: 0.2104304\ttotal: 7m 19s\tremaining: 6m 14s\n",
      "540:\tlearn: 0.2102592\ttotal: 7m 20s\tremaining: 6m 13s\n",
      "541:\tlearn: 0.2100994\ttotal: 7m 21s\tremaining: 6m 12s\n",
      "542:\tlearn: 0.2099906\ttotal: 7m 21s\tremaining: 6m 11s\n",
      "543:\tlearn: 0.2098351\ttotal: 7m 22s\tremaining: 6m 10s\n",
      "544:\tlearn: 0.2096416\ttotal: 7m 23s\tremaining: 6m 10s\n",
      "545:\tlearn: 0.2094365\ttotal: 7m 24s\tremaining: 6m 9s\n",
      "546:\tlearn: 0.2093546\ttotal: 7m 25s\tremaining: 6m 8s\n",
      "547:\tlearn: 0.2092197\ttotal: 7m 26s\tremaining: 6m 7s\n",
      "548:\tlearn: 0.2091304\ttotal: 7m 26s\tremaining: 6m 6s\n",
      "549:\tlearn: 0.2089079\ttotal: 7m 27s\tremaining: 6m 6s\n",
      "550:\tlearn: 0.2087084\ttotal: 7m 28s\tremaining: 6m 5s\n",
      "551:\tlearn: 0.2085975\ttotal: 7m 29s\tremaining: 6m 4s\n",
      "552:\tlearn: 0.2085070\ttotal: 7m 30s\tremaining: 6m 4s\n",
      "553:\tlearn: 0.2082946\ttotal: 7m 31s\tremaining: 6m 3s\n",
      "554:\tlearn: 0.2081734\ttotal: 7m 31s\tremaining: 6m 2s\n",
      "555:\tlearn: 0.2080700\ttotal: 7m 32s\tremaining: 6m 1s\n",
      "556:\tlearn: 0.2078430\ttotal: 7m 33s\tremaining: 6m\n",
      "557:\tlearn: 0.2076874\ttotal: 7m 34s\tremaining: 6m\n",
      "558:\tlearn: 0.2074995\ttotal: 7m 35s\tremaining: 5m 59s\n",
      "559:\tlearn: 0.2073770\ttotal: 7m 36s\tremaining: 5m 58s\n",
      "560:\tlearn: 0.2072217\ttotal: 7m 36s\tremaining: 5m 57s\n",
      "561:\tlearn: 0.2070955\ttotal: 7m 37s\tremaining: 5m 56s\n",
      "562:\tlearn: 0.2069851\ttotal: 7m 38s\tremaining: 5m 55s\n",
      "563:\tlearn: 0.2067909\ttotal: 7m 39s\tremaining: 5m 55s\n",
      "564:\tlearn: 0.2065959\ttotal: 7m 40s\tremaining: 5m 54s\n",
      "565:\tlearn: 0.2063854\ttotal: 7m 41s\tremaining: 5m 53s\n",
      "566:\tlearn: 0.2062397\ttotal: 7m 42s\tremaining: 5m 52s\n",
      "567:\tlearn: 0.2060927\ttotal: 7m 42s\tremaining: 5m 52s\n",
      "568:\tlearn: 0.2059515\ttotal: 7m 43s\tremaining: 5m 51s\n",
      "569:\tlearn: 0.2058351\ttotal: 7m 44s\tremaining: 5m 50s\n",
      "570:\tlearn: 0.2056898\ttotal: 7m 45s\tremaining: 5m 49s\n",
      "571:\tlearn: 0.2056063\ttotal: 7m 46s\tremaining: 5m 48s\n",
      "572:\tlearn: 0.2055121\ttotal: 7m 46s\tremaining: 5m 47s\n",
      "573:\tlearn: 0.2052667\ttotal: 7m 47s\tremaining: 5m 47s\n",
      "574:\tlearn: 0.2051735\ttotal: 7m 48s\tremaining: 5m 46s\n",
      "575:\tlearn: 0.2050962\ttotal: 7m 49s\tremaining: 5m 45s\n",
      "576:\tlearn: 0.2049771\ttotal: 7m 49s\tremaining: 5m 44s\n",
      "577:\tlearn: 0.2048327\ttotal: 7m 50s\tremaining: 5m 43s\n",
      "578:\tlearn: 0.2046567\ttotal: 7m 51s\tremaining: 5m 42s\n",
      "579:\tlearn: 0.2045316\ttotal: 7m 52s\tremaining: 5m 41s\n",
      "580:\tlearn: 0.2043552\ttotal: 7m 53s\tremaining: 5m 41s\n",
      "581:\tlearn: 0.2042374\ttotal: 7m 54s\tremaining: 5m 40s\n",
      "582:\tlearn: 0.2041357\ttotal: 7m 54s\tremaining: 5m 39s\n",
      "583:\tlearn: 0.2040022\ttotal: 7m 55s\tremaining: 5m 38s\n",
      "584:\tlearn: 0.2039141\ttotal: 7m 56s\tremaining: 5m 38s\n",
      "585:\tlearn: 0.2037483\ttotal: 7m 57s\tremaining: 5m 37s\n",
      "586:\tlearn: 0.2035458\ttotal: 7m 58s\tremaining: 5m 36s\n",
      "587:\tlearn: 0.2033853\ttotal: 7m 59s\tremaining: 5m 35s\n",
      "588:\tlearn: 0.2032999\ttotal: 8m\tremaining: 5m 34s\n",
      "589:\tlearn: 0.2031571\ttotal: 8m 1s\tremaining: 5m 34s\n",
      "590:\tlearn: 0.2030562\ttotal: 8m 1s\tremaining: 5m 33s\n",
      "591:\tlearn: 0.2029204\ttotal: 8m 2s\tremaining: 5m 32s\n",
      "592:\tlearn: 0.2027514\ttotal: 8m 3s\tremaining: 5m 31s\n",
      "593:\tlearn: 0.2026572\ttotal: 8m 4s\tremaining: 5m 31s\n",
      "594:\tlearn: 0.2025966\ttotal: 8m 5s\tremaining: 5m 30s\n",
      "595:\tlearn: 0.2024584\ttotal: 8m 5s\tremaining: 5m 29s\n",
      "596:\tlearn: 0.2023595\ttotal: 8m 6s\tremaining: 5m 28s\n",
      "597:\tlearn: 0.2022171\ttotal: 8m 7s\tremaining: 5m 27s\n",
      "598:\tlearn: 0.2020121\ttotal: 8m 8s\tremaining: 5m 27s\n",
      "599:\tlearn: 0.2018387\ttotal: 8m 9s\tremaining: 5m 26s\n",
      "600:\tlearn: 0.2016999\ttotal: 8m 10s\tremaining: 5m 25s\n",
      "601:\tlearn: 0.2015800\ttotal: 8m 11s\tremaining: 5m 24s\n",
      "602:\tlearn: 0.2014746\ttotal: 8m 11s\tremaining: 5m 23s\n",
      "603:\tlearn: 0.2013238\ttotal: 8m 12s\tremaining: 5m 22s\n",
      "604:\tlearn: 0.2012066\ttotal: 8m 13s\tremaining: 5m 22s\n",
      "605:\tlearn: 0.2010125\ttotal: 8m 14s\tremaining: 5m 21s\n",
      "606:\tlearn: 0.2008976\ttotal: 8m 15s\tremaining: 5m 20s\n",
      "607:\tlearn: 0.2008150\ttotal: 8m 16s\tremaining: 5m 19s\n",
      "608:\tlearn: 0.2006762\ttotal: 8m 16s\tremaining: 5m 18s\n",
      "609:\tlearn: 0.2005175\ttotal: 8m 17s\tremaining: 5m 18s\n",
      "610:\tlearn: 0.2003894\ttotal: 8m 18s\tremaining: 5m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611:\tlearn: 0.2002252\ttotal: 8m 19s\tremaining: 5m 16s\n",
      "612:\tlearn: 0.2001088\ttotal: 8m 20s\tremaining: 5m 15s\n",
      "613:\tlearn: 0.1999683\ttotal: 8m 21s\tremaining: 5m 15s\n",
      "614:\tlearn: 0.1998453\ttotal: 8m 22s\tremaining: 5m 14s\n",
      "615:\tlearn: 0.1997571\ttotal: 8m 22s\tremaining: 5m 13s\n",
      "616:\tlearn: 0.1996842\ttotal: 8m 23s\tremaining: 5m 12s\n",
      "617:\tlearn: 0.1994953\ttotal: 8m 24s\tremaining: 5m 11s\n",
      "618:\tlearn: 0.1993847\ttotal: 8m 25s\tremaining: 5m 11s\n",
      "619:\tlearn: 0.1992622\ttotal: 8m 26s\tremaining: 5m 10s\n",
      "620:\tlearn: 0.1991708\ttotal: 8m 26s\tremaining: 5m 9s\n",
      "621:\tlearn: 0.1990459\ttotal: 8m 27s\tremaining: 5m 8s\n",
      "622:\tlearn: 0.1989710\ttotal: 8m 28s\tremaining: 5m 7s\n",
      "623:\tlearn: 0.1988397\ttotal: 8m 29s\tremaining: 5m 6s\n",
      "624:\tlearn: 0.1986757\ttotal: 8m 30s\tremaining: 5m 6s\n",
      "625:\tlearn: 0.1985772\ttotal: 8m 31s\tremaining: 5m 5s\n",
      "626:\tlearn: 0.1984773\ttotal: 8m 31s\tremaining: 5m 4s\n",
      "627:\tlearn: 0.1983643\ttotal: 8m 32s\tremaining: 5m 3s\n",
      "628:\tlearn: 0.1982674\ttotal: 8m 33s\tremaining: 5m 2s\n",
      "629:\tlearn: 0.1981799\ttotal: 8m 34s\tremaining: 5m 2s\n",
      "630:\tlearn: 0.1980777\ttotal: 8m 35s\tremaining: 5m 1s\n",
      "631:\tlearn: 0.1978837\ttotal: 8m 36s\tremaining: 5m\n",
      "632:\tlearn: 0.1978084\ttotal: 8m 36s\tremaining: 4m 59s\n",
      "633:\tlearn: 0.1976825\ttotal: 8m 37s\tremaining: 4m 58s\n",
      "634:\tlearn: 0.1975974\ttotal: 8m 38s\tremaining: 4m 57s\n",
      "635:\tlearn: 0.1974896\ttotal: 8m 39s\tremaining: 4m 57s\n",
      "636:\tlearn: 0.1973831\ttotal: 8m 39s\tremaining: 4m 56s\n",
      "637:\tlearn: 0.1973146\ttotal: 8m 40s\tremaining: 4m 55s\n",
      "638:\tlearn: 0.1972036\ttotal: 8m 41s\tremaining: 4m 54s\n",
      "639:\tlearn: 0.1971375\ttotal: 8m 42s\tremaining: 4m 53s\n",
      "640:\tlearn: 0.1970110\ttotal: 8m 43s\tremaining: 4m 53s\n",
      "641:\tlearn: 0.1969284\ttotal: 8m 44s\tremaining: 4m 52s\n",
      "642:\tlearn: 0.1968095\ttotal: 8m 45s\tremaining: 4m 51s\n",
      "643:\tlearn: 0.1967107\ttotal: 8m 45s\tremaining: 4m 50s\n",
      "644:\tlearn: 0.1966222\ttotal: 8m 46s\tremaining: 4m 49s\n",
      "645:\tlearn: 0.1965496\ttotal: 8m 47s\tremaining: 4m 48s\n",
      "646:\tlearn: 0.1964360\ttotal: 8m 48s\tremaining: 4m 48s\n",
      "647:\tlearn: 0.1963670\ttotal: 8m 48s\tremaining: 4m 47s\n",
      "648:\tlearn: 0.1962341\ttotal: 8m 49s\tremaining: 4m 46s\n",
      "649:\tlearn: 0.1960941\ttotal: 8m 50s\tremaining: 4m 45s\n",
      "650:\tlearn: 0.1960250\ttotal: 8m 51s\tremaining: 4m 44s\n",
      "651:\tlearn: 0.1959061\ttotal: 8m 52s\tremaining: 4m 44s\n",
      "652:\tlearn: 0.1958242\ttotal: 8m 53s\tremaining: 4m 43s\n",
      "653:\tlearn: 0.1957593\ttotal: 8m 53s\tremaining: 4m 42s\n",
      "654:\tlearn: 0.1955073\ttotal: 8m 54s\tremaining: 4m 41s\n",
      "655:\tlearn: 0.1954182\ttotal: 8m 55s\tremaining: 4m 40s\n",
      "656:\tlearn: 0.1953645\ttotal: 8m 56s\tremaining: 4m 39s\n",
      "657:\tlearn: 0.1952780\ttotal: 8m 57s\tremaining: 4m 39s\n",
      "658:\tlearn: 0.1952077\ttotal: 8m 57s\tremaining: 4m 38s\n",
      "659:\tlearn: 0.1951530\ttotal: 8m 58s\tremaining: 4m 37s\n",
      "660:\tlearn: 0.1950045\ttotal: 8m 59s\tremaining: 4m 36s\n",
      "661:\tlearn: 0.1949339\ttotal: 9m\tremaining: 4m 35s\n",
      "662:\tlearn: 0.1948119\ttotal: 9m 1s\tremaining: 4m 35s\n",
      "663:\tlearn: 0.1946435\ttotal: 9m 2s\tremaining: 4m 34s\n",
      "664:\tlearn: 0.1945801\ttotal: 9m 3s\tremaining: 4m 33s\n",
      "665:\tlearn: 0.1944299\ttotal: 9m 4s\tremaining: 4m 32s\n",
      "666:\tlearn: 0.1943242\ttotal: 9m 4s\tremaining: 4m 32s\n",
      "667:\tlearn: 0.1941881\ttotal: 9m 5s\tremaining: 4m 31s\n",
      "668:\tlearn: 0.1941164\ttotal: 9m 6s\tremaining: 4m 30s\n",
      "669:\tlearn: 0.1939408\ttotal: 9m 7s\tremaining: 4m 29s\n",
      "670:\tlearn: 0.1938688\ttotal: 9m 7s\tremaining: 4m 28s\n",
      "671:\tlearn: 0.1937822\ttotal: 9m 8s\tremaining: 4m 27s\n",
      "672:\tlearn: 0.1936630\ttotal: 9m 9s\tremaining: 4m 27s\n",
      "673:\tlearn: 0.1935515\ttotal: 9m 10s\tremaining: 4m 26s\n",
      "674:\tlearn: 0.1934779\ttotal: 9m 11s\tremaining: 4m 25s\n",
      "675:\tlearn: 0.1933742\ttotal: 9m 12s\tremaining: 4m 24s\n",
      "676:\tlearn: 0.1932649\ttotal: 9m 12s\tremaining: 4m 23s\n",
      "677:\tlearn: 0.1931319\ttotal: 9m 13s\tremaining: 4m 22s\n",
      "678:\tlearn: 0.1930632\ttotal: 9m 14s\tremaining: 4m 22s\n",
      "679:\tlearn: 0.1929088\ttotal: 9m 15s\tremaining: 4m 21s\n",
      "680:\tlearn: 0.1928052\ttotal: 9m 16s\tremaining: 4m 20s\n",
      "681:\tlearn: 0.1927322\ttotal: 9m 16s\tremaining: 4m 19s\n",
      "682:\tlearn: 0.1926531\ttotal: 9m 17s\tremaining: 4m 18s\n",
      "683:\tlearn: 0.1925729\ttotal: 9m 18s\tremaining: 4m 18s\n",
      "684:\tlearn: 0.1924974\ttotal: 9m 19s\tremaining: 4m 17s\n",
      "685:\tlearn: 0.1923626\ttotal: 9m 20s\tremaining: 4m 16s\n",
      "686:\tlearn: 0.1922983\ttotal: 9m 20s\tremaining: 4m 15s\n",
      "687:\tlearn: 0.1921719\ttotal: 9m 21s\tremaining: 4m 14s\n",
      "688:\tlearn: 0.1920651\ttotal: 9m 22s\tremaining: 4m 13s\n",
      "689:\tlearn: 0.1919602\ttotal: 9m 23s\tremaining: 4m 13s\n",
      "690:\tlearn: 0.1918202\ttotal: 9m 24s\tremaining: 4m 12s\n",
      "691:\tlearn: 0.1917210\ttotal: 9m 25s\tremaining: 4m 11s\n",
      "692:\tlearn: 0.1915938\ttotal: 9m 26s\tremaining: 4m 10s\n",
      "693:\tlearn: 0.1914922\ttotal: 9m 26s\tremaining: 4m 9s\n",
      "694:\tlearn: 0.1913907\ttotal: 9m 27s\tremaining: 4m 9s\n",
      "695:\tlearn: 0.1913354\ttotal: 9m 28s\tremaining: 4m 8s\n",
      "696:\tlearn: 0.1912622\ttotal: 9m 28s\tremaining: 4m 7s\n",
      "697:\tlearn: 0.1911520\ttotal: 9m 29s\tremaining: 4m 6s\n",
      "698:\tlearn: 0.1910487\ttotal: 9m 30s\tremaining: 4m 5s\n",
      "699:\tlearn: 0.1909547\ttotal: 9m 31s\tremaining: 4m 5s\n",
      "700:\tlearn: 0.1908061\ttotal: 9m 32s\tremaining: 4m 4s\n",
      "701:\tlearn: 0.1907049\ttotal: 9m 33s\tremaining: 4m 3s\n",
      "702:\tlearn: 0.1906437\ttotal: 9m 34s\tremaining: 4m 2s\n",
      "703:\tlearn: 0.1905136\ttotal: 9m 35s\tremaining: 4m 1s\n",
      "704:\tlearn: 0.1904391\ttotal: 9m 36s\tremaining: 4m 1s\n",
      "705:\tlearn: 0.1903143\ttotal: 9m 36s\tremaining: 4m\n",
      "706:\tlearn: 0.1902486\ttotal: 9m 37s\tremaining: 3m 59s\n",
      "707:\tlearn: 0.1901989\ttotal: 9m 38s\tremaining: 3m 58s\n",
      "708:\tlearn: 0.1901252\ttotal: 9m 38s\tremaining: 3m 57s\n",
      "709:\tlearn: 0.1899743\ttotal: 9m 39s\tremaining: 3m 56s\n",
      "710:\tlearn: 0.1898744\ttotal: 9m 40s\tremaining: 3m 56s\n",
      "711:\tlearn: 0.1897475\ttotal: 9m 41s\tremaining: 3m 55s\n",
      "712:\tlearn: 0.1896127\ttotal: 9m 42s\tremaining: 3m 54s\n",
      "713:\tlearn: 0.1895360\ttotal: 9m 43s\tremaining: 3m 53s\n",
      "714:\tlearn: 0.1893667\ttotal: 9m 44s\tremaining: 3m 52s\n",
      "715:\tlearn: 0.1892660\ttotal: 9m 45s\tremaining: 3m 52s\n",
      "716:\tlearn: 0.1891991\ttotal: 9m 45s\tremaining: 3m 51s\n",
      "717:\tlearn: 0.1890657\ttotal: 9m 46s\tremaining: 3m 50s\n",
      "718:\tlearn: 0.1889291\ttotal: 9m 47s\tremaining: 3m 49s\n",
      "719:\tlearn: 0.1888377\ttotal: 9m 48s\tremaining: 3m 48s\n",
      "720:\tlearn: 0.1887124\ttotal: 9m 49s\tremaining: 3m 48s\n",
      "721:\tlearn: 0.1886348\ttotal: 9m 50s\tremaining: 3m 47s\n",
      "722:\tlearn: 0.1885295\ttotal: 9m 51s\tremaining: 3m 46s\n",
      "723:\tlearn: 0.1884819\ttotal: 9m 51s\tremaining: 3m 45s\n",
      "724:\tlearn: 0.1883873\ttotal: 9m 52s\tremaining: 3m 44s\n",
      "725:\tlearn: 0.1882720\ttotal: 9m 53s\tremaining: 3m 44s\n",
      "726:\tlearn: 0.1881612\ttotal: 9m 54s\tremaining: 3m 43s\n",
      "727:\tlearn: 0.1880672\ttotal: 9m 55s\tremaining: 3m 42s\n",
      "728:\tlearn: 0.1878995\ttotal: 9m 56s\tremaining: 3m 41s\n",
      "729:\tlearn: 0.1878088\ttotal: 9m 57s\tremaining: 3m 40s\n",
      "730:\tlearn: 0.1877266\ttotal: 9m 58s\tremaining: 3m 40s\n",
      "731:\tlearn: 0.1876154\ttotal: 9m 58s\tremaining: 3m 39s\n",
      "732:\tlearn: 0.1874990\ttotal: 9m 59s\tremaining: 3m 38s\n",
      "733:\tlearn: 0.1873938\ttotal: 10m\tremaining: 3m 37s\n",
      "734:\tlearn: 0.1873298\ttotal: 10m 1s\tremaining: 3m 36s\n",
      "735:\tlearn: 0.1872472\ttotal: 10m 2s\tremaining: 3m 36s\n",
      "736:\tlearn: 0.1871468\ttotal: 10m 2s\tremaining: 3m 35s\n",
      "737:\tlearn: 0.1870211\ttotal: 10m 3s\tremaining: 3m 34s\n",
      "738:\tlearn: 0.1869314\ttotal: 10m 4s\tremaining: 3m 33s\n",
      "739:\tlearn: 0.1868578\ttotal: 10m 5s\tremaining: 3m 32s\n",
      "740:\tlearn: 0.1867659\ttotal: 10m 6s\tremaining: 3m 32s\n",
      "741:\tlearn: 0.1866707\ttotal: 10m 7s\tremaining: 3m 31s\n",
      "742:\tlearn: 0.1865406\ttotal: 10m 8s\tremaining: 3m 30s\n",
      "743:\tlearn: 0.1864580\ttotal: 10m 9s\tremaining: 3m 29s\n",
      "744:\tlearn: 0.1863593\ttotal: 10m 9s\tremaining: 3m 28s\n",
      "745:\tlearn: 0.1862453\ttotal: 10m 10s\tremaining: 3m 27s\n",
      "746:\tlearn: 0.1861907\ttotal: 10m 11s\tremaining: 3m 27s\n",
      "747:\tlearn: 0.1860835\ttotal: 10m 12s\tremaining: 3m 26s\n",
      "748:\tlearn: 0.1859785\ttotal: 10m 13s\tremaining: 3m 25s\n",
      "749:\tlearn: 0.1858590\ttotal: 10m 14s\tremaining: 3m 24s\n",
      "750:\tlearn: 0.1857350\ttotal: 10m 14s\tremaining: 3m 23s\n",
      "751:\tlearn: 0.1856645\ttotal: 10m 15s\tremaining: 3m 23s\n",
      "752:\tlearn: 0.1855633\ttotal: 10m 16s\tremaining: 3m 22s\n",
      "753:\tlearn: 0.1854748\ttotal: 10m 17s\tremaining: 3m 21s\n",
      "754:\tlearn: 0.1853561\ttotal: 10m 18s\tremaining: 3m 20s\n",
      "755:\tlearn: 0.1852920\ttotal: 10m 19s\tremaining: 3m 19s\n",
      "756:\tlearn: 0.1852089\ttotal: 10m 20s\tremaining: 3m 19s\n",
      "757:\tlearn: 0.1850947\ttotal: 10m 21s\tremaining: 3m 18s\n",
      "758:\tlearn: 0.1850174\ttotal: 10m 22s\tremaining: 3m 17s\n",
      "759:\tlearn: 0.1849142\ttotal: 10m 23s\tremaining: 3m 16s\n",
      "760:\tlearn: 0.1848468\ttotal: 10m 23s\tremaining: 3m 15s\n",
      "761:\tlearn: 0.1847191\ttotal: 10m 24s\tremaining: 3m 15s\n",
      "762:\tlearn: 0.1845854\ttotal: 10m 25s\tremaining: 3m 14s\n",
      "763:\tlearn: 0.1844667\ttotal: 10m 26s\tremaining: 3m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764:\tlearn: 0.1843345\ttotal: 10m 27s\tremaining: 3m 12s\n",
      "765:\tlearn: 0.1842181\ttotal: 10m 28s\tremaining: 3m 12s\n",
      "766:\tlearn: 0.1841669\ttotal: 10m 29s\tremaining: 3m 11s\n",
      "767:\tlearn: 0.1841028\ttotal: 10m 30s\tremaining: 3m 10s\n",
      "768:\tlearn: 0.1840366\ttotal: 10m 31s\tremaining: 3m 9s\n",
      "769:\tlearn: 0.1839355\ttotal: 10m 32s\tremaining: 3m 8s\n",
      "770:\tlearn: 0.1838909\ttotal: 10m 32s\tremaining: 3m 7s\n",
      "771:\tlearn: 0.1838139\ttotal: 10m 33s\tremaining: 3m 7s\n",
      "772:\tlearn: 0.1837539\ttotal: 10m 34s\tremaining: 3m 6s\n",
      "773:\tlearn: 0.1836933\ttotal: 10m 35s\tremaining: 3m 5s\n",
      "774:\tlearn: 0.1836064\ttotal: 10m 35s\tremaining: 3m 4s\n",
      "775:\tlearn: 0.1835135\ttotal: 10m 36s\tremaining: 3m 3s\n",
      "776:\tlearn: 0.1834248\ttotal: 10m 37s\tremaining: 3m 3s\n",
      "777:\tlearn: 0.1833416\ttotal: 10m 38s\tremaining: 3m 2s\n",
      "778:\tlearn: 0.1832639\ttotal: 10m 39s\tremaining: 3m 1s\n",
      "779:\tlearn: 0.1831419\ttotal: 10m 40s\tremaining: 3m\n",
      "780:\tlearn: 0.1830603\ttotal: 10m 41s\tremaining: 2m 59s\n",
      "781:\tlearn: 0.1829805\ttotal: 10m 42s\tremaining: 2m 58s\n",
      "782:\tlearn: 0.1829048\ttotal: 10m 42s\tremaining: 2m 58s\n",
      "783:\tlearn: 0.1828598\ttotal: 10m 43s\tremaining: 2m 57s\n",
      "784:\tlearn: 0.1827507\ttotal: 10m 43s\tremaining: 2m 56s\n",
      "785:\tlearn: 0.1826542\ttotal: 10m 44s\tremaining: 2m 55s\n",
      "786:\tlearn: 0.1825967\ttotal: 10m 45s\tremaining: 2m 54s\n",
      "787:\tlearn: 0.1825108\ttotal: 10m 46s\tremaining: 2m 53s\n",
      "788:\tlearn: 0.1824192\ttotal: 10m 47s\tremaining: 2m 53s\n",
      "789:\tlearn: 0.1823414\ttotal: 10m 47s\tremaining: 2m 52s\n",
      "790:\tlearn: 0.1822546\ttotal: 10m 48s\tremaining: 2m 51s\n",
      "791:\tlearn: 0.1821925\ttotal: 10m 49s\tremaining: 2m 50s\n",
      "792:\tlearn: 0.1820206\ttotal: 10m 50s\tremaining: 2m 49s\n",
      "793:\tlearn: 0.1819642\ttotal: 10m 51s\tremaining: 2m 48s\n",
      "794:\tlearn: 0.1819228\ttotal: 10m 51s\tremaining: 2m 48s\n",
      "795:\tlearn: 0.1818627\ttotal: 10m 52s\tremaining: 2m 47s\n",
      "796:\tlearn: 0.1817609\ttotal: 10m 53s\tremaining: 2m 46s\n",
      "797:\tlearn: 0.1816541\ttotal: 10m 54s\tremaining: 2m 45s\n",
      "798:\tlearn: 0.1815815\ttotal: 10m 55s\tremaining: 2m 44s\n",
      "799:\tlearn: 0.1815182\ttotal: 10m 55s\tremaining: 2m 43s\n",
      "800:\tlearn: 0.1814622\ttotal: 10m 56s\tremaining: 2m 43s\n",
      "801:\tlearn: 0.1813511\ttotal: 10m 57s\tremaining: 2m 42s\n",
      "802:\tlearn: 0.1813250\ttotal: 10m 58s\tremaining: 2m 41s\n",
      "803:\tlearn: 0.1812691\ttotal: 10m 59s\tremaining: 2m 40s\n",
      "804:\tlearn: 0.1811469\ttotal: 11m\tremaining: 2m 39s\n",
      "805:\tlearn: 0.1810707\ttotal: 11m\tremaining: 2m 39s\n",
      "806:\tlearn: 0.1810086\ttotal: 11m 1s\tremaining: 2m 38s\n",
      "807:\tlearn: 0.1808951\ttotal: 11m 2s\tremaining: 2m 37s\n",
      "808:\tlearn: 0.1808213\ttotal: 11m 3s\tremaining: 2m 36s\n",
      "809:\tlearn: 0.1807452\ttotal: 11m 3s\tremaining: 2m 35s\n",
      "810:\tlearn: 0.1806703\ttotal: 11m 4s\tremaining: 2m 34s\n",
      "811:\tlearn: 0.1805278\ttotal: 11m 5s\tremaining: 2m 34s\n",
      "812:\tlearn: 0.1804556\ttotal: 11m 6s\tremaining: 2m 33s\n",
      "813:\tlearn: 0.1803399\ttotal: 11m 7s\tremaining: 2m 32s\n",
      "814:\tlearn: 0.1802332\ttotal: 11m 8s\tremaining: 2m 31s\n",
      "815:\tlearn: 0.1800908\ttotal: 11m 9s\tremaining: 2m 30s\n",
      "816:\tlearn: 0.1800123\ttotal: 11m 10s\tremaining: 2m 30s\n",
      "817:\tlearn: 0.1799314\ttotal: 11m 11s\tremaining: 2m 29s\n",
      "818:\tlearn: 0.1798090\ttotal: 11m 12s\tremaining: 2m 28s\n",
      "819:\tlearn: 0.1797614\ttotal: 11m 13s\tremaining: 2m 27s\n",
      "820:\tlearn: 0.1797071\ttotal: 11m 13s\tremaining: 2m 26s\n",
      "821:\tlearn: 0.1796398\ttotal: 11m 14s\tremaining: 2m 26s\n",
      "822:\tlearn: 0.1795774\ttotal: 11m 15s\tremaining: 2m 25s\n",
      "823:\tlearn: 0.1794592\ttotal: 11m 16s\tremaining: 2m 24s\n",
      "824:\tlearn: 0.1793668\ttotal: 11m 17s\tremaining: 2m 23s\n",
      "825:\tlearn: 0.1792809\ttotal: 11m 18s\tremaining: 2m 22s\n",
      "826:\tlearn: 0.1792353\ttotal: 11m 19s\tremaining: 2m 22s\n",
      "827:\tlearn: 0.1791606\ttotal: 11m 19s\tremaining: 2m 21s\n",
      "828:\tlearn: 0.1790477\ttotal: 11m 20s\tremaining: 2m 20s\n",
      "829:\tlearn: 0.1789756\ttotal: 11m 21s\tremaining: 2m 19s\n",
      "830:\tlearn: 0.1789139\ttotal: 11m 22s\tremaining: 2m 18s\n",
      "831:\tlearn: 0.1788282\ttotal: 11m 22s\tremaining: 2m 17s\n",
      "832:\tlearn: 0.1787451\ttotal: 11m 23s\tremaining: 2m 17s\n",
      "833:\tlearn: 0.1786580\ttotal: 11m 24s\tremaining: 2m 16s\n",
      "834:\tlearn: 0.1785993\ttotal: 11m 25s\tremaining: 2m 15s\n",
      "835:\tlearn: 0.1785068\ttotal: 11m 26s\tremaining: 2m 14s\n",
      "836:\tlearn: 0.1784451\ttotal: 11m 27s\tremaining: 2m 13s\n",
      "837:\tlearn: 0.1783318\ttotal: 11m 28s\tremaining: 2m 13s\n",
      "838:\tlearn: 0.1782625\ttotal: 11m 29s\tremaining: 2m 12s\n",
      "839:\tlearn: 0.1781931\ttotal: 11m 29s\tremaining: 2m 11s\n",
      "840:\tlearn: 0.1781248\ttotal: 11m 30s\tremaining: 2m 10s\n",
      "841:\tlearn: 0.1780651\ttotal: 11m 31s\tremaining: 2m 9s\n",
      "842:\tlearn: 0.1779760\ttotal: 11m 32s\tremaining: 2m 8s\n",
      "843:\tlearn: 0.1779208\ttotal: 11m 33s\tremaining: 2m 8s\n",
      "844:\tlearn: 0.1778242\ttotal: 11m 34s\tremaining: 2m 7s\n",
      "845:\tlearn: 0.1777795\ttotal: 11m 34s\tremaining: 2m 6s\n",
      "846:\tlearn: 0.1777142\ttotal: 11m 35s\tremaining: 2m 5s\n",
      "847:\tlearn: 0.1776231\ttotal: 11m 36s\tremaining: 2m 4s\n",
      "848:\tlearn: 0.1775697\ttotal: 11m 37s\tremaining: 2m 4s\n",
      "849:\tlearn: 0.1774719\ttotal: 11m 38s\tremaining: 2m 3s\n",
      "850:\tlearn: 0.1773816\ttotal: 11m 39s\tremaining: 2m 2s\n",
      "851:\tlearn: 0.1773305\ttotal: 11m 39s\tremaining: 2m 1s\n",
      "852:\tlearn: 0.1772512\ttotal: 11m 40s\tremaining: 2m\n",
      "853:\tlearn: 0.1771850\ttotal: 11m 41s\tremaining: 1m 59s\n",
      "854:\tlearn: 0.1770942\ttotal: 11m 42s\tremaining: 1m 59s\n",
      "855:\tlearn: 0.1770013\ttotal: 11m 43s\tremaining: 1m 58s\n",
      "856:\tlearn: 0.1769385\ttotal: 11m 44s\tremaining: 1m 57s\n",
      "857:\tlearn: 0.1768408\ttotal: 11m 45s\tremaining: 1m 56s\n",
      "858:\tlearn: 0.1767253\ttotal: 11m 46s\tremaining: 1m 55s\n",
      "859:\tlearn: 0.1766686\ttotal: 11m 46s\tremaining: 1m 55s\n",
      "860:\tlearn: 0.1765957\ttotal: 11m 47s\tremaining: 1m 54s\n",
      "861:\tlearn: 0.1764986\ttotal: 11m 48s\tremaining: 1m 53s\n",
      "862:\tlearn: 0.1764017\ttotal: 11m 49s\tremaining: 1m 52s\n",
      "863:\tlearn: 0.1763290\ttotal: 11m 50s\tremaining: 1m 51s\n",
      "864:\tlearn: 0.1762863\ttotal: 11m 50s\tremaining: 1m 50s\n",
      "865:\tlearn: 0.1762177\ttotal: 11m 51s\tremaining: 1m 50s\n",
      "866:\tlearn: 0.1761206\ttotal: 11m 52s\tremaining: 1m 49s\n",
      "867:\tlearn: 0.1760643\ttotal: 11m 53s\tremaining: 1m 48s\n",
      "868:\tlearn: 0.1759473\ttotal: 11m 54s\tremaining: 1m 47s\n",
      "869:\tlearn: 0.1758900\ttotal: 11m 55s\tremaining: 1m 46s\n",
      "870:\tlearn: 0.1757757\ttotal: 11m 56s\tremaining: 1m 46s\n",
      "871:\tlearn: 0.1757288\ttotal: 11m 56s\tremaining: 1m 45s\n",
      "872:\tlearn: 0.1756473\ttotal: 11m 57s\tremaining: 1m 44s\n",
      "873:\tlearn: 0.1755937\ttotal: 11m 58s\tremaining: 1m 43s\n",
      "874:\tlearn: 0.1755126\ttotal: 11m 59s\tremaining: 1m 42s\n",
      "875:\tlearn: 0.1754525\ttotal: 12m\tremaining: 1m 41s\n",
      "876:\tlearn: 0.1753811\ttotal: 12m 1s\tremaining: 1m 41s\n",
      "877:\tlearn: 0.1753108\ttotal: 12m 2s\tremaining: 1m 40s\n",
      "878:\tlearn: 0.1752376\ttotal: 12m 3s\tremaining: 1m 39s\n",
      "879:\tlearn: 0.1751427\ttotal: 12m 3s\tremaining: 1m 38s\n",
      "880:\tlearn: 0.1750420\ttotal: 12m 4s\tremaining: 1m 37s\n",
      "881:\tlearn: 0.1749784\ttotal: 12m 5s\tremaining: 1m 37s\n",
      "882:\tlearn: 0.1748883\ttotal: 12m 6s\tremaining: 1m 36s\n",
      "883:\tlearn: 0.1748421\ttotal: 12m 7s\tremaining: 1m 35s\n",
      "884:\tlearn: 0.1747762\ttotal: 12m 8s\tremaining: 1m 34s\n",
      "885:\tlearn: 0.1747335\ttotal: 12m 8s\tremaining: 1m 33s\n",
      "886:\tlearn: 0.1746543\ttotal: 12m 9s\tremaining: 1m 32s\n",
      "887:\tlearn: 0.1745941\ttotal: 12m 10s\tremaining: 1m 32s\n",
      "888:\tlearn: 0.1744869\ttotal: 12m 11s\tremaining: 1m 31s\n",
      "889:\tlearn: 0.1743916\ttotal: 12m 12s\tremaining: 1m 30s\n",
      "890:\tlearn: 0.1743434\ttotal: 12m 13s\tremaining: 1m 29s\n",
      "891:\tlearn: 0.1742875\ttotal: 12m 14s\tremaining: 1m 28s\n",
      "892:\tlearn: 0.1742329\ttotal: 12m 14s\tremaining: 1m 28s\n",
      "893:\tlearn: 0.1741784\ttotal: 12m 15s\tremaining: 1m 27s\n",
      "894:\tlearn: 0.1741216\ttotal: 12m 16s\tremaining: 1m 26s\n",
      "895:\tlearn: 0.1740720\ttotal: 12m 17s\tremaining: 1m 25s\n",
      "896:\tlearn: 0.1740350\ttotal: 12m 18s\tremaining: 1m 24s\n",
      "897:\tlearn: 0.1739885\ttotal: 12m 18s\tremaining: 1m 23s\n",
      "898:\tlearn: 0.1739308\ttotal: 12m 19s\tremaining: 1m 23s\n",
      "899:\tlearn: 0.1738639\ttotal: 12m 20s\tremaining: 1m 22s\n",
      "900:\tlearn: 0.1738118\ttotal: 12m 21s\tremaining: 1m 21s\n",
      "901:\tlearn: 0.1737188\ttotal: 12m 22s\tremaining: 1m 20s\n",
      "902:\tlearn: 0.1736517\ttotal: 12m 23s\tremaining: 1m 19s\n",
      "903:\tlearn: 0.1735683\ttotal: 12m 23s\tremaining: 1m 19s\n",
      "904:\tlearn: 0.1734541\ttotal: 12m 24s\tremaining: 1m 18s\n",
      "905:\tlearn: 0.1733748\ttotal: 12m 26s\tremaining: 1m 17s\n",
      "906:\tlearn: 0.1733012\ttotal: 12m 26s\tremaining: 1m 16s\n",
      "907:\tlearn: 0.1732085\ttotal: 12m 27s\tremaining: 1m 15s\n",
      "908:\tlearn: 0.1731632\ttotal: 12m 28s\tremaining: 1m 14s\n",
      "909:\tlearn: 0.1731099\ttotal: 12m 29s\tremaining: 1m 14s\n",
      "910:\tlearn: 0.1730786\ttotal: 12m 29s\tremaining: 1m 13s\n",
      "911:\tlearn: 0.1730027\ttotal: 12m 30s\tremaining: 1m 12s\n",
      "912:\tlearn: 0.1728789\ttotal: 12m 31s\tremaining: 1m 11s\n",
      "913:\tlearn: 0.1728326\ttotal: 12m 32s\tremaining: 1m 10s\n",
      "914:\tlearn: 0.1727845\ttotal: 12m 32s\tremaining: 1m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "915:\tlearn: 0.1726863\ttotal: 12m 33s\tremaining: 1m 9s\n",
      "916:\tlearn: 0.1726037\ttotal: 12m 34s\tremaining: 1m 8s\n",
      "917:\tlearn: 0.1725600\ttotal: 12m 35s\tremaining: 1m 7s\n",
      "918:\tlearn: 0.1725225\ttotal: 12m 36s\tremaining: 1m 6s\n",
      "919:\tlearn: 0.1724071\ttotal: 12m 37s\tremaining: 1m 5s\n",
      "920:\tlearn: 0.1723402\ttotal: 12m 38s\tremaining: 1m 5s\n",
      "921:\tlearn: 0.1722962\ttotal: 12m 38s\tremaining: 1m 4s\n",
      "922:\tlearn: 0.1722350\ttotal: 12m 39s\tremaining: 1m 3s\n",
      "923:\tlearn: 0.1721697\ttotal: 12m 40s\tremaining: 1m 2s\n",
      "924:\tlearn: 0.1721082\ttotal: 12m 41s\tremaining: 1m 1s\n",
      "925:\tlearn: 0.1720137\ttotal: 12m 42s\tremaining: 1m\n",
      "926:\tlearn: 0.1719145\ttotal: 12m 43s\tremaining: 1m\n",
      "927:\tlearn: 0.1718693\ttotal: 12m 44s\tremaining: 59.3s\n",
      "928:\tlearn: 0.1718171\ttotal: 12m 44s\tremaining: 58.4s\n",
      "929:\tlearn: 0.1717606\ttotal: 12m 45s\tremaining: 57.6s\n",
      "930:\tlearn: 0.1717063\ttotal: 12m 46s\tremaining: 56.8s\n",
      "931:\tlearn: 0.1715790\ttotal: 12m 47s\tremaining: 56s\n",
      "932:\tlearn: 0.1715217\ttotal: 12m 48s\tremaining: 55.2s\n",
      "933:\tlearn: 0.1714571\ttotal: 12m 48s\tremaining: 54.3s\n",
      "934:\tlearn: 0.1714161\ttotal: 12m 49s\tremaining: 53.5s\n",
      "935:\tlearn: 0.1713179\ttotal: 12m 50s\tremaining: 52.7s\n",
      "936:\tlearn: 0.1712372\ttotal: 12m 51s\tremaining: 51.8s\n",
      "937:\tlearn: 0.1711607\ttotal: 12m 52s\tremaining: 51s\n",
      "938:\tlearn: 0.1710593\ttotal: 12m 53s\tremaining: 50.2s\n",
      "939:\tlearn: 0.1709712\ttotal: 12m 54s\tremaining: 49.4s\n",
      "940:\tlearn: 0.1709398\ttotal: 12m 54s\tremaining: 48.6s\n",
      "941:\tlearn: 0.1708553\ttotal: 12m 55s\tremaining: 47.7s\n",
      "942:\tlearn: 0.1707885\ttotal: 12m 56s\tremaining: 46.9s\n",
      "943:\tlearn: 0.1706638\ttotal: 12m 57s\tremaining: 46.1s\n",
      "944:\tlearn: 0.1706135\ttotal: 12m 58s\tremaining: 45.3s\n",
      "945:\tlearn: 0.1705699\ttotal: 12m 58s\tremaining: 44.5s\n",
      "946:\tlearn: 0.1704600\ttotal: 12m 59s\tremaining: 43.6s\n",
      "947:\tlearn: 0.1704062\ttotal: 13m\tremaining: 42.8s\n",
      "948:\tlearn: 0.1703484\ttotal: 13m 1s\tremaining: 42s\n",
      "949:\tlearn: 0.1702785\ttotal: 13m 2s\tremaining: 41.2s\n",
      "950:\tlearn: 0.1702422\ttotal: 13m 3s\tremaining: 40.4s\n",
      "951:\tlearn: 0.1701750\ttotal: 13m 3s\tremaining: 39.5s\n",
      "952:\tlearn: 0.1701187\ttotal: 13m 4s\tremaining: 38.7s\n",
      "953:\tlearn: 0.1700377\ttotal: 13m 5s\tremaining: 37.9s\n",
      "954:\tlearn: 0.1699657\ttotal: 13m 6s\tremaining: 37.1s\n",
      "955:\tlearn: 0.1698909\ttotal: 13m 7s\tremaining: 36.2s\n",
      "956:\tlearn: 0.1698464\ttotal: 13m 8s\tremaining: 35.4s\n",
      "957:\tlearn: 0.1697898\ttotal: 13m 9s\tremaining: 34.6s\n",
      "958:\tlearn: 0.1697322\ttotal: 13m 9s\tremaining: 33.8s\n",
      "959:\tlearn: 0.1696815\ttotal: 13m 10s\tremaining: 32.9s\n",
      "960:\tlearn: 0.1696016\ttotal: 13m 11s\tremaining: 32.1s\n",
      "961:\tlearn: 0.1695618\ttotal: 13m 12s\tremaining: 31.3s\n",
      "962:\tlearn: 0.1694684\ttotal: 13m 13s\tremaining: 30.5s\n",
      "963:\tlearn: 0.1693954\ttotal: 13m 14s\tremaining: 29.7s\n",
      "964:\tlearn: 0.1693020\ttotal: 13m 15s\tremaining: 28.9s\n",
      "965:\tlearn: 0.1692416\ttotal: 13m 16s\tremaining: 28s\n",
      "966:\tlearn: 0.1691845\ttotal: 13m 17s\tremaining: 27.2s\n",
      "967:\tlearn: 0.1691364\ttotal: 13m 17s\tremaining: 26.4s\n",
      "968:\tlearn: 0.1690647\ttotal: 13m 18s\tremaining: 25.6s\n",
      "969:\tlearn: 0.1689913\ttotal: 13m 19s\tremaining: 24.7s\n",
      "970:\tlearn: 0.1689544\ttotal: 13m 20s\tremaining: 23.9s\n",
      "971:\tlearn: 0.1688712\ttotal: 13m 21s\tremaining: 23.1s\n",
      "972:\tlearn: 0.1688273\ttotal: 13m 22s\tremaining: 22.3s\n",
      "973:\tlearn: 0.1687823\ttotal: 13m 22s\tremaining: 21.4s\n",
      "974:\tlearn: 0.1687253\ttotal: 13m 23s\tremaining: 20.6s\n",
      "975:\tlearn: 0.1686625\ttotal: 13m 24s\tremaining: 19.8s\n",
      "976:\tlearn: 0.1686178\ttotal: 13m 25s\tremaining: 19s\n",
      "977:\tlearn: 0.1685434\ttotal: 13m 26s\tremaining: 18.1s\n",
      "978:\tlearn: 0.1684939\ttotal: 13m 27s\tremaining: 17.3s\n",
      "979:\tlearn: 0.1684539\ttotal: 13m 28s\tremaining: 16.5s\n",
      "980:\tlearn: 0.1683775\ttotal: 13m 29s\tremaining: 15.7s\n",
      "981:\tlearn: 0.1683445\ttotal: 13m 29s\tremaining: 14.8s\n",
      "982:\tlearn: 0.1682832\ttotal: 13m 30s\tremaining: 14s\n",
      "983:\tlearn: 0.1682169\ttotal: 13m 31s\tremaining: 13.2s\n",
      "984:\tlearn: 0.1681598\ttotal: 13m 32s\tremaining: 12.4s\n",
      "985:\tlearn: 0.1680962\ttotal: 13m 33s\tremaining: 11.6s\n",
      "986:\tlearn: 0.1680216\ttotal: 13m 34s\tremaining: 10.7s\n",
      "987:\tlearn: 0.1679555\ttotal: 13m 35s\tremaining: 9.9s\n",
      "988:\tlearn: 0.1678837\ttotal: 13m 35s\tremaining: 9.07s\n",
      "989:\tlearn: 0.1677872\ttotal: 13m 36s\tremaining: 8.25s\n",
      "990:\tlearn: 0.1677500\ttotal: 13m 37s\tremaining: 7.42s\n",
      "991:\tlearn: 0.1676594\ttotal: 13m 38s\tremaining: 6.6s\n",
      "992:\tlearn: 0.1675605\ttotal: 13m 39s\tremaining: 5.77s\n",
      "993:\tlearn: 0.1675060\ttotal: 13m 39s\tremaining: 4.95s\n",
      "994:\tlearn: 0.1674496\ttotal: 13m 40s\tremaining: 4.13s\n",
      "995:\tlearn: 0.1673543\ttotal: 13m 41s\tremaining: 3.3s\n",
      "996:\tlearn: 0.1672905\ttotal: 13m 42s\tremaining: 2.48s\n",
      "997:\tlearn: 0.1672518\ttotal: 13m 43s\tremaining: 1.65s\n",
      "998:\tlearn: 0.1672191\ttotal: 13m 44s\tremaining: 825ms\n",
      "999:\tlearn: 0.1671607\ttotal: 13m 45s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [   20 20168  4112   387]\n",
      " [    2   235  4773    54]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    8    16     1     0]\n",
      " [   30 27886  6321   622]\n",
      " [    3   598  6564   162]\n",
      " [    0    84    38   207]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      1.00      0.58        15\n",
      "           2       0.99      0.82      0.89     24687\n",
      "           3       0.54      0.94      0.68      5064\n",
      "           4       0.35      1.00      0.51       234\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.57      0.94      0.67     30000\n",
      "weighted avg       0.91      0.84      0.86     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.32      0.24        25\n",
      "           2       0.98      0.80      0.88     34859\n",
      "           3       0.51      0.90      0.65      7327\n",
      "           4       0.21      0.63      0.31       329\n",
      "\n",
      "    accuracy                           0.81     42540\n",
      "   macro avg       0.47      0.66      0.52     42540\n",
      "weighted avg       0.89      0.81      0.83     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier()\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blessed-degree",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2762534\ttotal: 1.28s\tremaining: 42m 32s\n",
      "100:\tlearn: 0.3550597\ttotal: 1m 46s\tremaining: 33m 28s\n",
      "200:\tlearn: 0.2749199\ttotal: 3m 25s\tremaining: 30m 42s\n",
      "300:\tlearn: 0.2348972\ttotal: 5m 5s\tremaining: 28m 45s\n",
      "400:\tlearn: 0.2087168\ttotal: 6m 50s\tremaining: 27m 17s\n",
      "500:\tlearn: 0.1918332\ttotal: 8m 32s\tremaining: 25m 32s\n",
      "600:\tlearn: 0.1784519\ttotal: 10m 16s\tremaining: 23m 55s\n",
      "700:\tlearn: 0.1679582\ttotal: 12m 1s\tremaining: 22m 17s\n",
      "800:\tlearn: 0.1597926\ttotal: 13m 46s\tremaining: 20m 37s\n",
      "900:\tlearn: 0.1521855\ttotal: 15m 34s\tremaining: 18m 59s\n",
      "1000:\tlearn: 0.1457856\ttotal: 17m 19s\tremaining: 17m 17s\n",
      "1100:\tlearn: 0.1401088\ttotal: 19m 4s\tremaining: 15m 34s\n",
      "1200:\tlearn: 0.1349203\ttotal: 20m 51s\tremaining: 13m 52s\n",
      "1300:\tlearn: 0.1303636\ttotal: 22m 37s\tremaining: 12m 9s\n",
      "1400:\tlearn: 0.1263183\ttotal: 24m 22s\tremaining: 10m 25s\n",
      "1500:\tlearn: 0.1220848\ttotal: 26m 9s\tremaining: 8m 41s\n",
      "1600:\tlearn: 0.1183708\ttotal: 27m 59s\tremaining: 6m 58s\n",
      "1700:\tlearn: 0.1149901\ttotal: 29m 45s\tremaining: 5m 13s\n",
      "1800:\tlearn: 0.1118849\ttotal: 31m 29s\tremaining: 3m 28s\n",
      "1900:\tlearn: 0.1088202\ttotal: 33m 16s\tremaining: 1m 43s\n",
      "1999:\tlearn: 0.1059346\ttotal: 35m 5s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    1 21775  2821    90]\n",
      " [    0   124  4932     8]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    5    19     1     0]\n",
      " [   12 29544  5111   192]\n",
      " [    1   891  6364    71]\n",
      " [    0   132    46   151]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       0.99      0.88      0.93     24687\n",
      "           3       0.64      0.97      0.77      5064\n",
      "           4       0.70      1.00      0.83       234\n",
      "\n",
      "    accuracy                           0.90     30000\n",
      "   macro avg       0.82      0.96      0.87     30000\n",
      "weighted avg       0.93      0.90      0.91     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.20      0.23        25\n",
      "           2       0.97      0.85      0.90     34859\n",
      "           3       0.55      0.87      0.68      7327\n",
      "           4       0.36      0.46      0.41       329\n",
      "\n",
      "    accuracy                           0.85     42540\n",
      "   macro avg       0.54      0.59      0.55     42540\n",
      "weighted avg       0.89      0.85      0.86     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=2000,learning_rate=0.1,max_depth=7,verbose=100,\n",
    "                         early_stopping_rounds=500)\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tropical-glossary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2762534\ttotal: 1.24s\tremaining: 3h 26m 28s\n",
      "100:\tlearn: 0.3550597\ttotal: 1m 47s\tremaining: 2h 55m 40s\n",
      "200:\tlearn: 0.2749199\ttotal: 3m 26s\tremaining: 2h 47m 55s\n",
      "300:\tlearn: 0.2348972\ttotal: 5m 7s\tremaining: 2h 44m 52s\n",
      "400:\tlearn: 0.2087168\ttotal: 6m 50s\tremaining: 2h 43m 44s\n",
      "500:\tlearn: 0.1918332\ttotal: 8m 31s\tremaining: 2h 41m 36s\n",
      "600:\tlearn: 0.1784519\ttotal: 10m 15s\tremaining: 2h 40m 19s\n",
      "700:\tlearn: 0.1679582\ttotal: 11m 58s\tremaining: 2h 38m 56s\n",
      "800:\tlearn: 0.1597926\ttotal: 13m 42s\tremaining: 2h 37m 31s\n",
      "900:\tlearn: 0.1521855\ttotal: 15m 28s\tremaining: 2h 36m 16s\n",
      "1000:\tlearn: 0.1457856\ttotal: 17m 12s\tremaining: 2h 34m 45s\n",
      "1100:\tlearn: 0.1401088\ttotal: 18m 58s\tremaining: 2h 33m 20s\n",
      "1200:\tlearn: 0.1349203\ttotal: 20m 44s\tremaining: 2h 32m\n",
      "1300:\tlearn: 0.1303636\ttotal: 22m 32s\tremaining: 2h 30m 41s\n",
      "1400:\tlearn: 0.1263183\ttotal: 24m 18s\tremaining: 2h 29m 10s\n",
      "1500:\tlearn: 0.1220848\ttotal: 26m 4s\tremaining: 2h 27m 39s\n",
      "1600:\tlearn: 0.1183708\ttotal: 27m 51s\tremaining: 2h 26m 8s\n",
      "1700:\tlearn: 0.1149901\ttotal: 29m 36s\tremaining: 2h 24m 28s\n",
      "1800:\tlearn: 0.1118849\ttotal: 31m 22s\tremaining: 2h 22m 48s\n",
      "1900:\tlearn: 0.1088202\ttotal: 33m 8s\tremaining: 2h 21m 12s\n",
      "2000:\tlearn: 0.1058984\ttotal: 34m 58s\tremaining: 2h 19m 47s\n",
      "2100:\tlearn: 0.1033248\ttotal: 36m 44s\tremaining: 2h 18m 8s\n",
      "2200:\tlearn: 0.1008488\ttotal: 38m 30s\tremaining: 2h 16m 27s\n",
      "2300:\tlearn: 0.0984330\ttotal: 40m 16s\tremaining: 2h 14m 45s\n",
      "2400:\tlearn: 0.0962002\ttotal: 42m 2s\tremaining: 2h 13m 3s\n",
      "2500:\tlearn: 0.0942122\ttotal: 43m 47s\tremaining: 2h 11m 18s\n",
      "2600:\tlearn: 0.0921207\ttotal: 45m 32s\tremaining: 2h 9m 34s\n",
      "2700:\tlearn: 0.0902204\ttotal: 47m 18s\tremaining: 2h 7m 51s\n",
      "2800:\tlearn: 0.0883519\ttotal: 49m 8s\tremaining: 2h 6m 17s\n",
      "2900:\tlearn: 0.0865146\ttotal: 50m 53s\tremaining: 2h 4m 32s\n",
      "3000:\tlearn: 0.0848839\ttotal: 52m 38s\tremaining: 2h 2m 46s\n",
      "3100:\tlearn: 0.0831585\ttotal: 54m 29s\tremaining: 2h 1m 13s\n",
      "3200:\tlearn: 0.0815103\ttotal: 56m 19s\tremaining: 1h 59m 38s\n",
      "3300:\tlearn: 0.0799485\ttotal: 58m 6s\tremaining: 1h 57m 54s\n",
      "3400:\tlearn: 0.0784613\ttotal: 59m 51s\tremaining: 1h 56m 8s\n",
      "3500:\tlearn: 0.0770778\ttotal: 1h 1m 39s\tremaining: 1h 54m 26s\n",
      "3600:\tlearn: 0.0757024\ttotal: 1h 3m 26s\tremaining: 1h 52m 43s\n",
      "3700:\tlearn: 0.0743291\ttotal: 1h 5m 17s\tremaining: 1h 51m 8s\n",
      "3800:\tlearn: 0.0730577\ttotal: 1h 7m 5s\tremaining: 1h 49m 24s\n",
      "3900:\tlearn: 0.0717621\ttotal: 1h 8m 52s\tremaining: 1h 47m 41s\n",
      "4000:\tlearn: 0.0704805\ttotal: 1h 10m 41s\tremaining: 1h 45m 58s\n",
      "4100:\tlearn: 0.0693169\ttotal: 1h 12m 28s\tremaining: 1h 44m 15s\n",
      "4200:\tlearn: 0.0681616\ttotal: 1h 14m 19s\tremaining: 1h 42m 35s\n",
      "4300:\tlearn: 0.0670625\ttotal: 1h 16m 7s\tremaining: 1h 40m 52s\n",
      "4400:\tlearn: 0.0659417\ttotal: 1h 17m 55s\tremaining: 1h 39m 7s\n",
      "4500:\tlearn: 0.0649161\ttotal: 1h 19m 42s\tremaining: 1h 37m 22s\n",
      "4600:\tlearn: 0.0638898\ttotal: 1h 21m 31s\tremaining: 1h 35m 40s\n",
      "4700:\tlearn: 0.0628752\ttotal: 1h 23m 20s\tremaining: 1h 33m 56s\n",
      "4800:\tlearn: 0.0618818\ttotal: 1h 25m 9s\tremaining: 1h 32m 13s\n",
      "4900:\tlearn: 0.0608473\ttotal: 1h 27m\tremaining: 1h 30m 31s\n",
      "5000:\tlearn: 0.0598935\ttotal: 1h 28m 47s\tremaining: 1h 28m 45s\n",
      "5100:\tlearn: 0.0590343\ttotal: 1h 30m 34s\tremaining: 1h 26m 59s\n",
      "5200:\tlearn: 0.0581953\ttotal: 1h 32m 22s\tremaining: 1h 25m 14s\n",
      "5300:\tlearn: 0.0573169\ttotal: 1h 34m 13s\tremaining: 1h 23m 31s\n",
      "5400:\tlearn: 0.0564746\ttotal: 1h 36m 1s\tremaining: 1h 21m 45s\n",
      "5500:\tlearn: 0.0556649\ttotal: 1h 37m 50s\tremaining: 1h 20m\n",
      "5600:\tlearn: 0.0548794\ttotal: 1h 39m 37s\tremaining: 1h 18m 14s\n",
      "5700:\tlearn: 0.0540907\ttotal: 1h 41m 24s\tremaining: 1h 16m 28s\n",
      "5800:\tlearn: 0.0532889\ttotal: 1h 43m 14s\tremaining: 1h 14m 43s\n",
      "5900:\tlearn: 0.0525305\ttotal: 1h 45m 2s\tremaining: 1h 12m 58s\n",
      "6000:\tlearn: 0.0517649\ttotal: 1h 46m 53s\tremaining: 1h 11m 13s\n",
      "6100:\tlearn: 0.0510272\ttotal: 1h 48m 46s\tremaining: 1h 9m 30s\n",
      "6200:\tlearn: 0.0502730\ttotal: 1h 50m 37s\tremaining: 1h 7m 46s\n",
      "6300:\tlearn: 0.0496205\ttotal: 1h 52m 28s\tremaining: 1h 6m 1s\n",
      "6400:\tlearn: 0.0489567\ttotal: 1h 54m 17s\tremaining: 1h 4m 15s\n",
      "6500:\tlearn: 0.0482796\ttotal: 1h 56m 6s\tremaining: 1h 2m 29s\n",
      "6600:\tlearn: 0.0475924\ttotal: 1h 57m 57s\tremaining: 1h 44s\n",
      "6700:\tlearn: 0.0469212\ttotal: 1h 59m 48s\tremaining: 58m 58s\n",
      "6800:\tlearn: 0.0462922\ttotal: 2h 1m 39s\tremaining: 57m 13s\n",
      "6900:\tlearn: 0.0456422\ttotal: 2h 3m 29s\tremaining: 55m 27s\n",
      "7000:\tlearn: 0.0450457\ttotal: 2h 5m 17s\tremaining: 53m 40s\n",
      "7100:\tlearn: 0.0444410\ttotal: 2h 7m 4s\tremaining: 51m 52s\n",
      "7200:\tlearn: 0.0438804\ttotal: 2h 8m 50s\tremaining: 50m 4s\n",
      "7300:\tlearn: 0.0433107\ttotal: 2h 10m 40s\tremaining: 48m 18s\n",
      "7400:\tlearn: 0.0427612\ttotal: 2h 12m 28s\tremaining: 46m 31s\n",
      "7500:\tlearn: 0.0422098\ttotal: 2h 14m 17s\tremaining: 44m 44s\n",
      "7600:\tlearn: 0.0416793\ttotal: 2h 16m 7s\tremaining: 42m 57s\n",
      "7700:\tlearn: 0.0411482\ttotal: 2h 17m 57s\tremaining: 41m 11s\n",
      "7800:\tlearn: 0.0406064\ttotal: 2h 19m 49s\tremaining: 39m 24s\n",
      "7900:\tlearn: 0.0400906\ttotal: 2h 21m 36s\tremaining: 37m 37s\n",
      "8000:\tlearn: 0.0396023\ttotal: 2h 23m 27s\tremaining: 35m 50s\n",
      "8100:\tlearn: 0.0391405\ttotal: 2h 25m 16s\tremaining: 34m 3s\n",
      "8200:\tlearn: 0.0386235\ttotal: 2h 27m 6s\tremaining: 32m 16s\n",
      "8300:\tlearn: 0.0381709\ttotal: 2h 28m 54s\tremaining: 30m 28s\n",
      "8400:\tlearn: 0.0377241\ttotal: 2h 30m 43s\tremaining: 28m 41s\n",
      "8500:\tlearn: 0.0372568\ttotal: 2h 32m 31s\tremaining: 26m 53s\n",
      "8600:\tlearn: 0.0368195\ttotal: 2h 34m 19s\tremaining: 25m 6s\n",
      "8700:\tlearn: 0.0363620\ttotal: 2h 36m 9s\tremaining: 23m 18s\n",
      "8800:\tlearn: 0.0359154\ttotal: 2h 37m 56s\tremaining: 21m 31s\n",
      "8900:\tlearn: 0.0355077\ttotal: 2h 39m 47s\tremaining: 19m 43s\n",
      "9000:\tlearn: 0.0350776\ttotal: 2h 41m 40s\tremaining: 17m 56s\n",
      "9100:\tlearn: 0.0346806\ttotal: 2h 43m 28s\tremaining: 16m 8s\n",
      "9200:\tlearn: 0.0342771\ttotal: 2h 45m 18s\tremaining: 14m 21s\n",
      "9300:\tlearn: 0.0338561\ttotal: 2h 47m 6s\tremaining: 12m 33s\n",
      "9400:\tlearn: 0.0334678\ttotal: 2h 48m 56s\tremaining: 10m 45s\n",
      "9500:\tlearn: 0.0330847\ttotal: 2h 50m 48s\tremaining: 8m 58s\n",
      "9600:\tlearn: 0.0327162\ttotal: 2h 52m 35s\tremaining: 7m 10s\n",
      "9700:\tlearn: 0.0323492\ttotal: 2h 54m 25s\tremaining: 5m 22s\n",
      "9800:\tlearn: 0.0319614\ttotal: 2h 56m 16s\tremaining: 3m 34s\n",
      "9900:\tlearn: 0.0316069\ttotal: 2h 58m 5s\tremaining: 1m 46s\n",
      "9999:\tlearn: 0.0312427\ttotal: 2h 59m 55s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    0 24335   326    26]\n",
      " [    0     5  5059     0]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    4    21     0     0]\n",
      " [    7 31489  3293    70]\n",
      " [    0  1705  5592    30]\n",
      " [    0   171    50   108]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      0.99      0.99     24687\n",
      "           3       0.94      1.00      0.97      5064\n",
      "           4       0.90      1.00      0.95       234\n",
      "\n",
      "    accuracy                           0.99     30000\n",
      "   macro avg       0.96      1.00      0.98     30000\n",
      "weighted avg       0.99      0.99      0.99     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.16      0.22        25\n",
      "           2       0.94      0.90      0.92     34859\n",
      "           3       0.63      0.76      0.69      7327\n",
      "           4       0.52      0.33      0.40       329\n",
      "\n",
      "    accuracy                           0.87     42540\n",
      "   macro avg       0.61      0.54      0.56     42540\n",
      "weighted avg       0.88      0.87      0.88     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=10000,learning_rate=0.1,max_depth=7,verbose=100,\n",
    "                         early_stopping_rounds=500)\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "monthly-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train,X_test,X_val,Y_train,Y_test,Y_val,dtree,clf,rfc,xgb,lgbm,cat,logs,pca,scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-importance",
   "metadata": {},
   "source": [
    "Part Ⅱ\n",
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-cleaning",
   "metadata": {},
   "source": [
    "1.划分数据集\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "muslim-melbourne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136125, 311), (42540, 311), (34032, 311), (136125,), (42540,), (34032,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10, stratify=Y)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size=0.2,random_state=10,stratify=Y_train)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape, Y_train.shape, Y_test.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-knock",
   "metadata": {},
   "source": [
    "2.PCA\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "still-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990110731963271\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.999)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "print(len(pca.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sixth-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136125, 111), (42540, 111), (34032, 111))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_val = pca.transform(X_val)\n",
    "\n",
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-transparency",
   "metadata": {},
   "source": [
    "3.OverSampling\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opposite-shelter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 111548), (2, 111548), (3, 111548), (4, 111548)]\n"
     ]
    }
   ],
   "source": [
    "ros = over_sampling.RandomOverSampler(random_state=12)\n",
    "\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(sorted(Counter(Y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-exhaust",
   "metadata": {},
   "source": [
    "4.Model\n",
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-approach",
   "metadata": {},
   "source": [
    "DecisionTree\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "moral-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    0 24652    13    22]\n",
      " [    0     0  5064     0]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    4    18     3     0]\n",
      " [   22 31132  3499   206]\n",
      " [    3  3740  3532    52]\n",
      " [    0   178    52    99]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00     24687\n",
      "           3       1.00      1.00      1.00      5064\n",
      "           4       0.91      1.00      0.96       234\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       0.98      1.00      0.99     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.16      0.15        25\n",
      "           2       0.89      0.89      0.89     34859\n",
      "           3       0.50      0.48      0.49      7327\n",
      "           4       0.28      0.30      0.29       329\n",
      "\n",
      "    accuracy                           0.82     42540\n",
      "   macro avg       0.45      0.46      0.45     42540\n",
      "weighted avg       0.82      0.82      0.82     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "\n",
    "pred_dt = dtree.predict(X_test)\n",
    "y_train_pred = dtree.predict(X_train[:30000])\n",
    "\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "mat_dt = confusion_matrix(Y_test, pred_dt)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_dt}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_dt))\n",
    "\n",
    "del pred_dt, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "embedded-facing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [  717 12906  8449  2615]\n",
      " [  107   383  4311   263]\n",
      " [    3     1    11   219]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    9    10     4     2]\n",
      " [ 1029 18049 12118  3663]\n",
      " [  152   609  6162   404]\n",
      " [    3    43    41   242]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.02      1.00      0.04        15\n",
      "           2       0.97      0.52      0.68     24687\n",
      "           3       0.34      0.85      0.48      5064\n",
      "           4       0.07      0.94      0.13       234\n",
      "\n",
      "    accuracy                           0.58     30000\n",
      "   macro avg       0.35      0.83      0.33     30000\n",
      "weighted avg       0.86      0.58      0.64     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.36      0.01        25\n",
      "           2       0.96      0.52      0.67     34859\n",
      "           3       0.34      0.84      0.48      7327\n",
      "           4       0.06      0.74      0.10       329\n",
      "\n",
      "    accuracy                           0.58     42540\n",
      "   macro avg       0.34      0.61      0.32     42540\n",
      "weighted avg       0.85      0.58      0.64     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[8,10,12,14,16]\n",
    "}\n",
    "clf = GridSearchCV(dtree, param_grid=dt_params,cv=5,scoring='recall',n_jobs=-1)\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(**clf.best_params_)\n",
    "dtree.fit(X_train, Y_train)\n",
    "\n",
    "pred_dt = dtree.predict(X_test)\n",
    "y_train_pred = dtree.predict(X_train[:30000])\n",
    "\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "mat_dt = confusion_matrix(Y_test, pred_dt)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_dt}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_dt))\n",
    "\n",
    "del pred_dt, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-method",
   "metadata": {},
   "source": [
    "RFC\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "honey-correction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    7 19563  4807   310]\n",
      " [    1    71  4942    50]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    5    18     2     0]\n",
      " [    8 26735  7603   513]\n",
      " [    3   857  6310   157]\n",
      " [    0   121    33   175]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      1.00      0.79        15\n",
      "           2       1.00      0.79      0.88     24687\n",
      "           3       0.51      0.98      0.67      5064\n",
      "           4       0.39      1.00      0.57       234\n",
      "\n",
      "    accuracy                           0.83     30000\n",
      "   macro avg       0.64      0.94      0.73     30000\n",
      "weighted avg       0.91      0.83      0.84     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.20      0.24        25\n",
      "           2       0.96      0.77      0.85     34859\n",
      "           3       0.45      0.86      0.59      7327\n",
      "           4       0.21      0.53      0.30       329\n",
      "\n",
      "    accuracy                           0.78     42540\n",
      "   macro avg       0.48      0.59      0.50     42540\n",
      "weighted avg       0.87      0.78      0.80     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=15)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "y_train_pred = rfc.predict(X_train[:30000])\n",
    "\n",
    "mat_rfc = confusion_matrix(Y_test, pred_rfc)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_rfc}\\n\")\n",
    "\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_rfc))\n",
    "\n",
    "del pred_rfc, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "suited-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [   23 17601  5968  1095]\n",
      " [    5   237  4660   162]\n",
      " [    0     0     3   231]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    6    15     4     0]\n",
      " [   29 24429  8787  1614]\n",
      " [    7   661  6354   305]\n",
      " [    0    75    23   231]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      1.00      0.52        15\n",
      "           2       0.99      0.71      0.83     24687\n",
      "           3       0.44      0.92      0.59      5064\n",
      "           4       0.16      0.99      0.27       234\n",
      "\n",
      "    accuracy                           0.75     30000\n",
      "   macro avg       0.48      0.91      0.55     30000\n",
      "weighted avg       0.89      0.75      0.78     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.24      0.18        25\n",
      "           2       0.97      0.70      0.81     34859\n",
      "           3       0.42      0.87      0.56      7327\n",
      "           4       0.11      0.70      0.19       329\n",
      "\n",
      "    accuracy                           0.73     42540\n",
      "   macro avg       0.41      0.63      0.44     42540\n",
      "weighted avg       0.87      0.73      0.77     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_params = {\n",
    "    \"n_estimators\" : [150, 200],\n",
    "    'max_depth' : [11,15,19]\n",
    "}\n",
    "clf = GridSearchCV(rfc, param_grid=rfc_params, scoring='recall',cv=5,n_jobs=-1)\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "rfc = RandomForestClassifier(**clf.best_params_)\n",
    "rfc.fit(X_train,Y_train)\n",
    "\n",
    "pred_rfc = rfc.predict(X_test)\n",
    "y_train_pred = rfc.predict(X_train[:30000])\n",
    "\n",
    "mat_rfc = confusion_matrix(Y_test, pred_rfc)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_rfc}\\n\")\n",
    "\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_rfc))\n",
    "\n",
    "del pred_rfc,y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-emphasis",
   "metadata": {},
   "source": [
    "XGB\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dangerous-absence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    1 19675  4669   342]\n",
      " [    0   228  4796    40]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    5    18     2     0]\n",
      " [    3 27215  7044   597]\n",
      " [    3   823  6354   147]\n",
      " [    0   100    42   187]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       0.99      0.80      0.88     24687\n",
      "           3       0.51      0.95      0.66      5064\n",
      "           4       0.38      1.00      0.55       234\n",
      "\n",
      "    accuracy                           0.82     30000\n",
      "   macro avg       0.70      0.94      0.77     30000\n",
      "weighted avg       0.90      0.82      0.84     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.20      0.28        25\n",
      "           2       0.97      0.78      0.86     34859\n",
      "           3       0.47      0.87      0.61      7327\n",
      "           4       0.20      0.57      0.30       329\n",
      "\n",
      "    accuracy                           0.79     42540\n",
      "   macro avg       0.52      0.60      0.51     42540\n",
      "weighted avg       0.88      0.79      0.82     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, Y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "y_train_pred = xgb.predict(X_train[:30000])\n",
    "\n",
    "mat_xgb = confusion_matrix(Y_test, pred_xgb)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_xgb}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_xgb))\n",
    "\n",
    "del pred_xgb, y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "moral-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:53:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:54:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:54:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:55:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:55:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:56:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:57:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:58:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:59:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:00:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:01:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:02:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:06:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:07:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:09:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:10:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:12:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:15:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:17:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:18:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:20:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:25:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [ 1420 13816  6567  2884]\n",
      " [  124   417  4214   309]\n",
      " [    7     6     9   212]]\n",
      "\n",
      "confusion matrix :\n",
      "[[   13     8     4     0]\n",
      " [ 2087 19403  9367  4002]\n",
      " [  199   616  6050   462]\n",
      " [   17    25    15   272]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      1.00      0.02        15\n",
      "           2       0.97      0.56      0.71     24687\n",
      "           3       0.39      0.83      0.53      5064\n",
      "           4       0.06      0.91      0.12       234\n",
      "\n",
      "    accuracy                           0.61     30000\n",
      "   macro avg       0.36      0.82      0.34     30000\n",
      "weighted avg       0.86      0.61      0.67     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.01      0.52      0.01        25\n",
      "           2       0.97      0.56      0.71     34859\n",
      "           3       0.39      0.83      0.53      7327\n",
      "           4       0.06      0.83      0.11       329\n",
      "\n",
      "    accuracy                           0.61     42540\n",
      "   macro avg       0.36      0.68      0.34     42540\n",
      "weighted avg       0.86      0.61      0.67     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'max_depth' : [1,3,5],\n",
    "    'n_estimators' : [150,200]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(xgb, param_grid=xgb_params,cv=5,scoring='recall')\n",
    "clf.fit(X_val, Y_val)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(**clf.best_params_)\n",
    "xgb.fit(X_train, Y_train)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "y_train_pred = xgb.predict(X_train[:30000])\n",
    "\n",
    "mat_xgb = confusion_matrix(Y_test, pred_xgb)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_xgb}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_xgb))\n",
    "\n",
    "del pred_xgb, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-washington",
   "metadata": {},
   "source": [
    "LGBM\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "immune-presentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    7 18708  5255   717]\n",
      " [    0   361  4606    97]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    6    15     4     0]\n",
      " [   11 26195  7594  1059]\n",
      " [    3   687  6415   222]\n",
      " [    1    74    30   224]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      1.00      0.81        15\n",
      "           2       0.98      0.76      0.86     24687\n",
      "           3       0.47      0.91      0.62      5064\n",
      "           4       0.22      1.00      0.37       234\n",
      "\n",
      "    accuracy                           0.79     30000\n",
      "   macro avg       0.59      0.92      0.66     30000\n",
      "weighted avg       0.89      0.79      0.81     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.24      0.26        25\n",
      "           2       0.97      0.75      0.85     34859\n",
      "           3       0.46      0.88      0.60      7327\n",
      "           4       0.15      0.68      0.24       329\n",
      "\n",
      "    accuracy                           0.77     42540\n",
      "   macro avg       0.47      0.64      0.49     42540\n",
      "weighted avg       0.88      0.77      0.80     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, Y_train)\n",
    "pred_lgbm = lgbm.predict(X_test)\n",
    "y_train_pred = lgbm.predict(X_train[:30000])\n",
    "\n",
    "mat_lgbm = confusion_matrix(Y_test, pred_lgbm)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_lgbm}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_lgbm))\n",
    "\n",
    "del pred_lgbm, y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-container",
   "metadata": {},
   "source": [
    "Catboost\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vulnerable-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.108006\n",
      "0:\tlearn: 1.2775178\ttotal: 640ms\tremaining: 10m 39s\n",
      "1:\tlearn: 1.1960211\ttotal: 1.18s\tremaining: 9m 49s\n",
      "2:\tlearn: 1.1313746\ttotal: 1.71s\tremaining: 9m 28s\n",
      "3:\tlearn: 1.0737064\ttotal: 2.35s\tremaining: 9m 46s\n",
      "4:\tlearn: 1.0241274\ttotal: 3.03s\tremaining: 10m 2s\n",
      "5:\tlearn: 0.9831410\ttotal: 3.64s\tremaining: 10m 3s\n",
      "6:\tlearn: 0.9504112\ttotal: 4.16s\tremaining: 9m 49s\n",
      "7:\tlearn: 0.9180309\ttotal: 4.77s\tremaining: 9m 51s\n",
      "8:\tlearn: 0.8895458\ttotal: 5.31s\tremaining: 9m 45s\n",
      "9:\tlearn: 0.8649228\ttotal: 5.87s\tremaining: 9m 40s\n",
      "10:\tlearn: 0.8434119\ttotal: 6.38s\tremaining: 9m 34s\n",
      "11:\tlearn: 0.8203264\ttotal: 6.96s\tremaining: 9m 32s\n",
      "12:\tlearn: 0.8004093\ttotal: 7.58s\tremaining: 9m 35s\n",
      "13:\tlearn: 0.7835097\ttotal: 8.19s\tremaining: 9m 36s\n",
      "14:\tlearn: 0.7646302\ttotal: 8.76s\tremaining: 9m 35s\n",
      "15:\tlearn: 0.7478352\ttotal: 9.33s\tremaining: 9m 33s\n",
      "16:\tlearn: 0.7372007\ttotal: 9.76s\tremaining: 9m 24s\n",
      "17:\tlearn: 0.7207904\ttotal: 10.5s\tremaining: 9m 30s\n",
      "18:\tlearn: 0.7072275\ttotal: 11s\tremaining: 9m 30s\n",
      "19:\tlearn: 0.6917727\ttotal: 11.7s\tremaining: 9m 32s\n",
      "20:\tlearn: 0.6785706\ttotal: 12.3s\tremaining: 9m 32s\n",
      "21:\tlearn: 0.6649642\ttotal: 12.9s\tremaining: 9m 33s\n",
      "22:\tlearn: 0.6563146\ttotal: 13.4s\tremaining: 9m 29s\n",
      "23:\tlearn: 0.6446592\ttotal: 14.1s\tremaining: 9m 32s\n",
      "24:\tlearn: 0.6347622\ttotal: 14.6s\tremaining: 9m 31s\n",
      "25:\tlearn: 0.6249511\ttotal: 15.2s\tremaining: 9m 28s\n",
      "26:\tlearn: 0.6193544\ttotal: 15.7s\tremaining: 9m 25s\n",
      "27:\tlearn: 0.6111063\ttotal: 16.2s\tremaining: 9m 22s\n",
      "28:\tlearn: 0.6033926\ttotal: 16.8s\tremaining: 9m 21s\n",
      "29:\tlearn: 0.5979257\ttotal: 17.2s\tremaining: 9m 16s\n",
      "30:\tlearn: 0.5889410\ttotal: 17.8s\tremaining: 9m 15s\n",
      "31:\tlearn: 0.5815531\ttotal: 18.4s\tremaining: 9m 15s\n",
      "32:\tlearn: 0.5762764\ttotal: 18.8s\tremaining: 9m 11s\n",
      "33:\tlearn: 0.5709626\ttotal: 19.4s\tremaining: 9m 11s\n",
      "34:\tlearn: 0.5646814\ttotal: 19.9s\tremaining: 9m 8s\n",
      "35:\tlearn: 0.5601409\ttotal: 20.3s\tremaining: 9m 3s\n",
      "36:\tlearn: 0.5551877\ttotal: 20.7s\tremaining: 9m\n",
      "37:\tlearn: 0.5494553\ttotal: 21.4s\tremaining: 9m 1s\n",
      "38:\tlearn: 0.5445734\ttotal: 21.9s\tremaining: 9m\n",
      "39:\tlearn: 0.5398879\ttotal: 22.4s\tremaining: 8m 58s\n",
      "40:\tlearn: 0.5349773\ttotal: 22.9s\tremaining: 8m 56s\n",
      "41:\tlearn: 0.5302563\ttotal: 23.4s\tremaining: 8m 54s\n",
      "42:\tlearn: 0.5262742\ttotal: 23.9s\tremaining: 8m 53s\n",
      "43:\tlearn: 0.5216618\ttotal: 24.5s\tremaining: 8m 52s\n",
      "44:\tlearn: 0.5176745\ttotal: 25s\tremaining: 8m 50s\n",
      "45:\tlearn: 0.5147582\ttotal: 25.5s\tremaining: 8m 49s\n",
      "46:\tlearn: 0.5098702\ttotal: 26.1s\tremaining: 8m 48s\n",
      "47:\tlearn: 0.5054429\ttotal: 26.6s\tremaining: 8m 47s\n",
      "48:\tlearn: 0.5015987\ttotal: 27.2s\tremaining: 8m 47s\n",
      "49:\tlearn: 0.4977388\ttotal: 27.7s\tremaining: 8m 46s\n",
      "50:\tlearn: 0.4946342\ttotal: 28.2s\tremaining: 8m 44s\n",
      "51:\tlearn: 0.4917334\ttotal: 28.6s\tremaining: 8m 41s\n",
      "52:\tlearn: 0.4885588\ttotal: 29.1s\tremaining: 8m 39s\n",
      "53:\tlearn: 0.4854418\ttotal: 29.5s\tremaining: 8m 37s\n",
      "54:\tlearn: 0.4824111\ttotal: 30s\tremaining: 8m 36s\n",
      "55:\tlearn: 0.4788397\ttotal: 30.6s\tremaining: 8m 35s\n",
      "56:\tlearn: 0.4760923\ttotal: 31.2s\tremaining: 8m 35s\n",
      "57:\tlearn: 0.4732748\ttotal: 31.7s\tremaining: 8m 35s\n",
      "58:\tlearn: 0.4706007\ttotal: 32.2s\tremaining: 8m 33s\n",
      "59:\tlearn: 0.4671591\ttotal: 32.8s\tremaining: 8m 33s\n",
      "60:\tlearn: 0.4652519\ttotal: 33.2s\tremaining: 8m 31s\n",
      "61:\tlearn: 0.4624441\ttotal: 33.7s\tremaining: 8m 30s\n",
      "62:\tlearn: 0.4599895\ttotal: 34.3s\tremaining: 8m 30s\n",
      "63:\tlearn: 0.4579184\ttotal: 34.8s\tremaining: 8m 28s\n",
      "64:\tlearn: 0.4564244\ttotal: 35.2s\tremaining: 8m 25s\n",
      "65:\tlearn: 0.4536660\ttotal: 35.7s\tremaining: 8m 25s\n",
      "66:\tlearn: 0.4520455\ttotal: 36.1s\tremaining: 8m 22s\n",
      "67:\tlearn: 0.4502812\ttotal: 36.6s\tremaining: 8m 21s\n",
      "68:\tlearn: 0.4478341\ttotal: 37s\tremaining: 8m 19s\n",
      "69:\tlearn: 0.4463434\ttotal: 37.5s\tremaining: 8m 18s\n",
      "70:\tlearn: 0.4448058\ttotal: 38s\tremaining: 8m 16s\n",
      "71:\tlearn: 0.4433055\ttotal: 38.4s\tremaining: 8m 14s\n",
      "72:\tlearn: 0.4408756\ttotal: 38.9s\tremaining: 8m 13s\n",
      "73:\tlearn: 0.4379081\ttotal: 39.5s\tremaining: 8m 14s\n",
      "74:\tlearn: 0.4364511\ttotal: 40s\tremaining: 8m 12s\n",
      "75:\tlearn: 0.4340166\ttotal: 40.4s\tremaining: 8m 10s\n",
      "76:\tlearn: 0.4317740\ttotal: 40.9s\tremaining: 8m 9s\n",
      "77:\tlearn: 0.4296819\ttotal: 41.4s\tremaining: 8m 9s\n",
      "78:\tlearn: 0.4279197\ttotal: 41.9s\tremaining: 8m 8s\n",
      "79:\tlearn: 0.4258054\ttotal: 42.5s\tremaining: 8m 8s\n",
      "80:\tlearn: 0.4238073\ttotal: 43s\tremaining: 8m 8s\n",
      "81:\tlearn: 0.4219466\ttotal: 43.5s\tremaining: 8m 7s\n",
      "82:\tlearn: 0.4201438\ttotal: 44s\tremaining: 8m 6s\n",
      "83:\tlearn: 0.4182425\ttotal: 44.5s\tremaining: 8m 5s\n",
      "84:\tlearn: 0.4160171\ttotal: 45s\tremaining: 8m 4s\n",
      "85:\tlearn: 0.4145384\ttotal: 45.5s\tremaining: 8m 3s\n",
      "86:\tlearn: 0.4129162\ttotal: 46s\tremaining: 8m 2s\n",
      "87:\tlearn: 0.4110528\ttotal: 46.5s\tremaining: 8m 1s\n",
      "88:\tlearn: 0.4089151\ttotal: 47.1s\tremaining: 8m 1s\n",
      "89:\tlearn: 0.4076092\ttotal: 47.5s\tremaining: 8m\n",
      "90:\tlearn: 0.4058142\ttotal: 48.1s\tremaining: 8m\n",
      "91:\tlearn: 0.4040138\ttotal: 48.7s\tremaining: 8m\n",
      "92:\tlearn: 0.4025656\ttotal: 49.2s\tremaining: 8m\n",
      "93:\tlearn: 0.4012771\ttotal: 49.7s\tremaining: 7m 58s\n",
      "94:\tlearn: 0.3999118\ttotal: 50.2s\tremaining: 7m 58s\n",
      "95:\tlearn: 0.3988544\ttotal: 50.6s\tremaining: 7m 56s\n",
      "96:\tlearn: 0.3975245\ttotal: 51.2s\tremaining: 7m 57s\n",
      "97:\tlearn: 0.3966962\ttotal: 51.6s\tremaining: 7m 55s\n",
      "98:\tlearn: 0.3950441\ttotal: 52.2s\tremaining: 7m 55s\n",
      "99:\tlearn: 0.3939851\ttotal: 52.7s\tremaining: 7m 53s\n",
      "100:\tlearn: 0.3927693\ttotal: 53.2s\tremaining: 7m 53s\n",
      "101:\tlearn: 0.3908106\ttotal: 53.7s\tremaining: 7m 52s\n",
      "102:\tlearn: 0.3898305\ttotal: 54.1s\tremaining: 7m 51s\n",
      "103:\tlearn: 0.3885295\ttotal: 54.6s\tremaining: 7m 50s\n",
      "104:\tlearn: 0.3868765\ttotal: 55.1s\tremaining: 7m 49s\n",
      "105:\tlearn: 0.3859839\ttotal: 55.5s\tremaining: 7m 48s\n",
      "106:\tlearn: 0.3850408\ttotal: 56s\tremaining: 7m 47s\n",
      "107:\tlearn: 0.3834539\ttotal: 56.5s\tremaining: 7m 46s\n",
      "108:\tlearn: 0.3825958\ttotal: 57s\tremaining: 7m 45s\n",
      "109:\tlearn: 0.3819260\ttotal: 57.4s\tremaining: 7m 44s\n",
      "110:\tlearn: 0.3809077\ttotal: 57.8s\tremaining: 7m 42s\n",
      "111:\tlearn: 0.3796520\ttotal: 58.2s\tremaining: 7m 41s\n",
      "112:\tlearn: 0.3782123\ttotal: 58.7s\tremaining: 7m 41s\n",
      "113:\tlearn: 0.3771893\ttotal: 59.2s\tremaining: 7m 40s\n",
      "114:\tlearn: 0.3755807\ttotal: 59.8s\tremaining: 7m 40s\n",
      "115:\tlearn: 0.3748612\ttotal: 1m\tremaining: 7m 39s\n",
      "116:\tlearn: 0.3738374\ttotal: 1m\tremaining: 7m 38s\n",
      "117:\tlearn: 0.3724769\ttotal: 1m 1s\tremaining: 7m 37s\n",
      "118:\tlearn: 0.3713970\ttotal: 1m 1s\tremaining: 7m 36s\n",
      "119:\tlearn: 0.3702525\ttotal: 1m 2s\tremaining: 7m 36s\n",
      "120:\tlearn: 0.3693700\ttotal: 1m 2s\tremaining: 7m 35s\n",
      "121:\tlearn: 0.3685652\ttotal: 1m 3s\tremaining: 7m 34s\n",
      "122:\tlearn: 0.3673436\ttotal: 1m 3s\tremaining: 7m 33s\n",
      "123:\tlearn: 0.3664990\ttotal: 1m 4s\tremaining: 7m 32s\n",
      "124:\tlearn: 0.3653401\ttotal: 1m 4s\tremaining: 7m 32s\n",
      "125:\tlearn: 0.3647671\ttotal: 1m 4s\tremaining: 7m 30s\n",
      "126:\tlearn: 0.3636285\ttotal: 1m 5s\tremaining: 7m 30s\n",
      "127:\tlearn: 0.3624569\ttotal: 1m 5s\tremaining: 7m 29s\n",
      "128:\tlearn: 0.3611420\ttotal: 1m 6s\tremaining: 7m 29s\n",
      "129:\tlearn: 0.3598446\ttotal: 1m 6s\tremaining: 7m 28s\n",
      "130:\tlearn: 0.3588246\ttotal: 1m 7s\tremaining: 7m 27s\n",
      "131:\tlearn: 0.3578871\ttotal: 1m 7s\tremaining: 7m 26s\n",
      "132:\tlearn: 0.3573031\ttotal: 1m 8s\tremaining: 7m 25s\n",
      "133:\tlearn: 0.3567461\ttotal: 1m 8s\tremaining: 7m 24s\n",
      "134:\tlearn: 0.3555532\ttotal: 1m 9s\tremaining: 7m 23s\n",
      "135:\tlearn: 0.3545292\ttotal: 1m 9s\tremaining: 7m 23s\n",
      "136:\tlearn: 0.3536776\ttotal: 1m 10s\tremaining: 7m 22s\n",
      "137:\tlearn: 0.3527564\ttotal: 1m 10s\tremaining: 7m 22s\n",
      "138:\tlearn: 0.3519168\ttotal: 1m 11s\tremaining: 7m 21s\n",
      "139:\tlearn: 0.3509261\ttotal: 1m 11s\tremaining: 7m 20s\n",
      "140:\tlearn: 0.3500820\ttotal: 1m 12s\tremaining: 7m 20s\n",
      "141:\tlearn: 0.3495109\ttotal: 1m 12s\tremaining: 7m 19s\n",
      "142:\tlearn: 0.3487176\ttotal: 1m 13s\tremaining: 7m 19s\n",
      "143:\tlearn: 0.3477863\ttotal: 1m 13s\tremaining: 7m 18s\n",
      "144:\tlearn: 0.3471315\ttotal: 1m 14s\tremaining: 7m 17s\n",
      "145:\tlearn: 0.3465800\ttotal: 1m 14s\tremaining: 7m 16s\n",
      "146:\tlearn: 0.3458195\ttotal: 1m 15s\tremaining: 7m 16s\n",
      "147:\tlearn: 0.3449743\ttotal: 1m 15s\tremaining: 7m 15s\n",
      "148:\tlearn: 0.3440992\ttotal: 1m 16s\tremaining: 7m 14s\n",
      "149:\tlearn: 0.3432553\ttotal: 1m 16s\tremaining: 7m 14s\n",
      "150:\tlearn: 0.3424296\ttotal: 1m 17s\tremaining: 7m 13s\n",
      "151:\tlearn: 0.3416966\ttotal: 1m 17s\tremaining: 7m 13s\n",
      "152:\tlearn: 0.3409598\ttotal: 1m 18s\tremaining: 7m 13s\n",
      "153:\tlearn: 0.3401823\ttotal: 1m 18s\tremaining: 7m 12s\n",
      "154:\tlearn: 0.3393896\ttotal: 1m 19s\tremaining: 7m 11s\n",
      "155:\tlearn: 0.3389513\ttotal: 1m 19s\tremaining: 7m 10s\n",
      "156:\tlearn: 0.3381069\ttotal: 1m 20s\tremaining: 7m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157:\tlearn: 0.3374422\ttotal: 1m 20s\tremaining: 7m 9s\n",
      "158:\tlearn: 0.3366581\ttotal: 1m 21s\tremaining: 7m 8s\n",
      "159:\tlearn: 0.3356324\ttotal: 1m 21s\tremaining: 7m 9s\n",
      "160:\tlearn: 0.3348894\ttotal: 1m 22s\tremaining: 7m 8s\n",
      "161:\tlearn: 0.3342125\ttotal: 1m 22s\tremaining: 7m 7s\n",
      "162:\tlearn: 0.3335222\ttotal: 1m 23s\tremaining: 7m 7s\n",
      "163:\tlearn: 0.3329898\ttotal: 1m 23s\tremaining: 7m 7s\n",
      "164:\tlearn: 0.3321160\ttotal: 1m 24s\tremaining: 7m 7s\n",
      "165:\tlearn: 0.3315168\ttotal: 1m 24s\tremaining: 7m 6s\n",
      "166:\tlearn: 0.3308328\ttotal: 1m 25s\tremaining: 7m 5s\n",
      "167:\tlearn: 0.3300814\ttotal: 1m 25s\tremaining: 7m 4s\n",
      "168:\tlearn: 0.3292913\ttotal: 1m 26s\tremaining: 7m 3s\n",
      "169:\tlearn: 0.3287683\ttotal: 1m 26s\tremaining: 7m 3s\n",
      "170:\tlearn: 0.3283564\ttotal: 1m 27s\tremaining: 7m 2s\n",
      "171:\tlearn: 0.3277937\ttotal: 1m 27s\tremaining: 7m 1s\n",
      "172:\tlearn: 0.3267425\ttotal: 1m 28s\tremaining: 7m 1s\n",
      "173:\tlearn: 0.3260295\ttotal: 1m 28s\tremaining: 7m 1s\n",
      "174:\tlearn: 0.3250557\ttotal: 1m 29s\tremaining: 7m\n",
      "175:\tlearn: 0.3242334\ttotal: 1m 29s\tremaining: 7m\n",
      "176:\tlearn: 0.3235893\ttotal: 1m 30s\tremaining: 6m 59s\n",
      "177:\tlearn: 0.3227670\ttotal: 1m 30s\tremaining: 6m 58s\n",
      "178:\tlearn: 0.3222921\ttotal: 1m 31s\tremaining: 6m 57s\n",
      "179:\tlearn: 0.3218440\ttotal: 1m 31s\tremaining: 6m 56s\n",
      "180:\tlearn: 0.3214581\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "181:\tlearn: 0.3206790\ttotal: 1m 32s\tremaining: 6m 55s\n",
      "182:\tlearn: 0.3202892\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "183:\tlearn: 0.3194783\ttotal: 1m 33s\tremaining: 6m 54s\n",
      "184:\tlearn: 0.3189842\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "185:\tlearn: 0.3185288\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "186:\tlearn: 0.3179418\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "187:\tlearn: 0.3175071\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "188:\tlearn: 0.3164389\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "189:\tlearn: 0.3159583\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "190:\tlearn: 0.3153881\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "191:\tlearn: 0.3147677\ttotal: 1m 37s\tremaining: 6m 49s\n",
      "192:\tlearn: 0.3143846\ttotal: 1m 37s\tremaining: 6m 48s\n",
      "193:\tlearn: 0.3138412\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "194:\tlearn: 0.3131644\ttotal: 1m 38s\tremaining: 6m 47s\n",
      "195:\tlearn: 0.3128065\ttotal: 1m 39s\tremaining: 6m 46s\n",
      "196:\tlearn: 0.3122287\ttotal: 1m 39s\tremaining: 6m 46s\n",
      "197:\tlearn: 0.3115920\ttotal: 1m 40s\tremaining: 6m 45s\n",
      "198:\tlearn: 0.3109752\ttotal: 1m 40s\tremaining: 6m 45s\n",
      "199:\tlearn: 0.3104746\ttotal: 1m 41s\tremaining: 6m 44s\n",
      "200:\tlearn: 0.3100060\ttotal: 1m 41s\tremaining: 6m 44s\n",
      "201:\tlearn: 0.3095274\ttotal: 1m 42s\tremaining: 6m 43s\n",
      "202:\tlearn: 0.3090788\ttotal: 1m 42s\tremaining: 6m 42s\n",
      "203:\tlearn: 0.3083470\ttotal: 1m 43s\tremaining: 6m 42s\n",
      "204:\tlearn: 0.3078201\ttotal: 1m 43s\tremaining: 6m 41s\n",
      "205:\tlearn: 0.3072556\ttotal: 1m 44s\tremaining: 6m 41s\n",
      "206:\tlearn: 0.3069087\ttotal: 1m 44s\tremaining: 6m 40s\n",
      "207:\tlearn: 0.3060898\ttotal: 1m 45s\tremaining: 6m 40s\n",
      "208:\tlearn: 0.3055007\ttotal: 1m 45s\tremaining: 6m 39s\n",
      "209:\tlearn: 0.3049299\ttotal: 1m 46s\tremaining: 6m 39s\n",
      "210:\tlearn: 0.3041593\ttotal: 1m 46s\tremaining: 6m 38s\n",
      "211:\tlearn: 0.3037659\ttotal: 1m 47s\tremaining: 6m 38s\n",
      "212:\tlearn: 0.3034235\ttotal: 1m 47s\tremaining: 6m 37s\n",
      "213:\tlearn: 0.3029792\ttotal: 1m 48s\tremaining: 6m 37s\n",
      "214:\tlearn: 0.3024188\ttotal: 1m 48s\tremaining: 6m 37s\n",
      "215:\tlearn: 0.3015576\ttotal: 1m 49s\tremaining: 6m 37s\n",
      "216:\tlearn: 0.3010389\ttotal: 1m 50s\tremaining: 6m 37s\n",
      "217:\tlearn: 0.3006481\ttotal: 1m 50s\tremaining: 6m 36s\n",
      "218:\tlearn: 0.3001956\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "219:\tlearn: 0.2995659\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "220:\tlearn: 0.2992426\ttotal: 1m 52s\tremaining: 6m 35s\n",
      "221:\tlearn: 0.2989058\ttotal: 1m 52s\tremaining: 6m 34s\n",
      "222:\tlearn: 0.2980735\ttotal: 1m 53s\tremaining: 6m 34s\n",
      "223:\tlearn: 0.2977639\ttotal: 1m 53s\tremaining: 6m 33s\n",
      "224:\tlearn: 0.2972405\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "225:\tlearn: 0.2966671\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "226:\tlearn: 0.2963027\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "227:\tlearn: 0.2955857\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "228:\tlearn: 0.2953114\ttotal: 1m 56s\tremaining: 6m 30s\n",
      "229:\tlearn: 0.2948897\ttotal: 1m 56s\tremaining: 6m 29s\n",
      "230:\tlearn: 0.2944716\ttotal: 1m 56s\tremaining: 6m 29s\n",
      "231:\tlearn: 0.2940710\ttotal: 1m 57s\tremaining: 6m 28s\n",
      "232:\tlearn: 0.2936998\ttotal: 1m 57s\tremaining: 6m 28s\n",
      "233:\tlearn: 0.2934711\ttotal: 1m 58s\tremaining: 6m 27s\n",
      "234:\tlearn: 0.2931026\ttotal: 1m 58s\tremaining: 6m 26s\n",
      "235:\tlearn: 0.2926613\ttotal: 1m 59s\tremaining: 6m 26s\n",
      "236:\tlearn: 0.2923121\ttotal: 1m 59s\tremaining: 6m 25s\n",
      "237:\tlearn: 0.2916093\ttotal: 2m\tremaining: 6m 25s\n",
      "238:\tlearn: 0.2911670\ttotal: 2m\tremaining: 6m 24s\n",
      "239:\tlearn: 0.2906919\ttotal: 2m 1s\tremaining: 6m 24s\n",
      "240:\tlearn: 0.2900059\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "241:\tlearn: 0.2895756\ttotal: 2m 2s\tremaining: 6m 23s\n",
      "242:\tlearn: 0.2892545\ttotal: 2m 2s\tremaining: 6m 23s\n",
      "243:\tlearn: 0.2888996\ttotal: 2m 3s\tremaining: 6m 22s\n",
      "244:\tlearn: 0.2885647\ttotal: 2m 3s\tremaining: 6m 21s\n",
      "245:\tlearn: 0.2880340\ttotal: 2m 4s\tremaining: 6m 21s\n",
      "246:\tlearn: 0.2875193\ttotal: 2m 4s\tremaining: 6m 20s\n",
      "247:\tlearn: 0.2870302\ttotal: 2m 5s\tremaining: 6m 20s\n",
      "248:\tlearn: 0.2866459\ttotal: 2m 5s\tremaining: 6m 19s\n",
      "249:\tlearn: 0.2862881\ttotal: 2m 6s\tremaining: 6m 19s\n",
      "250:\tlearn: 0.2859684\ttotal: 2m 6s\tremaining: 6m 18s\n",
      "251:\tlearn: 0.2856675\ttotal: 2m 7s\tremaining: 6m 17s\n",
      "252:\tlearn: 0.2852599\ttotal: 2m 7s\tremaining: 6m 17s\n",
      "253:\tlearn: 0.2850275\ttotal: 2m 8s\tremaining: 6m 17s\n",
      "254:\tlearn: 0.2847452\ttotal: 2m 8s\tremaining: 6m 16s\n",
      "255:\tlearn: 0.2842083\ttotal: 2m 9s\tremaining: 6m 15s\n",
      "256:\tlearn: 0.2835767\ttotal: 2m 9s\tremaining: 6m 15s\n",
      "257:\tlearn: 0.2831268\ttotal: 2m 10s\tremaining: 6m 15s\n",
      "258:\tlearn: 0.2826320\ttotal: 2m 10s\tremaining: 6m 14s\n",
      "259:\tlearn: 0.2822863\ttotal: 2m 11s\tremaining: 6m 14s\n",
      "260:\tlearn: 0.2818823\ttotal: 2m 12s\tremaining: 6m 13s\n",
      "261:\tlearn: 0.2814688\ttotal: 2m 12s\tremaining: 6m 13s\n",
      "262:\tlearn: 0.2811683\ttotal: 2m 12s\tremaining: 6m 12s\n",
      "263:\tlearn: 0.2807970\ttotal: 2m 13s\tremaining: 6m 12s\n",
      "264:\tlearn: 0.2804171\ttotal: 2m 13s\tremaining: 6m 11s\n",
      "265:\tlearn: 0.2802115\ttotal: 2m 14s\tremaining: 6m 10s\n",
      "266:\tlearn: 0.2798464\ttotal: 2m 14s\tremaining: 6m 10s\n",
      "267:\tlearn: 0.2795786\ttotal: 2m 15s\tremaining: 6m 9s\n",
      "268:\tlearn: 0.2790272\ttotal: 2m 15s\tremaining: 6m 9s\n",
      "269:\tlearn: 0.2785130\ttotal: 2m 16s\tremaining: 6m 8s\n",
      "270:\tlearn: 0.2781994\ttotal: 2m 16s\tremaining: 6m 8s\n",
      "271:\tlearn: 0.2778433\ttotal: 2m 17s\tremaining: 6m 7s\n",
      "272:\tlearn: 0.2774328\ttotal: 2m 18s\tremaining: 6m 7s\n",
      "273:\tlearn: 0.2771691\ttotal: 2m 18s\tremaining: 6m 7s\n",
      "274:\tlearn: 0.2768580\ttotal: 2m 18s\tremaining: 6m 6s\n",
      "275:\tlearn: 0.2765689\ttotal: 2m 19s\tremaining: 6m 5s\n",
      "276:\tlearn: 0.2761688\ttotal: 2m 19s\tremaining: 6m 5s\n",
      "277:\tlearn: 0.2759635\ttotal: 2m 20s\tremaining: 6m 4s\n",
      "278:\tlearn: 0.2756470\ttotal: 2m 20s\tremaining: 6m 3s\n",
      "279:\tlearn: 0.2752739\ttotal: 2m 21s\tremaining: 6m 3s\n",
      "280:\tlearn: 0.2748978\ttotal: 2m 21s\tremaining: 6m 2s\n",
      "281:\tlearn: 0.2744754\ttotal: 2m 22s\tremaining: 6m 2s\n",
      "282:\tlearn: 0.2743069\ttotal: 2m 22s\tremaining: 6m 1s\n",
      "283:\tlearn: 0.2738801\ttotal: 2m 23s\tremaining: 6m 1s\n",
      "284:\tlearn: 0.2734945\ttotal: 2m 23s\tremaining: 6m\n",
      "285:\tlearn: 0.2730961\ttotal: 2m 24s\tremaining: 6m\n",
      "286:\tlearn: 0.2725454\ttotal: 2m 25s\tremaining: 6m\n",
      "287:\tlearn: 0.2720771\ttotal: 2m 25s\tremaining: 5m 59s\n",
      "288:\tlearn: 0.2717311\ttotal: 2m 26s\tremaining: 5m 59s\n",
      "289:\tlearn: 0.2715471\ttotal: 2m 26s\tremaining: 5m 58s\n",
      "290:\tlearn: 0.2712960\ttotal: 2m 26s\tremaining: 5m 57s\n",
      "291:\tlearn: 0.2708382\ttotal: 2m 27s\tremaining: 5m 57s\n",
      "292:\tlearn: 0.2705029\ttotal: 2m 28s\tremaining: 5m 57s\n",
      "293:\tlearn: 0.2702229\ttotal: 2m 28s\tremaining: 5m 56s\n",
      "294:\tlearn: 0.2698980\ttotal: 2m 28s\tremaining: 5m 56s\n",
      "295:\tlearn: 0.2694753\ttotal: 2m 29s\tremaining: 5m 55s\n",
      "296:\tlearn: 0.2691534\ttotal: 2m 30s\tremaining: 5m 55s\n",
      "297:\tlearn: 0.2686765\ttotal: 2m 30s\tremaining: 5m 54s\n",
      "298:\tlearn: 0.2683005\ttotal: 2m 31s\tremaining: 5m 54s\n",
      "299:\tlearn: 0.2678789\ttotal: 2m 31s\tremaining: 5m 54s\n",
      "300:\tlearn: 0.2674899\ttotal: 2m 32s\tremaining: 5m 53s\n",
      "301:\tlearn: 0.2672040\ttotal: 2m 32s\tremaining: 5m 53s\n",
      "302:\tlearn: 0.2667072\ttotal: 2m 33s\tremaining: 5m 52s\n",
      "303:\tlearn: 0.2664738\ttotal: 2m 33s\tremaining: 5m 52s\n",
      "304:\tlearn: 0.2661561\ttotal: 2m 34s\tremaining: 5m 51s\n",
      "305:\tlearn: 0.2659115\ttotal: 2m 34s\tremaining: 5m 51s\n",
      "306:\tlearn: 0.2656545\ttotal: 2m 35s\tremaining: 5m 50s\n",
      "307:\tlearn: 0.2655204\ttotal: 2m 35s\tremaining: 5m 50s\n",
      "308:\tlearn: 0.2652846\ttotal: 2m 36s\tremaining: 5m 49s\n",
      "309:\tlearn: 0.2649029\ttotal: 2m 36s\tremaining: 5m 49s\n",
      "310:\tlearn: 0.2645837\ttotal: 2m 37s\tremaining: 5m 48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311:\tlearn: 0.2642909\ttotal: 2m 37s\tremaining: 5m 48s\n",
      "312:\tlearn: 0.2641355\ttotal: 2m 38s\tremaining: 5m 47s\n",
      "313:\tlearn: 0.2637424\ttotal: 2m 38s\tremaining: 5m 47s\n",
      "314:\tlearn: 0.2634654\ttotal: 2m 39s\tremaining: 5m 46s\n",
      "315:\tlearn: 0.2631581\ttotal: 2m 39s\tremaining: 5m 46s\n",
      "316:\tlearn: 0.2625858\ttotal: 2m 40s\tremaining: 5m 46s\n",
      "317:\tlearn: 0.2622302\ttotal: 2m 41s\tremaining: 5m 45s\n",
      "318:\tlearn: 0.2619246\ttotal: 2m 41s\tremaining: 5m 45s\n",
      "319:\tlearn: 0.2616102\ttotal: 2m 42s\tremaining: 5m 44s\n",
      "320:\tlearn: 0.2613991\ttotal: 2m 42s\tremaining: 5m 44s\n",
      "321:\tlearn: 0.2610172\ttotal: 2m 43s\tremaining: 5m 44s\n",
      "322:\tlearn: 0.2606625\ttotal: 2m 43s\tremaining: 5m 43s\n",
      "323:\tlearn: 0.2602987\ttotal: 2m 44s\tremaining: 5m 43s\n",
      "324:\tlearn: 0.2599361\ttotal: 2m 45s\tremaining: 5m 42s\n",
      "325:\tlearn: 0.2597911\ttotal: 2m 45s\tremaining: 5m 42s\n",
      "326:\tlearn: 0.2594889\ttotal: 2m 46s\tremaining: 5m 41s\n",
      "327:\tlearn: 0.2591429\ttotal: 2m 46s\tremaining: 5m 41s\n",
      "328:\tlearn: 0.2589365\ttotal: 2m 47s\tremaining: 5m 40s\n",
      "329:\tlearn: 0.2584793\ttotal: 2m 47s\tremaining: 5m 40s\n",
      "330:\tlearn: 0.2582444\ttotal: 2m 48s\tremaining: 5m 40s\n",
      "331:\tlearn: 0.2579142\ttotal: 2m 48s\tremaining: 5m 39s\n",
      "332:\tlearn: 0.2573508\ttotal: 2m 49s\tremaining: 5m 39s\n",
      "333:\tlearn: 0.2570240\ttotal: 2m 50s\tremaining: 5m 39s\n",
      "334:\tlearn: 0.2566315\ttotal: 2m 50s\tremaining: 5m 39s\n",
      "335:\tlearn: 0.2563821\ttotal: 2m 51s\tremaining: 5m 38s\n",
      "336:\tlearn: 0.2562031\ttotal: 2m 51s\tremaining: 5m 38s\n",
      "337:\tlearn: 0.2558301\ttotal: 2m 52s\tremaining: 5m 37s\n",
      "338:\tlearn: 0.2556413\ttotal: 2m 52s\tremaining: 5m 36s\n",
      "339:\tlearn: 0.2554232\ttotal: 2m 53s\tremaining: 5m 36s\n",
      "340:\tlearn: 0.2551901\ttotal: 2m 53s\tremaining: 5m 36s\n",
      "341:\tlearn: 0.2549924\ttotal: 2m 54s\tremaining: 5m 35s\n",
      "342:\tlearn: 0.2547810\ttotal: 2m 54s\tremaining: 5m 35s\n",
      "343:\tlearn: 0.2545435\ttotal: 2m 55s\tremaining: 5m 34s\n",
      "344:\tlearn: 0.2541192\ttotal: 2m 56s\tremaining: 5m 34s\n",
      "345:\tlearn: 0.2538604\ttotal: 2m 56s\tremaining: 5m 34s\n",
      "346:\tlearn: 0.2536973\ttotal: 2m 57s\tremaining: 5m 33s\n",
      "347:\tlearn: 0.2532245\ttotal: 2m 57s\tremaining: 5m 33s\n",
      "348:\tlearn: 0.2528940\ttotal: 2m 58s\tremaining: 5m 33s\n",
      "349:\tlearn: 0.2524690\ttotal: 2m 59s\tremaining: 5m 32s\n",
      "350:\tlearn: 0.2522558\ttotal: 2m 59s\tremaining: 5m 32s\n",
      "351:\tlearn: 0.2520824\ttotal: 3m\tremaining: 5m 31s\n",
      "352:\tlearn: 0.2518360\ttotal: 3m\tremaining: 5m 31s\n",
      "353:\tlearn: 0.2515591\ttotal: 3m 1s\tremaining: 5m 30s\n",
      "354:\tlearn: 0.2512035\ttotal: 3m 1s\tremaining: 5m 30s\n",
      "355:\tlearn: 0.2509279\ttotal: 3m 2s\tremaining: 5m 29s\n",
      "356:\tlearn: 0.2508372\ttotal: 3m 2s\tremaining: 5m 29s\n",
      "357:\tlearn: 0.2505466\ttotal: 3m 3s\tremaining: 5m 28s\n",
      "358:\tlearn: 0.2503979\ttotal: 3m 3s\tremaining: 5m 27s\n",
      "359:\tlearn: 0.2501450\ttotal: 3m 4s\tremaining: 5m 27s\n",
      "360:\tlearn: 0.2499084\ttotal: 3m 4s\tremaining: 5m 26s\n",
      "361:\tlearn: 0.2495996\ttotal: 3m 5s\tremaining: 5m 26s\n",
      "362:\tlearn: 0.2494076\ttotal: 3m 5s\tremaining: 5m 25s\n",
      "363:\tlearn: 0.2491601\ttotal: 3m 6s\tremaining: 5m 25s\n",
      "364:\tlearn: 0.2488623\ttotal: 3m 6s\tremaining: 5m 24s\n",
      "365:\tlearn: 0.2485476\ttotal: 3m 7s\tremaining: 5m 24s\n",
      "366:\tlearn: 0.2482609\ttotal: 3m 7s\tremaining: 5m 23s\n",
      "367:\tlearn: 0.2480320\ttotal: 3m 8s\tremaining: 5m 23s\n",
      "368:\tlearn: 0.2477122\ttotal: 3m 8s\tremaining: 5m 22s\n",
      "369:\tlearn: 0.2474294\ttotal: 3m 9s\tremaining: 5m 22s\n",
      "370:\tlearn: 0.2471637\ttotal: 3m 9s\tremaining: 5m 21s\n",
      "371:\tlearn: 0.2469577\ttotal: 3m 10s\tremaining: 5m 21s\n",
      "372:\tlearn: 0.2467287\ttotal: 3m 10s\tremaining: 5m 20s\n",
      "373:\tlearn: 0.2464821\ttotal: 3m 11s\tremaining: 5m 20s\n",
      "374:\tlearn: 0.2462332\ttotal: 3m 11s\tremaining: 5m 19s\n",
      "375:\tlearn: 0.2460327\ttotal: 3m 12s\tremaining: 5m 19s\n",
      "376:\tlearn: 0.2458794\ttotal: 3m 12s\tremaining: 5m 18s\n",
      "377:\tlearn: 0.2456941\ttotal: 3m 13s\tremaining: 5m 17s\n",
      "378:\tlearn: 0.2453964\ttotal: 3m 13s\tremaining: 5m 17s\n",
      "379:\tlearn: 0.2451093\ttotal: 3m 14s\tremaining: 5m 17s\n",
      "380:\tlearn: 0.2449954\ttotal: 3m 15s\tremaining: 5m 16s\n",
      "381:\tlearn: 0.2448220\ttotal: 3m 15s\tremaining: 5m 16s\n",
      "382:\tlearn: 0.2445853\ttotal: 3m 16s\tremaining: 5m 15s\n",
      "383:\tlearn: 0.2443385\ttotal: 3m 16s\tremaining: 5m 15s\n",
      "384:\tlearn: 0.2440241\ttotal: 3m 17s\tremaining: 5m 14s\n",
      "385:\tlearn: 0.2439191\ttotal: 3m 17s\tremaining: 5m 14s\n",
      "386:\tlearn: 0.2437110\ttotal: 3m 18s\tremaining: 5m 13s\n",
      "387:\tlearn: 0.2435044\ttotal: 3m 18s\tremaining: 5m 13s\n",
      "388:\tlearn: 0.2432400\ttotal: 3m 19s\tremaining: 5m 12s\n",
      "389:\tlearn: 0.2429485\ttotal: 3m 19s\tremaining: 5m 12s\n",
      "390:\tlearn: 0.2427820\ttotal: 3m 20s\tremaining: 5m 11s\n",
      "391:\tlearn: 0.2425629\ttotal: 3m 20s\tremaining: 5m 11s\n",
      "392:\tlearn: 0.2422466\ttotal: 3m 21s\tremaining: 5m 10s\n",
      "393:\tlearn: 0.2420418\ttotal: 3m 21s\tremaining: 5m 10s\n",
      "394:\tlearn: 0.2417035\ttotal: 3m 22s\tremaining: 5m 10s\n",
      "395:\tlearn: 0.2415422\ttotal: 3m 23s\tremaining: 5m 9s\n",
      "396:\tlearn: 0.2412439\ttotal: 3m 23s\tremaining: 5m 9s\n",
      "397:\tlearn: 0.2411108\ttotal: 3m 24s\tremaining: 5m 8s\n",
      "398:\tlearn: 0.2409701\ttotal: 3m 24s\tremaining: 5m 8s\n",
      "399:\tlearn: 0.2407273\ttotal: 3m 25s\tremaining: 5m 7s\n",
      "400:\tlearn: 0.2404883\ttotal: 3m 25s\tremaining: 5m 7s\n",
      "401:\tlearn: 0.2403122\ttotal: 3m 26s\tremaining: 5m 6s\n",
      "402:\tlearn: 0.2401229\ttotal: 3m 26s\tremaining: 5m 6s\n",
      "403:\tlearn: 0.2399761\ttotal: 3m 27s\tremaining: 5m 5s\n",
      "404:\tlearn: 0.2397274\ttotal: 3m 27s\tremaining: 5m 5s\n",
      "405:\tlearn: 0.2395740\ttotal: 3m 28s\tremaining: 5m 4s\n",
      "406:\tlearn: 0.2394266\ttotal: 3m 28s\tremaining: 5m 3s\n",
      "407:\tlearn: 0.2392163\ttotal: 3m 29s\tremaining: 5m 3s\n",
      "408:\tlearn: 0.2390607\ttotal: 3m 29s\tremaining: 5m 2s\n",
      "409:\tlearn: 0.2388897\ttotal: 3m 30s\tremaining: 5m 2s\n",
      "410:\tlearn: 0.2385846\ttotal: 3m 30s\tremaining: 5m 1s\n",
      "411:\tlearn: 0.2383284\ttotal: 3m 31s\tremaining: 5m 1s\n",
      "412:\tlearn: 0.2381095\ttotal: 3m 31s\tremaining: 5m\n",
      "413:\tlearn: 0.2378909\ttotal: 3m 32s\tremaining: 5m\n",
      "414:\tlearn: 0.2377111\ttotal: 3m 32s\tremaining: 4m 59s\n",
      "415:\tlearn: 0.2374958\ttotal: 3m 33s\tremaining: 4m 59s\n",
      "416:\tlearn: 0.2373124\ttotal: 3m 33s\tremaining: 4m 58s\n",
      "417:\tlearn: 0.2371656\ttotal: 3m 34s\tremaining: 4m 58s\n",
      "418:\tlearn: 0.2368919\ttotal: 3m 34s\tremaining: 4m 57s\n",
      "419:\tlearn: 0.2367398\ttotal: 3m 35s\tremaining: 4m 57s\n",
      "420:\tlearn: 0.2365917\ttotal: 3m 35s\tremaining: 4m 56s\n",
      "421:\tlearn: 0.2363981\ttotal: 3m 36s\tremaining: 4m 56s\n",
      "422:\tlearn: 0.2362658\ttotal: 3m 36s\tremaining: 4m 55s\n",
      "423:\tlearn: 0.2360875\ttotal: 3m 37s\tremaining: 4m 55s\n",
      "424:\tlearn: 0.2358872\ttotal: 3m 37s\tremaining: 4m 54s\n",
      "425:\tlearn: 0.2355690\ttotal: 3m 38s\tremaining: 4m 54s\n",
      "426:\tlearn: 0.2354293\ttotal: 3m 38s\tremaining: 4m 53s\n",
      "427:\tlearn: 0.2352508\ttotal: 3m 39s\tremaining: 4m 53s\n",
      "428:\tlearn: 0.2350957\ttotal: 3m 39s\tremaining: 4m 52s\n",
      "429:\tlearn: 0.2348822\ttotal: 3m 40s\tremaining: 4m 52s\n",
      "430:\tlearn: 0.2346880\ttotal: 3m 40s\tremaining: 4m 51s\n",
      "431:\tlearn: 0.2345597\ttotal: 3m 41s\tremaining: 4m 51s\n",
      "432:\tlearn: 0.2343105\ttotal: 3m 42s\tremaining: 4m 50s\n",
      "433:\tlearn: 0.2341288\ttotal: 3m 42s\tremaining: 4m 50s\n",
      "434:\tlearn: 0.2339297\ttotal: 3m 42s\tremaining: 4m 49s\n",
      "435:\tlearn: 0.2337559\ttotal: 3m 43s\tremaining: 4m 49s\n",
      "436:\tlearn: 0.2334536\ttotal: 3m 44s\tremaining: 4m 48s\n",
      "437:\tlearn: 0.2331935\ttotal: 3m 44s\tremaining: 4m 48s\n",
      "438:\tlearn: 0.2330894\ttotal: 3m 45s\tremaining: 4m 47s\n",
      "439:\tlearn: 0.2328499\ttotal: 3m 45s\tremaining: 4m 47s\n",
      "440:\tlearn: 0.2325573\ttotal: 3m 46s\tremaining: 4m 46s\n",
      "441:\tlearn: 0.2323598\ttotal: 3m 46s\tremaining: 4m 46s\n",
      "442:\tlearn: 0.2321944\ttotal: 3m 47s\tremaining: 4m 45s\n",
      "443:\tlearn: 0.2320447\ttotal: 3m 47s\tremaining: 4m 45s\n",
      "444:\tlearn: 0.2318581\ttotal: 3m 48s\tremaining: 4m 44s\n",
      "445:\tlearn: 0.2316799\ttotal: 3m 48s\tremaining: 4m 44s\n",
      "446:\tlearn: 0.2315771\ttotal: 3m 49s\tremaining: 4m 43s\n",
      "447:\tlearn: 0.2314925\ttotal: 3m 49s\tremaining: 4m 43s\n",
      "448:\tlearn: 0.2313218\ttotal: 3m 50s\tremaining: 4m 42s\n",
      "449:\tlearn: 0.2311543\ttotal: 3m 50s\tremaining: 4m 41s\n",
      "450:\tlearn: 0.2309778\ttotal: 3m 51s\tremaining: 4m 41s\n",
      "451:\tlearn: 0.2308194\ttotal: 3m 51s\tremaining: 4m 40s\n",
      "452:\tlearn: 0.2306378\ttotal: 3m 52s\tremaining: 4m 40s\n",
      "453:\tlearn: 0.2304168\ttotal: 3m 52s\tremaining: 4m 40s\n",
      "454:\tlearn: 0.2302656\ttotal: 3m 53s\tremaining: 4m 39s\n",
      "455:\tlearn: 0.2299990\ttotal: 3m 54s\tremaining: 4m 39s\n",
      "456:\tlearn: 0.2297943\ttotal: 3m 54s\tremaining: 4m 38s\n",
      "457:\tlearn: 0.2296038\ttotal: 3m 55s\tremaining: 4m 38s\n",
      "458:\tlearn: 0.2294902\ttotal: 3m 55s\tremaining: 4m 37s\n",
      "459:\tlearn: 0.2293673\ttotal: 3m 55s\tremaining: 4m 37s\n",
      "460:\tlearn: 0.2291332\ttotal: 3m 56s\tremaining: 4m 36s\n",
      "461:\tlearn: 0.2289111\ttotal: 3m 57s\tremaining: 4m 36s\n",
      "462:\tlearn: 0.2286654\ttotal: 3m 57s\tremaining: 4m 35s\n",
      "463:\tlearn: 0.2284640\ttotal: 3m 58s\tremaining: 4m 35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464:\tlearn: 0.2282741\ttotal: 3m 58s\tremaining: 4m 34s\n",
      "465:\tlearn: 0.2281600\ttotal: 3m 59s\tremaining: 4m 34s\n",
      "466:\tlearn: 0.2279131\ttotal: 3m 59s\tremaining: 4m 33s\n",
      "467:\tlearn: 0.2277812\ttotal: 4m\tremaining: 4m 33s\n",
      "468:\tlearn: 0.2275917\ttotal: 4m\tremaining: 4m 32s\n",
      "469:\tlearn: 0.2274493\ttotal: 4m 1s\tremaining: 4m 32s\n",
      "470:\tlearn: 0.2273231\ttotal: 4m 1s\tremaining: 4m 31s\n",
      "471:\tlearn: 0.2271719\ttotal: 4m 2s\tremaining: 4m 31s\n",
      "472:\tlearn: 0.2270921\ttotal: 4m 2s\tremaining: 4m 30s\n",
      "473:\tlearn: 0.2269578\ttotal: 4m 3s\tremaining: 4m 29s\n",
      "474:\tlearn: 0.2266933\ttotal: 4m 3s\tremaining: 4m 29s\n",
      "475:\tlearn: 0.2265293\ttotal: 4m 4s\tremaining: 4m 28s\n",
      "476:\tlearn: 0.2262912\ttotal: 4m 4s\tremaining: 4m 28s\n",
      "477:\tlearn: 0.2261858\ttotal: 4m 5s\tremaining: 4m 27s\n",
      "478:\tlearn: 0.2260388\ttotal: 4m 5s\tremaining: 4m 27s\n",
      "479:\tlearn: 0.2258195\ttotal: 4m 6s\tremaining: 4m 27s\n",
      "480:\tlearn: 0.2255287\ttotal: 4m 7s\tremaining: 4m 26s\n",
      "481:\tlearn: 0.2254000\ttotal: 4m 7s\tremaining: 4m 26s\n",
      "482:\tlearn: 0.2252154\ttotal: 4m 8s\tremaining: 4m 25s\n",
      "483:\tlearn: 0.2250763\ttotal: 4m 8s\tremaining: 4m 25s\n",
      "484:\tlearn: 0.2249214\ttotal: 4m 9s\tremaining: 4m 24s\n",
      "485:\tlearn: 0.2247919\ttotal: 4m 9s\tremaining: 4m 24s\n",
      "486:\tlearn: 0.2246653\ttotal: 4m 10s\tremaining: 4m 23s\n",
      "487:\tlearn: 0.2245029\ttotal: 4m 10s\tremaining: 4m 23s\n",
      "488:\tlearn: 0.2243228\ttotal: 4m 11s\tremaining: 4m 22s\n",
      "489:\tlearn: 0.2241511\ttotal: 4m 11s\tremaining: 4m 22s\n",
      "490:\tlearn: 0.2239733\ttotal: 4m 12s\tremaining: 4m 21s\n",
      "491:\tlearn: 0.2237720\ttotal: 4m 13s\tremaining: 4m 21s\n",
      "492:\tlearn: 0.2236345\ttotal: 4m 13s\tremaining: 4m 20s\n",
      "493:\tlearn: 0.2234683\ttotal: 4m 14s\tremaining: 4m 20s\n",
      "494:\tlearn: 0.2232621\ttotal: 4m 14s\tremaining: 4m 19s\n",
      "495:\tlearn: 0.2231322\ttotal: 4m 15s\tremaining: 4m 19s\n",
      "496:\tlearn: 0.2228959\ttotal: 4m 15s\tremaining: 4m 18s\n",
      "497:\tlearn: 0.2227009\ttotal: 4m 16s\tremaining: 4m 18s\n",
      "498:\tlearn: 0.2225978\ttotal: 4m 16s\tremaining: 4m 17s\n",
      "499:\tlearn: 0.2224326\ttotal: 4m 17s\tremaining: 4m 17s\n",
      "500:\tlearn: 0.2223304\ttotal: 4m 17s\tremaining: 4m 16s\n",
      "501:\tlearn: 0.2222280\ttotal: 4m 18s\tremaining: 4m 16s\n",
      "502:\tlearn: 0.2221518\ttotal: 4m 18s\tremaining: 4m 15s\n",
      "503:\tlearn: 0.2219689\ttotal: 4m 19s\tremaining: 4m 15s\n",
      "504:\tlearn: 0.2216298\ttotal: 4m 19s\tremaining: 4m 14s\n",
      "505:\tlearn: 0.2214756\ttotal: 4m 20s\tremaining: 4m 14s\n",
      "506:\tlearn: 0.2213144\ttotal: 4m 21s\tremaining: 4m 13s\n",
      "507:\tlearn: 0.2212200\ttotal: 4m 21s\tremaining: 4m 13s\n",
      "508:\tlearn: 0.2209083\ttotal: 4m 22s\tremaining: 4m 12s\n",
      "509:\tlearn: 0.2207658\ttotal: 4m 22s\tremaining: 4m 12s\n",
      "510:\tlearn: 0.2205583\ttotal: 4m 23s\tremaining: 4m 11s\n",
      "511:\tlearn: 0.2204025\ttotal: 4m 23s\tremaining: 4m 11s\n",
      "512:\tlearn: 0.2202350\ttotal: 4m 24s\tremaining: 4m 10s\n",
      "513:\tlearn: 0.2200971\ttotal: 4m 24s\tremaining: 4m 10s\n",
      "514:\tlearn: 0.2200124\ttotal: 4m 25s\tremaining: 4m 9s\n",
      "515:\tlearn: 0.2197719\ttotal: 4m 25s\tremaining: 4m 9s\n",
      "516:\tlearn: 0.2196319\ttotal: 4m 26s\tremaining: 4m 8s\n",
      "517:\tlearn: 0.2194898\ttotal: 4m 26s\tremaining: 4m 8s\n",
      "518:\tlearn: 0.2192931\ttotal: 4m 27s\tremaining: 4m 7s\n",
      "519:\tlearn: 0.2191520\ttotal: 4m 28s\tremaining: 4m 7s\n",
      "520:\tlearn: 0.2190534\ttotal: 4m 28s\tremaining: 4m 6s\n",
      "521:\tlearn: 0.2189256\ttotal: 4m 29s\tremaining: 4m 6s\n",
      "522:\tlearn: 0.2187282\ttotal: 4m 29s\tremaining: 4m 6s\n",
      "523:\tlearn: 0.2185950\ttotal: 4m 30s\tremaining: 4m 5s\n",
      "524:\tlearn: 0.2184485\ttotal: 4m 30s\tremaining: 4m 5s\n",
      "525:\tlearn: 0.2183465\ttotal: 4m 31s\tremaining: 4m 4s\n",
      "526:\tlearn: 0.2182636\ttotal: 4m 31s\tremaining: 4m 3s\n",
      "527:\tlearn: 0.2180562\ttotal: 4m 32s\tremaining: 4m 3s\n",
      "528:\tlearn: 0.2179547\ttotal: 4m 32s\tremaining: 4m 2s\n",
      "529:\tlearn: 0.2177108\ttotal: 4m 33s\tremaining: 4m 2s\n",
      "530:\tlearn: 0.2175640\ttotal: 4m 34s\tremaining: 4m 2s\n",
      "531:\tlearn: 0.2173684\ttotal: 4m 34s\tremaining: 4m 1s\n",
      "532:\tlearn: 0.2172283\ttotal: 4m 35s\tremaining: 4m 1s\n",
      "533:\tlearn: 0.2170779\ttotal: 4m 35s\tremaining: 4m\n",
      "534:\tlearn: 0.2169207\ttotal: 4m 36s\tremaining: 4m\n",
      "535:\tlearn: 0.2167917\ttotal: 4m 36s\tremaining: 3m 59s\n",
      "536:\tlearn: 0.2166002\ttotal: 4m 37s\tremaining: 3m 59s\n",
      "537:\tlearn: 0.2165206\ttotal: 4m 37s\tremaining: 3m 58s\n",
      "538:\tlearn: 0.2162786\ttotal: 4m 38s\tremaining: 3m 58s\n",
      "539:\tlearn: 0.2161395\ttotal: 4m 38s\tremaining: 3m 57s\n",
      "540:\tlearn: 0.2160778\ttotal: 4m 39s\tremaining: 3m 57s\n",
      "541:\tlearn: 0.2159459\ttotal: 4m 40s\tremaining: 3m 56s\n",
      "542:\tlearn: 0.2158092\ttotal: 4m 40s\tremaining: 3m 56s\n",
      "543:\tlearn: 0.2156340\ttotal: 4m 41s\tremaining: 3m 55s\n",
      "544:\tlearn: 0.2155234\ttotal: 4m 41s\tremaining: 3m 55s\n",
      "545:\tlearn: 0.2154403\ttotal: 4m 42s\tremaining: 3m 54s\n",
      "546:\tlearn: 0.2153703\ttotal: 4m 42s\tremaining: 3m 53s\n",
      "547:\tlearn: 0.2152208\ttotal: 4m 43s\tremaining: 3m 53s\n",
      "548:\tlearn: 0.2151383\ttotal: 4m 43s\tremaining: 3m 52s\n",
      "549:\tlearn: 0.2149526\ttotal: 4m 44s\tremaining: 3m 52s\n",
      "550:\tlearn: 0.2147784\ttotal: 4m 44s\tremaining: 3m 52s\n",
      "551:\tlearn: 0.2146647\ttotal: 4m 45s\tremaining: 3m 51s\n",
      "552:\tlearn: 0.2145274\ttotal: 4m 45s\tremaining: 3m 51s\n",
      "553:\tlearn: 0.2144045\ttotal: 4m 46s\tremaining: 3m 50s\n",
      "554:\tlearn: 0.2142751\ttotal: 4m 46s\tremaining: 3m 50s\n",
      "555:\tlearn: 0.2141603\ttotal: 4m 47s\tremaining: 3m 49s\n",
      "556:\tlearn: 0.2139443\ttotal: 4m 48s\tremaining: 3m 49s\n",
      "557:\tlearn: 0.2138523\ttotal: 4m 48s\tremaining: 3m 48s\n",
      "558:\tlearn: 0.2137716\ttotal: 4m 49s\tremaining: 3m 48s\n",
      "559:\tlearn: 0.2136272\ttotal: 4m 49s\tremaining: 3m 47s\n",
      "560:\tlearn: 0.2134875\ttotal: 4m 50s\tremaining: 3m 47s\n",
      "561:\tlearn: 0.2133707\ttotal: 4m 50s\tremaining: 3m 46s\n",
      "562:\tlearn: 0.2131695\ttotal: 4m 51s\tremaining: 3m 46s\n",
      "563:\tlearn: 0.2130409\ttotal: 4m 51s\tremaining: 3m 45s\n",
      "564:\tlearn: 0.2129634\ttotal: 4m 52s\tremaining: 3m 45s\n",
      "565:\tlearn: 0.2128161\ttotal: 4m 52s\tremaining: 3m 44s\n",
      "566:\tlearn: 0.2126831\ttotal: 4m 53s\tremaining: 3m 44s\n",
      "567:\tlearn: 0.2125296\ttotal: 4m 54s\tremaining: 3m 43s\n",
      "568:\tlearn: 0.2124405\ttotal: 4m 54s\tremaining: 3m 43s\n",
      "569:\tlearn: 0.2122507\ttotal: 4m 55s\tremaining: 3m 42s\n",
      "570:\tlearn: 0.2120621\ttotal: 4m 55s\tremaining: 3m 42s\n",
      "571:\tlearn: 0.2119686\ttotal: 4m 56s\tremaining: 3m 41s\n",
      "572:\tlearn: 0.2119048\ttotal: 4m 56s\tremaining: 3m 41s\n",
      "573:\tlearn: 0.2116445\ttotal: 4m 57s\tremaining: 3m 40s\n",
      "574:\tlearn: 0.2115705\ttotal: 4m 57s\tremaining: 3m 40s\n",
      "575:\tlearn: 0.2114566\ttotal: 4m 58s\tremaining: 3m 39s\n",
      "576:\tlearn: 0.2112594\ttotal: 4m 58s\tremaining: 3m 39s\n",
      "577:\tlearn: 0.2109737\ttotal: 4m 59s\tremaining: 3m 38s\n",
      "578:\tlearn: 0.2108798\ttotal: 5m\tremaining: 3m 38s\n",
      "579:\tlearn: 0.2107796\ttotal: 5m\tremaining: 3m 37s\n",
      "580:\tlearn: 0.2107043\ttotal: 5m 1s\tremaining: 3m 37s\n",
      "581:\tlearn: 0.2105156\ttotal: 5m 1s\tremaining: 3m 36s\n",
      "582:\tlearn: 0.2104386\ttotal: 5m 2s\tremaining: 3m 36s\n",
      "583:\tlearn: 0.2102939\ttotal: 5m 2s\tremaining: 3m 35s\n",
      "584:\tlearn: 0.2101537\ttotal: 5m 3s\tremaining: 3m 35s\n",
      "585:\tlearn: 0.2100311\ttotal: 5m 3s\tremaining: 3m 34s\n",
      "586:\tlearn: 0.2099320\ttotal: 5m 4s\tremaining: 3m 34s\n",
      "587:\tlearn: 0.2096992\ttotal: 5m 4s\tremaining: 3m 33s\n",
      "588:\tlearn: 0.2095643\ttotal: 5m 5s\tremaining: 3m 33s\n",
      "589:\tlearn: 0.2094450\ttotal: 5m 5s\tremaining: 3m 32s\n",
      "590:\tlearn: 0.2092954\ttotal: 5m 6s\tremaining: 3m 32s\n",
      "591:\tlearn: 0.2092270\ttotal: 5m 6s\tremaining: 3m 31s\n",
      "592:\tlearn: 0.2090523\ttotal: 5m 7s\tremaining: 3m 31s\n",
      "593:\tlearn: 0.2089069\ttotal: 5m 7s\tremaining: 3m 30s\n",
      "594:\tlearn: 0.2087776\ttotal: 5m 8s\tremaining: 3m 30s\n",
      "595:\tlearn: 0.2086813\ttotal: 5m 8s\tremaining: 3m 29s\n",
      "596:\tlearn: 0.2086175\ttotal: 5m 9s\tremaining: 3m 28s\n",
      "597:\tlearn: 0.2084792\ttotal: 5m 9s\tremaining: 3m 28s\n",
      "598:\tlearn: 0.2083440\ttotal: 5m 10s\tremaining: 3m 27s\n",
      "599:\tlearn: 0.2082686\ttotal: 5m 10s\tremaining: 3m 27s\n",
      "600:\tlearn: 0.2081711\ttotal: 5m 11s\tremaining: 3m 26s\n",
      "601:\tlearn: 0.2080430\ttotal: 5m 12s\tremaining: 3m 26s\n",
      "602:\tlearn: 0.2079093\ttotal: 5m 12s\tremaining: 3m 25s\n",
      "603:\tlearn: 0.2078388\ttotal: 5m 12s\tremaining: 3m 25s\n",
      "604:\tlearn: 0.2076967\ttotal: 5m 13s\tremaining: 3m 24s\n",
      "605:\tlearn: 0.2075681\ttotal: 5m 14s\tremaining: 3m 24s\n",
      "606:\tlearn: 0.2073841\ttotal: 5m 14s\tremaining: 3m 23s\n",
      "607:\tlearn: 0.2072268\ttotal: 5m 15s\tremaining: 3m 23s\n",
      "608:\tlearn: 0.2070923\ttotal: 5m 15s\tremaining: 3m 22s\n",
      "609:\tlearn: 0.2069966\ttotal: 5m 16s\tremaining: 3m 22s\n",
      "610:\tlearn: 0.2069150\ttotal: 5m 16s\tremaining: 3m 21s\n",
      "611:\tlearn: 0.2068005\ttotal: 5m 17s\tremaining: 3m 21s\n",
      "612:\tlearn: 0.2066817\ttotal: 5m 18s\tremaining: 3m 20s\n",
      "613:\tlearn: 0.2065815\ttotal: 5m 18s\tremaining: 3m 20s\n",
      "614:\tlearn: 0.2064106\ttotal: 5m 19s\tremaining: 3m 19s\n",
      "615:\tlearn: 0.2062605\ttotal: 5m 19s\tremaining: 3m 19s\n",
      "616:\tlearn: 0.2061731\ttotal: 5m 20s\tremaining: 3m 18s\n",
      "617:\tlearn: 0.2061207\ttotal: 5m 20s\tremaining: 3m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618:\tlearn: 0.2060150\ttotal: 5m 21s\tremaining: 3m 17s\n",
      "619:\tlearn: 0.2059292\ttotal: 5m 21s\tremaining: 3m 17s\n",
      "620:\tlearn: 0.2058380\ttotal: 5m 22s\tremaining: 3m 16s\n",
      "621:\tlearn: 0.2057815\ttotal: 5m 22s\tremaining: 3m 16s\n",
      "622:\tlearn: 0.2056755\ttotal: 5m 23s\tremaining: 3m 15s\n",
      "623:\tlearn: 0.2055460\ttotal: 5m 23s\tremaining: 3m 15s\n",
      "624:\tlearn: 0.2054535\ttotal: 5m 24s\tremaining: 3m 14s\n",
      "625:\tlearn: 0.2052934\ttotal: 5m 25s\tremaining: 3m 14s\n",
      "626:\tlearn: 0.2051817\ttotal: 5m 25s\tremaining: 3m 13s\n",
      "627:\tlearn: 0.2051140\ttotal: 5m 26s\tremaining: 3m 13s\n",
      "628:\tlearn: 0.2049954\ttotal: 5m 26s\tremaining: 3m 12s\n",
      "629:\tlearn: 0.2048776\ttotal: 5m 27s\tremaining: 3m 12s\n",
      "630:\tlearn: 0.2047787\ttotal: 5m 27s\tremaining: 3m 11s\n",
      "631:\tlearn: 0.2047056\ttotal: 5m 28s\tremaining: 3m 11s\n",
      "632:\tlearn: 0.2046198\ttotal: 5m 28s\tremaining: 3m 10s\n",
      "633:\tlearn: 0.2045112\ttotal: 5m 29s\tremaining: 3m 10s\n",
      "634:\tlearn: 0.2044145\ttotal: 5m 29s\tremaining: 3m 9s\n",
      "635:\tlearn: 0.2043166\ttotal: 5m 30s\tremaining: 3m 8s\n",
      "636:\tlearn: 0.2042487\ttotal: 5m 30s\tremaining: 3m 8s\n",
      "637:\tlearn: 0.2040853\ttotal: 5m 31s\tremaining: 3m 7s\n",
      "638:\tlearn: 0.2039092\ttotal: 5m 31s\tremaining: 3m 7s\n",
      "639:\tlearn: 0.2037825\ttotal: 5m 32s\tremaining: 3m 6s\n",
      "640:\tlearn: 0.2036781\ttotal: 5m 32s\tremaining: 3m 6s\n",
      "641:\tlearn: 0.2035729\ttotal: 5m 33s\tremaining: 3m 5s\n",
      "642:\tlearn: 0.2034607\ttotal: 5m 33s\tremaining: 3m 5s\n",
      "643:\tlearn: 0.2034003\ttotal: 5m 34s\tremaining: 3m 4s\n",
      "644:\tlearn: 0.2033143\ttotal: 5m 34s\tremaining: 3m 4s\n",
      "645:\tlearn: 0.2032191\ttotal: 5m 35s\tremaining: 3m 3s\n",
      "646:\tlearn: 0.2031434\ttotal: 5m 35s\tremaining: 3m 3s\n",
      "647:\tlearn: 0.2030090\ttotal: 5m 36s\tremaining: 3m 2s\n",
      "648:\tlearn: 0.2029200\ttotal: 5m 36s\tremaining: 3m 2s\n",
      "649:\tlearn: 0.2028205\ttotal: 5m 37s\tremaining: 3m 1s\n",
      "650:\tlearn: 0.2027553\ttotal: 5m 37s\tremaining: 3m 1s\n",
      "651:\tlearn: 0.2026793\ttotal: 5m 38s\tremaining: 3m\n",
      "652:\tlearn: 0.2025210\ttotal: 5m 39s\tremaining: 3m\n",
      "653:\tlearn: 0.2024472\ttotal: 5m 39s\tremaining: 2m 59s\n",
      "654:\tlearn: 0.2023374\ttotal: 5m 40s\tremaining: 2m 59s\n",
      "655:\tlearn: 0.2022162\ttotal: 5m 41s\tremaining: 2m 58s\n",
      "656:\tlearn: 0.2021181\ttotal: 5m 41s\tremaining: 2m 58s\n",
      "657:\tlearn: 0.2020025\ttotal: 5m 42s\tremaining: 2m 57s\n",
      "658:\tlearn: 0.2019162\ttotal: 5m 42s\tremaining: 2m 57s\n",
      "659:\tlearn: 0.2018388\ttotal: 5m 43s\tremaining: 2m 56s\n",
      "660:\tlearn: 0.2017726\ttotal: 5m 43s\tremaining: 2m 56s\n",
      "661:\tlearn: 0.2016406\ttotal: 5m 44s\tremaining: 2m 55s\n",
      "662:\tlearn: 0.2015294\ttotal: 5m 45s\tremaining: 2m 55s\n",
      "663:\tlearn: 0.2014417\ttotal: 5m 45s\tremaining: 2m 54s\n",
      "664:\tlearn: 0.2013835\ttotal: 5m 46s\tremaining: 2m 54s\n",
      "665:\tlearn: 0.2013078\ttotal: 5m 46s\tremaining: 2m 53s\n",
      "666:\tlearn: 0.2011935\ttotal: 5m 47s\tremaining: 2m 53s\n",
      "667:\tlearn: 0.2011304\ttotal: 5m 47s\tremaining: 2m 52s\n",
      "668:\tlearn: 0.2010186\ttotal: 5m 48s\tremaining: 2m 52s\n",
      "669:\tlearn: 0.2008771\ttotal: 5m 48s\tremaining: 2m 51s\n",
      "670:\tlearn: 0.2008085\ttotal: 5m 49s\tremaining: 2m 51s\n",
      "671:\tlearn: 0.2006598\ttotal: 5m 49s\tremaining: 2m 50s\n",
      "672:\tlearn: 0.2006105\ttotal: 5m 50s\tremaining: 2m 50s\n",
      "673:\tlearn: 0.2005349\ttotal: 5m 50s\tremaining: 2m 49s\n",
      "674:\tlearn: 0.2004530\ttotal: 5m 51s\tremaining: 2m 49s\n",
      "675:\tlearn: 0.2003191\ttotal: 5m 51s\tremaining: 2m 48s\n",
      "676:\tlearn: 0.2002454\ttotal: 5m 52s\tremaining: 2m 48s\n",
      "677:\tlearn: 0.2001833\ttotal: 5m 52s\tremaining: 2m 47s\n",
      "678:\tlearn: 0.2001020\ttotal: 5m 53s\tremaining: 2m 46s\n",
      "679:\tlearn: 0.2000037\ttotal: 5m 53s\tremaining: 2m 46s\n",
      "680:\tlearn: 0.1998968\ttotal: 5m 54s\tremaining: 2m 45s\n",
      "681:\tlearn: 0.1998155\ttotal: 5m 54s\tremaining: 2m 45s\n",
      "682:\tlearn: 0.1997050\ttotal: 5m 55s\tremaining: 2m 44s\n",
      "683:\tlearn: 0.1996237\ttotal: 5m 55s\tremaining: 2m 44s\n",
      "684:\tlearn: 0.1995156\ttotal: 5m 56s\tremaining: 2m 43s\n",
      "685:\tlearn: 0.1994159\ttotal: 5m 57s\tremaining: 2m 43s\n",
      "686:\tlearn: 0.1992113\ttotal: 5m 57s\tremaining: 2m 42s\n",
      "687:\tlearn: 0.1991592\ttotal: 5m 58s\tremaining: 2m 42s\n",
      "688:\tlearn: 0.1990871\ttotal: 5m 58s\tremaining: 2m 41s\n",
      "689:\tlearn: 0.1990034\ttotal: 5m 59s\tremaining: 2m 41s\n",
      "690:\tlearn: 0.1989076\ttotal: 5m 59s\tremaining: 2m 40s\n",
      "691:\tlearn: 0.1988098\ttotal: 6m\tremaining: 2m 40s\n",
      "692:\tlearn: 0.1987187\ttotal: 6m\tremaining: 2m 39s\n",
      "693:\tlearn: 0.1986282\ttotal: 6m 1s\tremaining: 2m 39s\n",
      "694:\tlearn: 0.1985513\ttotal: 6m 1s\tremaining: 2m 38s\n",
      "695:\tlearn: 0.1984323\ttotal: 6m 2s\tremaining: 2m 38s\n",
      "696:\tlearn: 0.1983468\ttotal: 6m 2s\tremaining: 2m 37s\n",
      "697:\tlearn: 0.1982025\ttotal: 6m 3s\tremaining: 2m 37s\n",
      "698:\tlearn: 0.1981258\ttotal: 6m 4s\tremaining: 2m 36s\n",
      "699:\tlearn: 0.1980753\ttotal: 6m 4s\tremaining: 2m 36s\n",
      "700:\tlearn: 0.1980011\ttotal: 6m 5s\tremaining: 2m 35s\n",
      "701:\tlearn: 0.1979130\ttotal: 6m 5s\tremaining: 2m 35s\n",
      "702:\tlearn: 0.1978096\ttotal: 6m 6s\tremaining: 2m 34s\n",
      "703:\tlearn: 0.1977579\ttotal: 6m 6s\tremaining: 2m 34s\n",
      "704:\tlearn: 0.1976333\ttotal: 6m 7s\tremaining: 2m 33s\n",
      "705:\tlearn: 0.1975349\ttotal: 6m 7s\tremaining: 2m 33s\n",
      "706:\tlearn: 0.1974186\ttotal: 6m 8s\tremaining: 2m 32s\n",
      "707:\tlearn: 0.1972996\ttotal: 6m 9s\tremaining: 2m 32s\n",
      "708:\tlearn: 0.1972429\ttotal: 6m 9s\tremaining: 2m 31s\n",
      "709:\tlearn: 0.1970490\ttotal: 6m 10s\tremaining: 2m 31s\n",
      "710:\tlearn: 0.1969385\ttotal: 6m 10s\tremaining: 2m 30s\n",
      "711:\tlearn: 0.1967857\ttotal: 6m 11s\tremaining: 2m 30s\n",
      "712:\tlearn: 0.1967071\ttotal: 6m 11s\tremaining: 2m 29s\n",
      "713:\tlearn: 0.1966359\ttotal: 6m 12s\tremaining: 2m 29s\n",
      "714:\tlearn: 0.1965528\ttotal: 6m 12s\tremaining: 2m 28s\n",
      "715:\tlearn: 0.1964824\ttotal: 6m 13s\tremaining: 2m 28s\n",
      "716:\tlearn: 0.1963390\ttotal: 6m 14s\tremaining: 2m 27s\n",
      "717:\tlearn: 0.1962645\ttotal: 6m 14s\tremaining: 2m 27s\n",
      "718:\tlearn: 0.1962139\ttotal: 6m 14s\tremaining: 2m 26s\n",
      "719:\tlearn: 0.1961310\ttotal: 6m 15s\tremaining: 2m 26s\n",
      "720:\tlearn: 0.1960157\ttotal: 6m 16s\tremaining: 2m 25s\n",
      "721:\tlearn: 0.1959118\ttotal: 6m 16s\tremaining: 2m 24s\n",
      "722:\tlearn: 0.1958259\ttotal: 6m 17s\tremaining: 2m 24s\n",
      "723:\tlearn: 0.1957291\ttotal: 6m 17s\tremaining: 2m 23s\n",
      "724:\tlearn: 0.1956634\ttotal: 6m 18s\tremaining: 2m 23s\n",
      "725:\tlearn: 0.1955625\ttotal: 6m 18s\tremaining: 2m 22s\n",
      "726:\tlearn: 0.1954994\ttotal: 6m 19s\tremaining: 2m 22s\n",
      "727:\tlearn: 0.1954224\ttotal: 6m 19s\tremaining: 2m 21s\n",
      "728:\tlearn: 0.1953508\ttotal: 6m 20s\tremaining: 2m 21s\n",
      "729:\tlearn: 0.1952698\ttotal: 6m 20s\tremaining: 2m 20s\n",
      "730:\tlearn: 0.1952276\ttotal: 6m 21s\tremaining: 2m 20s\n",
      "731:\tlearn: 0.1951394\ttotal: 6m 21s\tremaining: 2m 19s\n",
      "732:\tlearn: 0.1950248\ttotal: 6m 22s\tremaining: 2m 19s\n",
      "733:\tlearn: 0.1948772\ttotal: 6m 22s\tremaining: 2m 18s\n",
      "734:\tlearn: 0.1948095\ttotal: 6m 23s\tremaining: 2m 18s\n",
      "735:\tlearn: 0.1947053\ttotal: 6m 23s\tremaining: 2m 17s\n",
      "736:\tlearn: 0.1946268\ttotal: 6m 24s\tremaining: 2m 17s\n",
      "737:\tlearn: 0.1945738\ttotal: 6m 24s\tremaining: 2m 16s\n",
      "738:\tlearn: 0.1945043\ttotal: 6m 25s\tremaining: 2m 16s\n",
      "739:\tlearn: 0.1944290\ttotal: 6m 25s\tremaining: 2m 15s\n",
      "740:\tlearn: 0.1943632\ttotal: 6m 26s\tremaining: 2m 15s\n",
      "741:\tlearn: 0.1942968\ttotal: 6m 26s\tremaining: 2m 14s\n",
      "742:\tlearn: 0.1942304\ttotal: 6m 27s\tremaining: 2m 13s\n",
      "743:\tlearn: 0.1941644\ttotal: 6m 27s\tremaining: 2m 13s\n",
      "744:\tlearn: 0.1941022\ttotal: 6m 28s\tremaining: 2m 12s\n",
      "745:\tlearn: 0.1940477\ttotal: 6m 28s\tremaining: 2m 12s\n",
      "746:\tlearn: 0.1939771\ttotal: 6m 29s\tremaining: 2m 11s\n",
      "747:\tlearn: 0.1939097\ttotal: 6m 29s\tremaining: 2m 11s\n",
      "748:\tlearn: 0.1938402\ttotal: 6m 30s\tremaining: 2m 10s\n",
      "749:\tlearn: 0.1938021\ttotal: 6m 30s\tremaining: 2m 10s\n",
      "750:\tlearn: 0.1936788\ttotal: 6m 31s\tremaining: 2m 9s\n",
      "751:\tlearn: 0.1935920\ttotal: 6m 31s\tremaining: 2m 9s\n",
      "752:\tlearn: 0.1935350\ttotal: 6m 32s\tremaining: 2m 8s\n",
      "753:\tlearn: 0.1934129\ttotal: 6m 32s\tremaining: 2m 8s\n",
      "754:\tlearn: 0.1933585\ttotal: 6m 33s\tremaining: 2m 7s\n",
      "755:\tlearn: 0.1933073\ttotal: 6m 33s\tremaining: 2m 7s\n",
      "756:\tlearn: 0.1932453\ttotal: 6m 34s\tremaining: 2m 6s\n",
      "757:\tlearn: 0.1931689\ttotal: 6m 34s\tremaining: 2m 5s\n",
      "758:\tlearn: 0.1930898\ttotal: 6m 35s\tremaining: 2m 5s\n",
      "759:\tlearn: 0.1930104\ttotal: 6m 35s\tremaining: 2m 4s\n",
      "760:\tlearn: 0.1929306\ttotal: 6m 36s\tremaining: 2m 4s\n",
      "761:\tlearn: 0.1928246\ttotal: 6m 36s\tremaining: 2m 3s\n",
      "762:\tlearn: 0.1927710\ttotal: 6m 37s\tremaining: 2m 3s\n",
      "763:\tlearn: 0.1927239\ttotal: 6m 37s\tremaining: 2m 2s\n",
      "764:\tlearn: 0.1926389\ttotal: 6m 38s\tremaining: 2m 2s\n",
      "765:\tlearn: 0.1925796\ttotal: 6m 38s\tremaining: 2m 1s\n",
      "766:\tlearn: 0.1923896\ttotal: 6m 39s\tremaining: 2m 1s\n",
      "767:\tlearn: 0.1922065\ttotal: 6m 39s\tremaining: 2m\n",
      "768:\tlearn: 0.1921285\ttotal: 6m 40s\tremaining: 2m\n",
      "769:\tlearn: 0.1920274\ttotal: 6m 40s\tremaining: 1m 59s\n",
      "770:\tlearn: 0.1919467\ttotal: 6m 41s\tremaining: 1m 59s\n",
      "771:\tlearn: 0.1918954\ttotal: 6m 42s\tremaining: 1m 58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772:\tlearn: 0.1918273\ttotal: 6m 42s\tremaining: 1m 58s\n",
      "773:\tlearn: 0.1917486\ttotal: 6m 42s\tremaining: 1m 57s\n",
      "774:\tlearn: 0.1916437\ttotal: 6m 43s\tremaining: 1m 57s\n",
      "775:\tlearn: 0.1915682\ttotal: 6m 44s\tremaining: 1m 56s\n",
      "776:\tlearn: 0.1914774\ttotal: 6m 44s\tremaining: 1m 56s\n",
      "777:\tlearn: 0.1914055\ttotal: 6m 45s\tremaining: 1m 55s\n",
      "778:\tlearn: 0.1913323\ttotal: 6m 45s\tremaining: 1m 55s\n",
      "779:\tlearn: 0.1912797\ttotal: 6m 46s\tremaining: 1m 54s\n",
      "780:\tlearn: 0.1912095\ttotal: 6m 46s\tremaining: 1m 53s\n",
      "781:\tlearn: 0.1911384\ttotal: 6m 47s\tremaining: 1m 53s\n",
      "782:\tlearn: 0.1910772\ttotal: 6m 47s\tremaining: 1m 52s\n",
      "783:\tlearn: 0.1910050\ttotal: 6m 48s\tremaining: 1m 52s\n",
      "784:\tlearn: 0.1909191\ttotal: 6m 48s\tremaining: 1m 51s\n",
      "785:\tlearn: 0.1908577\ttotal: 6m 49s\tremaining: 1m 51s\n",
      "786:\tlearn: 0.1908003\ttotal: 6m 49s\tremaining: 1m 50s\n",
      "787:\tlearn: 0.1907151\ttotal: 6m 50s\tremaining: 1m 50s\n",
      "788:\tlearn: 0.1906177\ttotal: 6m 50s\tremaining: 1m 49s\n",
      "789:\tlearn: 0.1904825\ttotal: 6m 51s\tremaining: 1m 49s\n",
      "790:\tlearn: 0.1904043\ttotal: 6m 51s\tremaining: 1m 48s\n",
      "791:\tlearn: 0.1903104\ttotal: 6m 52s\tremaining: 1m 48s\n",
      "792:\tlearn: 0.1901984\ttotal: 6m 52s\tremaining: 1m 47s\n",
      "793:\tlearn: 0.1901580\ttotal: 6m 53s\tremaining: 1m 47s\n",
      "794:\tlearn: 0.1900778\ttotal: 6m 53s\tremaining: 1m 46s\n",
      "795:\tlearn: 0.1899656\ttotal: 6m 54s\tremaining: 1m 46s\n",
      "796:\tlearn: 0.1899098\ttotal: 6m 54s\tremaining: 1m 45s\n",
      "797:\tlearn: 0.1898520\ttotal: 6m 55s\tremaining: 1m 45s\n",
      "798:\tlearn: 0.1897555\ttotal: 6m 55s\tremaining: 1m 44s\n",
      "799:\tlearn: 0.1896936\ttotal: 6m 56s\tremaining: 1m 44s\n",
      "800:\tlearn: 0.1895693\ttotal: 6m 56s\tremaining: 1m 43s\n",
      "801:\tlearn: 0.1894855\ttotal: 6m 57s\tremaining: 1m 43s\n",
      "802:\tlearn: 0.1894005\ttotal: 6m 57s\tremaining: 1m 42s\n",
      "803:\tlearn: 0.1892988\ttotal: 6m 58s\tremaining: 1m 42s\n",
      "804:\tlearn: 0.1892487\ttotal: 6m 59s\tremaining: 1m 41s\n",
      "805:\tlearn: 0.1891787\ttotal: 6m 59s\tremaining: 1m 40s\n",
      "806:\tlearn: 0.1890979\ttotal: 7m\tremaining: 1m 40s\n",
      "807:\tlearn: 0.1890317\ttotal: 7m\tremaining: 1m 39s\n",
      "808:\tlearn: 0.1888485\ttotal: 7m 1s\tremaining: 1m 39s\n",
      "809:\tlearn: 0.1886563\ttotal: 7m 1s\tremaining: 1m 38s\n",
      "810:\tlearn: 0.1885764\ttotal: 7m 2s\tremaining: 1m 38s\n",
      "811:\tlearn: 0.1884356\ttotal: 7m 2s\tremaining: 1m 37s\n",
      "812:\tlearn: 0.1883402\ttotal: 7m 3s\tremaining: 1m 37s\n",
      "813:\tlearn: 0.1882919\ttotal: 7m 4s\tremaining: 1m 36s\n",
      "814:\tlearn: 0.1882282\ttotal: 7m 4s\tremaining: 1m 36s\n",
      "815:\tlearn: 0.1881965\ttotal: 7m 4s\tremaining: 1m 35s\n",
      "816:\tlearn: 0.1881236\ttotal: 7m 5s\tremaining: 1m 35s\n",
      "817:\tlearn: 0.1880189\ttotal: 7m 5s\tremaining: 1m 34s\n",
      "818:\tlearn: 0.1879267\ttotal: 7m 6s\tremaining: 1m 34s\n",
      "819:\tlearn: 0.1878364\ttotal: 7m 6s\tremaining: 1m 33s\n",
      "820:\tlearn: 0.1877255\ttotal: 7m 7s\tremaining: 1m 33s\n",
      "821:\tlearn: 0.1875990\ttotal: 7m 8s\tremaining: 1m 32s\n",
      "822:\tlearn: 0.1875305\ttotal: 7m 8s\tremaining: 1m 32s\n",
      "823:\tlearn: 0.1874877\ttotal: 7m 9s\tremaining: 1m 31s\n",
      "824:\tlearn: 0.1874035\ttotal: 7m 9s\tremaining: 1m 31s\n",
      "825:\tlearn: 0.1872973\ttotal: 7m 10s\tremaining: 1m 30s\n",
      "826:\tlearn: 0.1872504\ttotal: 7m 10s\tremaining: 1m 30s\n",
      "827:\tlearn: 0.1871543\ttotal: 7m 11s\tremaining: 1m 29s\n",
      "828:\tlearn: 0.1870367\ttotal: 7m 11s\tremaining: 1m 29s\n",
      "829:\tlearn: 0.1869429\ttotal: 7m 12s\tremaining: 1m 28s\n",
      "830:\tlearn: 0.1868279\ttotal: 7m 12s\tremaining: 1m 28s\n",
      "831:\tlearn: 0.1867630\ttotal: 7m 13s\tremaining: 1m 27s\n",
      "832:\tlearn: 0.1867159\ttotal: 7m 13s\tremaining: 1m 26s\n",
      "833:\tlearn: 0.1866576\ttotal: 7m 14s\tremaining: 1m 26s\n",
      "834:\tlearn: 0.1865769\ttotal: 7m 14s\tremaining: 1m 25s\n",
      "835:\tlearn: 0.1865272\ttotal: 7m 15s\tremaining: 1m 25s\n",
      "836:\tlearn: 0.1864672\ttotal: 7m 15s\tremaining: 1m 24s\n",
      "837:\tlearn: 0.1864154\ttotal: 7m 16s\tremaining: 1m 24s\n",
      "838:\tlearn: 0.1863530\ttotal: 7m 16s\tremaining: 1m 23s\n",
      "839:\tlearn: 0.1862866\ttotal: 7m 17s\tremaining: 1m 23s\n",
      "840:\tlearn: 0.1862048\ttotal: 7m 17s\tremaining: 1m 22s\n",
      "841:\tlearn: 0.1861720\ttotal: 7m 18s\tremaining: 1m 22s\n",
      "842:\tlearn: 0.1860436\ttotal: 7m 18s\tremaining: 1m 21s\n",
      "843:\tlearn: 0.1859285\ttotal: 7m 19s\tremaining: 1m 21s\n",
      "844:\tlearn: 0.1858721\ttotal: 7m 19s\tremaining: 1m 20s\n",
      "845:\tlearn: 0.1858178\ttotal: 7m 20s\tremaining: 1m 20s\n",
      "846:\tlearn: 0.1857222\ttotal: 7m 21s\tremaining: 1m 19s\n",
      "847:\tlearn: 0.1856066\ttotal: 7m 21s\tremaining: 1m 19s\n",
      "848:\tlearn: 0.1855630\ttotal: 7m 22s\tremaining: 1m 18s\n",
      "849:\tlearn: 0.1855023\ttotal: 7m 22s\tremaining: 1m 18s\n",
      "850:\tlearn: 0.1854433\ttotal: 7m 23s\tremaining: 1m 17s\n",
      "851:\tlearn: 0.1854090\ttotal: 7m 23s\tremaining: 1m 17s\n",
      "852:\tlearn: 0.1853737\ttotal: 7m 24s\tremaining: 1m 16s\n",
      "853:\tlearn: 0.1853035\ttotal: 7m 24s\tremaining: 1m 16s\n",
      "854:\tlearn: 0.1852114\ttotal: 7m 25s\tremaining: 1m 15s\n",
      "855:\tlearn: 0.1851627\ttotal: 7m 25s\tremaining: 1m 14s\n",
      "856:\tlearn: 0.1850500\ttotal: 7m 26s\tremaining: 1m 14s\n",
      "857:\tlearn: 0.1849850\ttotal: 7m 26s\tremaining: 1m 13s\n",
      "858:\tlearn: 0.1849146\ttotal: 7m 27s\tremaining: 1m 13s\n",
      "859:\tlearn: 0.1848419\ttotal: 7m 27s\tremaining: 1m 12s\n",
      "860:\tlearn: 0.1847448\ttotal: 7m 28s\tremaining: 1m 12s\n",
      "861:\tlearn: 0.1846813\ttotal: 7m 28s\tremaining: 1m 11s\n",
      "862:\tlearn: 0.1846058\ttotal: 7m 29s\tremaining: 1m 11s\n",
      "863:\tlearn: 0.1845304\ttotal: 7m 29s\tremaining: 1m 10s\n",
      "864:\tlearn: 0.1844818\ttotal: 7m 30s\tremaining: 1m 10s\n",
      "865:\tlearn: 0.1844156\ttotal: 7m 30s\tremaining: 1m 9s\n",
      "866:\tlearn: 0.1843605\ttotal: 7m 31s\tremaining: 1m 9s\n",
      "867:\tlearn: 0.1842606\ttotal: 7m 31s\tremaining: 1m 8s\n",
      "868:\tlearn: 0.1842305\ttotal: 7m 32s\tremaining: 1m 8s\n",
      "869:\tlearn: 0.1842044\ttotal: 7m 32s\tremaining: 1m 7s\n",
      "870:\tlearn: 0.1840920\ttotal: 7m 33s\tremaining: 1m 7s\n",
      "871:\tlearn: 0.1840569\ttotal: 7m 33s\tremaining: 1m 6s\n",
      "872:\tlearn: 0.1839990\ttotal: 7m 34s\tremaining: 1m 6s\n",
      "873:\tlearn: 0.1839313\ttotal: 7m 34s\tremaining: 1m 5s\n",
      "874:\tlearn: 0.1838856\ttotal: 7m 35s\tremaining: 1m 5s\n",
      "875:\tlearn: 0.1838083\ttotal: 7m 36s\tremaining: 1m 4s\n",
      "876:\tlearn: 0.1837210\ttotal: 7m 36s\tremaining: 1m 4s\n",
      "877:\tlearn: 0.1836843\ttotal: 7m 37s\tremaining: 1m 3s\n",
      "878:\tlearn: 0.1836155\ttotal: 7m 37s\tremaining: 1m 2s\n",
      "879:\tlearn: 0.1835217\ttotal: 7m 38s\tremaining: 1m 2s\n",
      "880:\tlearn: 0.1834705\ttotal: 7m 38s\tremaining: 1m 1s\n",
      "881:\tlearn: 0.1834081\ttotal: 7m 39s\tremaining: 1m 1s\n",
      "882:\tlearn: 0.1832883\ttotal: 7m 40s\tremaining: 1m\n",
      "883:\tlearn: 0.1832504\ttotal: 7m 40s\tremaining: 1m\n",
      "884:\tlearn: 0.1832019\ttotal: 7m 41s\tremaining: 59.9s\n",
      "885:\tlearn: 0.1831207\ttotal: 7m 41s\tremaining: 59.4s\n",
      "886:\tlearn: 0.1830730\ttotal: 7m 42s\tremaining: 58.9s\n",
      "887:\tlearn: 0.1830274\ttotal: 7m 42s\tremaining: 58.4s\n",
      "888:\tlearn: 0.1829681\ttotal: 7m 43s\tremaining: 57.9s\n",
      "889:\tlearn: 0.1828903\ttotal: 7m 43s\tremaining: 57.3s\n",
      "890:\tlearn: 0.1828101\ttotal: 7m 44s\tremaining: 56.8s\n",
      "891:\tlearn: 0.1826995\ttotal: 7m 45s\tremaining: 56.3s\n",
      "892:\tlearn: 0.1826198\ttotal: 7m 45s\tremaining: 55.8s\n",
      "893:\tlearn: 0.1825460\ttotal: 7m 46s\tremaining: 55.3s\n",
      "894:\tlearn: 0.1824878\ttotal: 7m 46s\tremaining: 54.8s\n",
      "895:\tlearn: 0.1824096\ttotal: 7m 47s\tremaining: 54.2s\n",
      "896:\tlearn: 0.1823331\ttotal: 7m 47s\tremaining: 53.7s\n",
      "897:\tlearn: 0.1822860\ttotal: 7m 48s\tremaining: 53.2s\n",
      "898:\tlearn: 0.1821724\ttotal: 7m 48s\tremaining: 52.7s\n",
      "899:\tlearn: 0.1821208\ttotal: 7m 49s\tremaining: 52.2s\n",
      "900:\tlearn: 0.1820598\ttotal: 7m 50s\tremaining: 51.7s\n",
      "901:\tlearn: 0.1820041\ttotal: 7m 50s\tremaining: 51.1s\n",
      "902:\tlearn: 0.1819608\ttotal: 7m 51s\tremaining: 50.6s\n",
      "903:\tlearn: 0.1818859\ttotal: 7m 51s\tremaining: 50.1s\n",
      "904:\tlearn: 0.1818052\ttotal: 7m 52s\tremaining: 49.6s\n",
      "905:\tlearn: 0.1817080\ttotal: 7m 53s\tremaining: 49.1s\n",
      "906:\tlearn: 0.1815972\ttotal: 7m 53s\tremaining: 48.6s\n",
      "907:\tlearn: 0.1815484\ttotal: 7m 54s\tremaining: 48s\n",
      "908:\tlearn: 0.1814829\ttotal: 7m 54s\tremaining: 47.5s\n",
      "909:\tlearn: 0.1814304\ttotal: 7m 55s\tremaining: 47s\n",
      "910:\tlearn: 0.1813486\ttotal: 7m 55s\tremaining: 46.5s\n",
      "911:\tlearn: 0.1813078\ttotal: 7m 56s\tremaining: 45.9s\n",
      "912:\tlearn: 0.1812283\ttotal: 7m 56s\tremaining: 45.4s\n",
      "913:\tlearn: 0.1811851\ttotal: 7m 57s\tremaining: 44.9s\n",
      "914:\tlearn: 0.1811031\ttotal: 7m 57s\tremaining: 44.4s\n",
      "915:\tlearn: 0.1810568\ttotal: 7m 58s\tremaining: 43.9s\n",
      "916:\tlearn: 0.1809868\ttotal: 7m 58s\tremaining: 43.3s\n",
      "917:\tlearn: 0.1809244\ttotal: 7m 59s\tremaining: 42.8s\n",
      "918:\tlearn: 0.1808144\ttotal: 7m 59s\tremaining: 42.3s\n",
      "919:\tlearn: 0.1807645\ttotal: 8m\tremaining: 41.8s\n",
      "920:\tlearn: 0.1806709\ttotal: 8m\tremaining: 41.2s\n",
      "921:\tlearn: 0.1806258\ttotal: 8m 1s\tremaining: 40.7s\n",
      "922:\tlearn: 0.1806023\ttotal: 8m 1s\tremaining: 40.2s\n",
      "923:\tlearn: 0.1805660\ttotal: 8m 2s\tremaining: 39.7s\n",
      "924:\tlearn: 0.1805181\ttotal: 8m 2s\tremaining: 39.1s\n",
      "925:\tlearn: 0.1804112\ttotal: 8m 3s\tremaining: 38.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926:\tlearn: 0.1803536\ttotal: 8m 3s\tremaining: 38.1s\n",
      "927:\tlearn: 0.1803075\ttotal: 8m 4s\tremaining: 37.6s\n",
      "928:\tlearn: 0.1802529\ttotal: 8m 4s\tremaining: 37s\n",
      "929:\tlearn: 0.1801508\ttotal: 8m 5s\tremaining: 36.5s\n",
      "930:\tlearn: 0.1800801\ttotal: 8m 5s\tremaining: 36s\n",
      "931:\tlearn: 0.1800358\ttotal: 8m 6s\tremaining: 35.5s\n",
      "932:\tlearn: 0.1799874\ttotal: 8m 6s\tremaining: 35s\n",
      "933:\tlearn: 0.1799342\ttotal: 8m 7s\tremaining: 34.4s\n",
      "934:\tlearn: 0.1798557\ttotal: 8m 7s\tremaining: 33.9s\n",
      "935:\tlearn: 0.1798182\ttotal: 8m 8s\tremaining: 33.4s\n",
      "936:\tlearn: 0.1797706\ttotal: 8m 8s\tremaining: 32.9s\n",
      "937:\tlearn: 0.1797238\ttotal: 8m 9s\tremaining: 32.3s\n",
      "938:\tlearn: 0.1796745\ttotal: 8m 9s\tremaining: 31.8s\n",
      "939:\tlearn: 0.1796078\ttotal: 8m 10s\tremaining: 31.3s\n",
      "940:\tlearn: 0.1795188\ttotal: 8m 10s\tremaining: 30.8s\n",
      "941:\tlearn: 0.1794482\ttotal: 8m 11s\tremaining: 30.3s\n",
      "942:\tlearn: 0.1793905\ttotal: 8m 12s\tremaining: 29.7s\n",
      "943:\tlearn: 0.1793611\ttotal: 8m 12s\tremaining: 29.2s\n",
      "944:\tlearn: 0.1793257\ttotal: 8m 12s\tremaining: 28.7s\n",
      "945:\tlearn: 0.1792664\ttotal: 8m 13s\tremaining: 28.2s\n",
      "946:\tlearn: 0.1791779\ttotal: 8m 14s\tremaining: 27.7s\n",
      "947:\tlearn: 0.1791367\ttotal: 8m 14s\tremaining: 27.1s\n",
      "948:\tlearn: 0.1790909\ttotal: 8m 15s\tremaining: 26.6s\n",
      "949:\tlearn: 0.1790108\ttotal: 8m 15s\tremaining: 26.1s\n",
      "950:\tlearn: 0.1789664\ttotal: 8m 16s\tremaining: 25.6s\n",
      "951:\tlearn: 0.1789067\ttotal: 8m 16s\tremaining: 25s\n",
      "952:\tlearn: 0.1788703\ttotal: 8m 17s\tremaining: 24.5s\n",
      "953:\tlearn: 0.1788346\ttotal: 8m 17s\tremaining: 24s\n",
      "954:\tlearn: 0.1787778\ttotal: 8m 17s\tremaining: 23.5s\n",
      "955:\tlearn: 0.1786633\ttotal: 8m 18s\tremaining: 22.9s\n",
      "956:\tlearn: 0.1785863\ttotal: 8m 19s\tremaining: 22.4s\n",
      "957:\tlearn: 0.1785570\ttotal: 8m 19s\tremaining: 21.9s\n",
      "958:\tlearn: 0.1785067\ttotal: 8m 20s\tremaining: 21.4s\n",
      "959:\tlearn: 0.1784506\ttotal: 8m 20s\tremaining: 20.9s\n",
      "960:\tlearn: 0.1784065\ttotal: 8m 21s\tremaining: 20.3s\n",
      "961:\tlearn: 0.1783449\ttotal: 8m 21s\tremaining: 19.8s\n",
      "962:\tlearn: 0.1782932\ttotal: 8m 22s\tremaining: 19.3s\n",
      "963:\tlearn: 0.1781902\ttotal: 8m 22s\tremaining: 18.8s\n",
      "964:\tlearn: 0.1781179\ttotal: 8m 23s\tremaining: 18.3s\n",
      "965:\tlearn: 0.1780276\ttotal: 8m 23s\tremaining: 17.7s\n",
      "966:\tlearn: 0.1779719\ttotal: 8m 24s\tremaining: 17.2s\n",
      "967:\tlearn: 0.1779097\ttotal: 8m 24s\tremaining: 16.7s\n",
      "968:\tlearn: 0.1778398\ttotal: 8m 25s\tremaining: 16.2s\n",
      "969:\tlearn: 0.1777833\ttotal: 8m 25s\tremaining: 15.6s\n",
      "970:\tlearn: 0.1777346\ttotal: 8m 26s\tremaining: 15.1s\n",
      "971:\tlearn: 0.1776811\ttotal: 8m 26s\tremaining: 14.6s\n",
      "972:\tlearn: 0.1776027\ttotal: 8m 27s\tremaining: 14.1s\n",
      "973:\tlearn: 0.1775661\ttotal: 8m 27s\tremaining: 13.6s\n",
      "974:\tlearn: 0.1775124\ttotal: 8m 28s\tremaining: 13s\n",
      "975:\tlearn: 0.1774780\ttotal: 8m 28s\tremaining: 12.5s\n",
      "976:\tlearn: 0.1773701\ttotal: 8m 29s\tremaining: 12s\n",
      "977:\tlearn: 0.1772805\ttotal: 8m 30s\tremaining: 11.5s\n",
      "978:\tlearn: 0.1772102\ttotal: 8m 30s\tremaining: 11s\n",
      "979:\tlearn: 0.1771811\ttotal: 8m 31s\tremaining: 10.4s\n",
      "980:\tlearn: 0.1770571\ttotal: 8m 31s\tremaining: 9.91s\n",
      "981:\tlearn: 0.1769752\ttotal: 8m 32s\tremaining: 9.39s\n",
      "982:\tlearn: 0.1769061\ttotal: 8m 32s\tremaining: 8.87s\n",
      "983:\tlearn: 0.1768438\ttotal: 8m 33s\tremaining: 8.35s\n",
      "984:\tlearn: 0.1767822\ttotal: 8m 34s\tremaining: 7.83s\n",
      "985:\tlearn: 0.1766881\ttotal: 8m 34s\tremaining: 7.31s\n",
      "986:\tlearn: 0.1766278\ttotal: 8m 35s\tremaining: 6.79s\n",
      "987:\tlearn: 0.1765773\ttotal: 8m 35s\tremaining: 6.26s\n",
      "988:\tlearn: 0.1764703\ttotal: 8m 36s\tremaining: 5.74s\n",
      "989:\tlearn: 0.1763878\ttotal: 8m 37s\tremaining: 5.22s\n",
      "990:\tlearn: 0.1763318\ttotal: 8m 37s\tremaining: 4.7s\n",
      "991:\tlearn: 0.1762494\ttotal: 8m 38s\tremaining: 4.18s\n",
      "992:\tlearn: 0.1762090\ttotal: 8m 38s\tremaining: 3.65s\n",
      "993:\tlearn: 0.1761194\ttotal: 8m 39s\tremaining: 3.13s\n",
      "994:\tlearn: 0.1760487\ttotal: 8m 39s\tremaining: 2.61s\n",
      "995:\tlearn: 0.1759932\ttotal: 8m 40s\tremaining: 2.09s\n",
      "996:\tlearn: 0.1759493\ttotal: 8m 40s\tremaining: 1.57s\n",
      "997:\tlearn: 0.1758704\ttotal: 8m 41s\tremaining: 1.04s\n",
      "998:\tlearn: 0.1757747\ttotal: 8m 41s\tremaining: 522ms\n",
      "999:\tlearn: 0.1756812\ttotal: 8m 42s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [   18 19736  4542   391]\n",
      " [    3   271  4739    51]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    6    15     4     0]\n",
      " [   26 27324  6898   611]\n",
      " [    5   759  6414   149]\n",
      " [    0    94    37   198]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      1.00      0.59        15\n",
      "           2       0.99      0.80      0.88     24687\n",
      "           3       0.51      0.94      0.66      5064\n",
      "           4       0.35      1.00      0.51       234\n",
      "\n",
      "    accuracy                           0.82     30000\n",
      "   macro avg       0.56      0.93      0.66     30000\n",
      "weighted avg       0.90      0.82      0.84     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.24      0.19        25\n",
      "           2       0.97      0.78      0.87     34859\n",
      "           3       0.48      0.88      0.62      7327\n",
      "           4       0.21      0.60      0.31       329\n",
      "\n",
      "    accuracy                           0.80     42540\n",
      "   macro avg       0.45      0.63      0.50     42540\n",
      "weighted avg       0.88      0.80      0.82     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier()\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alpine-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2733535\ttotal: 706ms\tremaining: 23m 31s\n",
      "100:\tlearn: 0.3597656\ttotal: 1m 4s\tremaining: 20m 22s\n",
      "200:\tlearn: 0.2816706\ttotal: 2m 5s\tremaining: 18m 42s\n",
      "300:\tlearn: 0.2412878\ttotal: 3m 8s\tremaining: 17m 41s\n",
      "400:\tlearn: 0.2164067\ttotal: 4m 11s\tremaining: 16m 44s\n",
      "500:\tlearn: 0.1993755\ttotal: 5m 16s\tremaining: 15m 46s\n",
      "600:\tlearn: 0.1865392\ttotal: 6m 21s\tremaining: 14m 47s\n",
      "700:\tlearn: 0.1765208\ttotal: 7m 24s\tremaining: 13m 44s\n",
      "800:\tlearn: 0.1682405\ttotal: 8m 29s\tremaining: 12m 42s\n",
      "900:\tlearn: 0.1614147\ttotal: 9m 33s\tremaining: 11m 39s\n",
      "1000:\tlearn: 0.1551755\ttotal: 10m 37s\tremaining: 10m 36s\n",
      "1100:\tlearn: 0.1495718\ttotal: 11m 43s\tremaining: 9m 34s\n",
      "1200:\tlearn: 0.1442189\ttotal: 12m 48s\tremaining: 8m 31s\n",
      "1300:\tlearn: 0.1396994\ttotal: 13m 52s\tremaining: 7m 27s\n",
      "1400:\tlearn: 0.1354558\ttotal: 14m 57s\tremaining: 6m 23s\n",
      "1500:\tlearn: 0.1315181\ttotal: 16m 1s\tremaining: 5m 19s\n",
      "1600:\tlearn: 0.1278580\ttotal: 17m 4s\tremaining: 4m 15s\n",
      "1700:\tlearn: 0.1245630\ttotal: 18m 7s\tremaining: 3m 11s\n",
      "1800:\tlearn: 0.1214251\ttotal: 19m 12s\tremaining: 2m 7s\n",
      "1900:\tlearn: 0.1183691\ttotal: 20m 17s\tremaining: 1m 3s\n",
      "1999:\tlearn: 0.1155393\ttotal: 21m 21s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    0 21481  3115    91]\n",
      " [    0   151  4907     6]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    4    20     1     0]\n",
      " [   10 29004  5663   182]\n",
      " [    4  1091  6165    67]\n",
      " [    0   127    52   150]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       0.99      0.87      0.93     24687\n",
      "           3       0.61      0.97      0.75      5064\n",
      "           4       0.71      1.00      0.83       234\n",
      "\n",
      "    accuracy                           0.89     30000\n",
      "   macro avg       0.83      0.96      0.88     30000\n",
      "weighted avg       0.93      0.89      0.90     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.22      0.16      0.19        25\n",
      "           2       0.96      0.83      0.89     34859\n",
      "           3       0.52      0.84      0.64      7327\n",
      "           4       0.38      0.46      0.41       329\n",
      "\n",
      "    accuracy                           0.83     42540\n",
      "   macro avg       0.52      0.57      0.53     42540\n",
      "weighted avg       0.88      0.83      0.84     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=2000,learning_rate=0.1,max_depth=7,verbose=100,\n",
    "                         early_stopping_rounds=500)\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "floral-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.2733535\ttotal: 720ms\tremaining: 1h 59m 58s\n",
      "100:\tlearn: 0.3597656\ttotal: 1m 5s\tremaining: 1h 47m 10s\n",
      "200:\tlearn: 0.2816706\ttotal: 2m 7s\tremaining: 1h 43m 28s\n",
      "300:\tlearn: 0.2412878\ttotal: 3m 10s\tremaining: 1h 42m 28s\n",
      "400:\tlearn: 0.2164067\ttotal: 4m 15s\tremaining: 1h 41m 55s\n",
      "500:\tlearn: 0.1993755\ttotal: 5m 20s\tremaining: 1h 41m 22s\n",
      "600:\tlearn: 0.1865392\ttotal: 6m 28s\tremaining: 1h 41m 22s\n",
      "700:\tlearn: 0.1765208\ttotal: 7m 35s\tremaining: 1h 40m 45s\n",
      "800:\tlearn: 0.1682405\ttotal: 8m 41s\tremaining: 1h 39m 43s\n",
      "900:\tlearn: 0.1614147\ttotal: 9m 45s\tremaining: 1h 38m 32s\n",
      "1000:\tlearn: 0.1551755\ttotal: 10m 51s\tremaining: 1h 37m 35s\n",
      "1100:\tlearn: 0.1495718\ttotal: 11m 57s\tremaining: 1h 36m 35s\n",
      "1200:\tlearn: 0.1442189\ttotal: 13m 2s\tremaining: 1h 35m 34s\n",
      "1300:\tlearn: 0.1396994\ttotal: 14m 6s\tremaining: 1h 34m 22s\n",
      "1400:\tlearn: 0.1354558\ttotal: 15m 12s\tremaining: 1h 33m 22s\n",
      "1500:\tlearn: 0.1315181\ttotal: 16m 17s\tremaining: 1h 32m 14s\n",
      "1600:\tlearn: 0.1278580\ttotal: 17m 21s\tremaining: 1h 31m 6s\n",
      "1700:\tlearn: 0.1245630\ttotal: 18m 26s\tremaining: 1h 29m 56s\n",
      "1800:\tlearn: 0.1214251\ttotal: 19m 32s\tremaining: 1h 28m 59s\n",
      "1900:\tlearn: 0.1183691\ttotal: 20m 44s\tremaining: 1h 28m 19s\n",
      "2000:\tlearn: 0.1155065\ttotal: 21m 52s\tremaining: 1h 27m 25s\n",
      "2100:\tlearn: 0.1130467\ttotal: 23m 2s\tremaining: 1h 26m 38s\n",
      "2200:\tlearn: 0.1104833\ttotal: 24m 11s\tremaining: 1h 25m 43s\n",
      "2300:\tlearn: 0.1080488\ttotal: 25m 18s\tremaining: 1h 24m 41s\n",
      "2400:\tlearn: 0.1058707\ttotal: 26m 23s\tremaining: 1h 23m 32s\n",
      "2500:\tlearn: 0.1035679\ttotal: 27m 30s\tremaining: 1h 22m 28s\n",
      "2600:\tlearn: 0.1013371\ttotal: 28m 39s\tremaining: 1h 21m 30s\n",
      "2700:\tlearn: 0.0993982\ttotal: 29m 46s\tremaining: 1h 20m 28s\n",
      "2800:\tlearn: 0.0974350\ttotal: 30m 57s\tremaining: 1h 19m 34s\n",
      "2900:\tlearn: 0.0956298\ttotal: 32m 1s\tremaining: 1h 18m 22s\n",
      "3000:\tlearn: 0.0937282\ttotal: 33m 8s\tremaining: 1h 17m 17s\n",
      "3100:\tlearn: 0.0918779\ttotal: 34m 14s\tremaining: 1h 16m 10s\n",
      "3200:\tlearn: 0.0901310\ttotal: 35m 20s\tremaining: 1h 15m 4s\n",
      "3300:\tlearn: 0.0886031\ttotal: 36m 25s\tremaining: 1h 13m 54s\n",
      "3400:\tlearn: 0.0869603\ttotal: 37m 31s\tremaining: 1h 12m 49s\n",
      "3500:\tlearn: 0.0853455\ttotal: 38m 38s\tremaining: 1h 11m 43s\n",
      "3600:\tlearn: 0.0838297\ttotal: 39m 46s\tremaining: 1h 10m 41s\n",
      "3700:\tlearn: 0.0823414\ttotal: 40m 59s\tremaining: 1h 9m 45s\n",
      "3800:\tlearn: 0.0808838\ttotal: 42m 9s\tremaining: 1h 8m 45s\n",
      "3900:\tlearn: 0.0795889\ttotal: 43m 17s\tremaining: 1h 7m 40s\n",
      "4000:\tlearn: 0.0782538\ttotal: 44m 26s\tremaining: 1h 6m 38s\n",
      "4100:\tlearn: 0.0769362\ttotal: 45m 35s\tremaining: 1h 5m 34s\n",
      "4200:\tlearn: 0.0756216\ttotal: 46m 45s\tremaining: 1h 4m 32s\n",
      "4300:\tlearn: 0.0743781\ttotal: 47m 55s\tremaining: 1h 3m 29s\n",
      "4400:\tlearn: 0.0732401\ttotal: 49m 2s\tremaining: 1h 2m 24s\n",
      "4500:\tlearn: 0.0721038\ttotal: 50m 11s\tremaining: 1h 1m 19s\n",
      "4600:\tlearn: 0.0709929\ttotal: 51m 19s\tremaining: 1h 13s\n",
      "4700:\tlearn: 0.0699013\ttotal: 52m 26s\tremaining: 59m 6s\n",
      "4800:\tlearn: 0.0688615\ttotal: 53m 33s\tremaining: 57m 59s\n",
      "4900:\tlearn: 0.0677430\ttotal: 54m 40s\tremaining: 56m 53s\n",
      "5000:\tlearn: 0.0666814\ttotal: 55m 50s\tremaining: 55m 49s\n",
      "5100:\tlearn: 0.0657152\ttotal: 57m 2s\tremaining: 54m 47s\n",
      "5200:\tlearn: 0.0646413\ttotal: 58m 13s\tremaining: 53m 43s\n",
      "5300:\tlearn: 0.0636311\ttotal: 59m 21s\tremaining: 52m 36s\n",
      "5400:\tlearn: 0.0626715\ttotal: 1h 31s\tremaining: 51m 31s\n",
      "5500:\tlearn: 0.0617237\ttotal: 1h 1m 38s\tremaining: 50m 24s\n",
      "5600:\tlearn: 0.0608221\ttotal: 1h 2m 49s\tremaining: 49m 20s\n",
      "5700:\tlearn: 0.0599994\ttotal: 1h 4m\tremaining: 48m 16s\n",
      "5800:\tlearn: 0.0591546\ttotal: 1h 5m 9s\tremaining: 47m 9s\n",
      "5900:\tlearn: 0.0583894\ttotal: 1h 6m 18s\tremaining: 46m 3s\n",
      "6000:\tlearn: 0.0574603\ttotal: 1h 7m 31s\tremaining: 44m 59s\n",
      "6100:\tlearn: 0.0566321\ttotal: 1h 8m 41s\tremaining: 43m 53s\n",
      "6200:\tlearn: 0.0558595\ttotal: 1h 9m 52s\tremaining: 42m 48s\n",
      "6300:\tlearn: 0.0550765\ttotal: 1h 11m 7s\tremaining: 41m 45s\n",
      "6400:\tlearn: 0.0543569\ttotal: 1h 12m 17s\tremaining: 40m 38s\n",
      "6500:\tlearn: 0.0535944\ttotal: 1h 13m 39s\tremaining: 39m 38s\n",
      "6600:\tlearn: 0.0528617\ttotal: 1h 14m 55s\tremaining: 38m 34s\n",
      "6700:\tlearn: 0.0521371\ttotal: 1h 16m 8s\tremaining: 37m 29s\n",
      "6800:\tlearn: 0.0514441\ttotal: 1h 17m 20s\tremaining: 36m 22s\n",
      "6900:\tlearn: 0.0508163\ttotal: 1h 18m 33s\tremaining: 35m 16s\n",
      "7000:\tlearn: 0.0501191\ttotal: 1h 19m 48s\tremaining: 34m 11s\n",
      "7100:\tlearn: 0.0494811\ttotal: 1h 21m 3s\tremaining: 33m 5s\n",
      "7200:\tlearn: 0.0488363\ttotal: 1h 22m 18s\tremaining: 31m 59s\n",
      "7300:\tlearn: 0.0482005\ttotal: 1h 23m 34s\tremaining: 30m 53s\n",
      "7400:\tlearn: 0.0475696\ttotal: 1h 25m\tremaining: 29m 51s\n",
      "7500:\tlearn: 0.0469933\ttotal: 1h 26m 30s\tremaining: 28m 49s\n",
      "7600:\tlearn: 0.0463942\ttotal: 1h 28m 1s\tremaining: 27m 46s\n",
      "7700:\tlearn: 0.0458049\ttotal: 1h 29m 28s\tremaining: 26m 42s\n",
      "7800:\tlearn: 0.0452560\ttotal: 1h 30m 45s\tremaining: 25m 34s\n",
      "7900:\tlearn: 0.0446892\ttotal: 1h 32m 4s\tremaining: 24m 27s\n",
      "8000:\tlearn: 0.0441274\ttotal: 1h 33m 17s\tremaining: 23m 18s\n",
      "8100:\tlearn: 0.0435608\ttotal: 1h 34m 34s\tremaining: 22m 10s\n",
      "8200:\tlearn: 0.0430015\ttotal: 1h 35m 48s\tremaining: 21m 1s\n",
      "8300:\tlearn: 0.0424421\ttotal: 1h 37m 4s\tremaining: 19m 52s\n",
      "8400:\tlearn: 0.0419445\ttotal: 1h 38m 14s\tremaining: 18m 41s\n",
      "8500:\tlearn: 0.0414154\ttotal: 1h 39m 23s\tremaining: 17m 31s\n",
      "8600:\tlearn: 0.0409184\ttotal: 1h 40m 34s\tremaining: 16m 21s\n",
      "8700:\tlearn: 0.0404190\ttotal: 1h 41m 47s\tremaining: 15m 11s\n",
      "8800:\tlearn: 0.0399455\ttotal: 1h 43m 1s\tremaining: 14m 2s\n",
      "8900:\tlearn: 0.0394608\ttotal: 1h 44m 15s\tremaining: 12m 52s\n",
      "9000:\tlearn: 0.0389938\ttotal: 1h 45m 27s\tremaining: 11m 42s\n",
      "9100:\tlearn: 0.0385283\ttotal: 1h 46m 38s\tremaining: 10m 32s\n",
      "9200:\tlearn: 0.0380607\ttotal: 1h 47m 54s\tremaining: 9m 22s\n",
      "9300:\tlearn: 0.0376311\ttotal: 1h 49m 9s\tremaining: 8m 12s\n",
      "9400:\tlearn: 0.0371998\ttotal: 1h 50m 21s\tremaining: 7m 1s\n",
      "9500:\tlearn: 0.0367555\ttotal: 1h 51m 35s\tremaining: 5m 51s\n",
      "9600:\tlearn: 0.0363787\ttotal: 1h 52m 47s\tremaining: 4m 41s\n",
      "9700:\tlearn: 0.0359573\ttotal: 1h 53m 59s\tremaining: 3m 30s\n",
      "9800:\tlearn: 0.0355634\ttotal: 1h 55m 10s\tremaining: 2m 20s\n",
      "9900:\tlearn: 0.0351649\ttotal: 1h 56m 20s\tremaining: 1m 9s\n",
      "9999:\tlearn: 0.0347683\ttotal: 1h 57m 30s\tremaining: 0us\n",
      "confusion matrix :\n",
      "[[   15     0     0     0]\n",
      " [    0 24305   357    25]\n",
      " [    0     7  5057     0]\n",
      " [    0     0     0   234]]\n",
      "\n",
      "confusion matrix :\n",
      "[[    4    21     0     0]\n",
      " [    8 31251  3532    68]\n",
      " [    4  2030  5269    24]\n",
      " [    0   163    47   119]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      0.98      0.99     24687\n",
      "           3       0.93      1.00      0.97      5064\n",
      "           4       0.90      1.00      0.95       234\n",
      "\n",
      "    accuracy                           0.99     30000\n",
      "   macro avg       0.96      1.00      0.98     30000\n",
      "weighted avg       0.99      0.99      0.99     30000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.16      0.20        25\n",
      "           2       0.93      0.90      0.91     34859\n",
      "           3       0.60      0.72      0.65      7327\n",
      "           4       0.56      0.36      0.44       329\n",
      "\n",
      "    accuracy                           0.86     42540\n",
      "   macro avg       0.59      0.53      0.55     42540\n",
      "weighted avg       0.87      0.86      0.87     42540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier(iterations=10000,learning_rate=0.1,max_depth=7,verbose=100,\n",
    "                         early_stopping_rounds=500)\n",
    "logs = cat.fit(X_train, Y_train)\n",
    "\n",
    "pred_cat = cat.predict(X_test)\n",
    "y_train_pred = cat.predict(X_train[:30000])\n",
    "\n",
    "mat_cat = confusion_matrix(Y_test, pred_cat)\n",
    "mat_train = confusion_matrix(Y_train[:30000],y_train_pred)\n",
    "\n",
    "print(f\"confusion matrix :\\n{mat_train}\\n\")\n",
    "print(f\"confusion matrix :\\n{mat_cat}\\n\")\n",
    "print(classification_report(Y_train[:30000],y_train_pred))\n",
    "print(classification_report(Y_test, pred_cat))\n",
    "\n",
    "del pred_cat,y_train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-korea",
   "metadata": {},
   "source": [
    "Result\n",
    "="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "recognized-criterion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Severity-1</th>\n",
       "      <th>Severity-2</th>\n",
       "      <th>Severity-3</th>\n",
       "      <th>Severity-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DTree-0.9999</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFC1-0.9999</td>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RFC2-0.9999</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>87</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB-0.9999</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM-0.9999</td>\n",
       "      <td>32</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CAT-0.9999</td>\n",
       "      <td>32</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DTree-0.999</td>\n",
       "      <td>36</td>\n",
       "      <td>52</td>\n",
       "      <td>84</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RFC-0.999</td>\n",
       "      <td>24</td>\n",
       "      <td>70</td>\n",
       "      <td>87</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB1-0.999</td>\n",
       "      <td>20</td>\n",
       "      <td>78</td>\n",
       "      <td>87</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGB2-0.999</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBM-0.999</td>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>88</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CAT-0.999</td>\n",
       "      <td>24</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Severity-1  Severity-2  Severity-3  Severity-4\n",
       "0   DTree-0.9999          44          52          84          77\n",
       "1    RFC1-0.9999          20          78          88          56\n",
       "2    RFC2-0.9999          24          72          87          71\n",
       "3     XGB-0.9999          20          80          89          55\n",
       "4    LGBM-0.9999          32          77          89          70\n",
       "5     CAT-0.9999          32          80          90          63\n",
       "6    DTree-0.999          36          52          84          74\n",
       "7      RFC-0.999          24          70          87          70\n",
       "8     XGB1-0.999          20          78          87          57\n",
       "9     XGB2-0.999          52          56          83          83\n",
       "10    LGBM-0.999          24          75          88          68\n",
       "11     CAT-0.999          24          78          88          60"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'Model':['DTree-0.9999','RFC1-0.9999','RFC2-0.9999','XGB-0.9999','LGBM-0.9999','CAT-0.9999','DTree-0.999','RFC-0.999','XGB1-0.999','XGB2-0.999','LGBM-0.999','CAT-0.999'],\n",
    "                        'Severity-1':[44,20,24,20,32,32,36,24,20,52,24,24],\n",
    "                        'Severity-2':[52,78,72,80,77,80,52,70,78,56,75,78],\n",
    "                        'Severity-3':[84,88,87,89,89,90,84,87,87,83,88,88],\n",
    "                        'Severity-4':[77,56,71,55,70,63,74,70,57,83,68,60]\n",
    "                      })\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "boxed-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(4,1,figsize=(14,22))\n",
    "sns.barplot(x='Model',y='Severity-1',data=result,ax=ax[0])\n",
    "sns.barplot(x='Model',y='Severity-2',data=result,ax=ax[1])\n",
    "sns.barplot(x='Model',y='Severity-3',data=result,ax=ax[2])\n",
    "sns.barplot(x='Model',y='Severity-4',data=result,ax=ax[3])\n",
    "ax[0].set_ylim(0,100)\n",
    "ax[1].set_ylim(0,100)\n",
    "ax[2].set_ylim(0,100)\n",
    "ax[3].set_ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-polyester",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "467px",
    "left": "1013px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
